<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.3.450" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />

<meta name="author" content="Kunal Khurana" />
<meta name="dcterms.date" content="2024-02-23" />

<title>Homepage – Data Cleaning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<!-- htmldependencies:E3FAD763 -->
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YSR47ZM5Y0"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-YSR47ZM5Y0', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css" />
</head>

<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="/index.html">
    <span class="navbar-title">Homepage</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse"
  aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation"
  onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="/about.html" rel="" target="">
 <span class="menu-text">Kunal Khurana</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-posts" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Posts</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-posts">    
        <li>
    <a class="dropdown-item" href="/posts/index.html" rel="" target="">
 <span class="dropdown-text">All posts</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="/posts/en.html" rel="" target="">
 <span class="dropdown-text">English</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="/posts/fr.html" rel="" target="">
 <span class="dropdown-text">Français</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Kkhurana007/fr_blog_mine" rel="" target=""><i 
  class="bi bi-github" 
  role="img" 
>
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/kunalkhurana007" rel="" target=""><i 
  class="bi bi-twitter" 
  role="img" 
>
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <div id="quarto-toc-target"></div>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
  <div class="quarto-title-banner">
    <div class="quarto-title column-body">
      <h1 class="title">Data Cleaning</h1>
            <p class="subtitle lead">Python basics</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Python</div>
                <div class="quarto-category">Transformation</div>
                <div class="quarto-category">Catagorical</div>
                <div class="quarto-category">Mapping</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Kunal Khurana </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 23, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header>
<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#handing-missing-data" id="toc-handing-missing-data">Handing missing data</a></li>
  <li><a href="#data-transformation" id="toc-data-transformation">Data Transformation</a></li>
  <li><a href="#extension-data-types" id="toc-extension-data-types">Extension data types</a></li>
  <li><a href="#string-manipulation" id="toc-string-manipulation">String Manipulation</a></li>
  <li><a href="#categorical-data" id="toc-categorical-data">Categorical Data</a>
  <ul>
  <li><a href="#pandas.isna---other-methds" id="toc-pandas.isna---other-methds">pandas.isna - other methds</a></li>
  </ul></li>
  <li><a href="#filling-in-missing-data" id="toc-filling-in-missing-data">filling in missing data</a></li>
  <li><a href="#imputations-with-fillna" id="toc-imputations-with-fillna">imputations with fillna()</a></li>
  <li><a href="#data-transformation-1" id="toc-data-transformation-1">Data Transformation</a>
  <ul>
  <li><a href="#removing-duplicates" id="toc-removing-duplicates">Removing duplicates</a></li>
  <li><a href="#transforming-data-using-a-function-or-mapping" id="toc-transforming-data-using-a-function-or-mapping">Transforming data using a Function or mapping</a></li>
  <li><a href="#replacing-values" id="toc-replacing-values">Replacing values</a></li>
  <li><a href="#renaming-axis-indexes" id="toc-renaming-axis-indexes">Renaming Axis indexes</a></li>
  <li><a href="#discretization-and-binning" id="toc-discretization-and-binning">Discretization and Binning</a></li>
  <li><a href="#detecting-and-filtering-outliers" id="toc-detecting-and-filtering-outliers">Detecting and Filtering Outliers</a></li>
  <li><a href="#permutation-and-random-sampling" id="toc-permutation-and-random-sampling">Permutation and Random Sampling</a></li>
  <li><a href="#computing-indicatordummay-variables" id="toc-computing-indicatordummay-variables">Computing Indicator/Dummay Variables</a></li>
  <li><a href="#extension-data-types-1" id="toc-extension-data-types-1">Extension data types</a></li>
  <li><a href="#string-manipulation-1" id="toc-string-manipulation-1">String manipulation</a></li>
  <li><a href="#regular-expressions" id="toc-regular-expressions">Regular expressions</a></li>
  <li><a href="#string-functions-in-pandas" id="toc-string-functions-in-pandas">String functions in pandas</a></li>
  <li><a href="#categorical-data-1" id="toc-categorical-data-1">Categorical data</a></li>
  <li><a href="#categorical-extension-type-in-pandas" id="toc-categorical-extension-type-in-pandas">Categorical Extension type in pandas</a></li>
  <li><a href="#categorical-data-2" id="toc-categorical-data-2">Categorical data</a></li>
  <li><a href="#computations-with-categoricals" id="toc-computations-with-categoricals">Computations with categoricals</a>
  <ul>
  <li><a href="#using-groupby-for-summary-statistics" id="toc-using-groupby-for-summary-statistics">using groupby for summary statistics</a></li>
  <li><a href="#better-performance-with-categoricals" id="toc-better-performance-with-categoricals">Better performance with categoricals</a></li>
  </ul></li>
  <li><a href="#categorical-methods" id="toc-categorical-methods">Categorical Methods</a></li>
  <li><a href="#creating-dummy-variables-for-modelling" id="toc-creating-dummy-variables-for-modelling">Creating dummy variables for modelling</a></li>
  </ul></li>
  </ul>
</nav>
<section id="handing-missing-data" class="level2">
<h2>Handing missing data</h2>
<ul>
<li>Filtering</li>
<li>Filling</li>
</ul>
</section>
<section id="data-transformation" class="level2">
<h2>Data Transformation</h2>
<ul>
<li>Removing duplicates</li>
<li>Transforming data using function or Mapping</li>
<li>Replacing values</li>
<li>Renaming Axis Indexes</li>
<li>Discretization and Binning</li>
<li>Detecting and Filtering Outliers</li>
<li>Permutation and Random Sampling</li>
<li>Computing Indicator/Dummy variables</li>
</ul>
</section>
<section id="extension-data-types" class="level2">
<h2>Extension data types</h2>
</section>
<section id="string-manipulation" class="level2">
<h2>String Manipulation</h2>
<ul>
<li>Regular expressions</li>
<li>String functions in Pandas</li>
</ul>
</section>
<section id="categorical-data" class="level2">
<h2>Categorical Data</h2>
<ul>
<li>Background</li>
<li>types</li>
<li>computations with categoricals</li>
<li>Better performance with categoricals</li>
<li>Categorical methods</li>
<li>Creating dummy variables for modeling</li>
</ul>
<div class="cell" data-execution_count="3">
<div class="sourceCode" id="cb1"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode" id="cb2"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>float_data <span class="op">=</span> pd.Series([<span class="fl">1.2</span>, <span class="op">-</span><span class="fl">3.5</span>, np.nan, <span class="dv">0</span>])</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>float_data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>0    1.2
1   -3.5
2    NaN
3    0.0
dtype: float64</code></pre>
</div>
</div>
<section id="pandas.isna---other-methds" class="level3">
<h3>pandas.isna - <a href="https://learning.oreilly.com/library/view/python-for-data/9781098104023/ch07.html#table_na_method">other methds</a></h3>
<div class="cell" data-execution_count="7">
<div class="sourceCode" id="cb4"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># checking for nan values with booleans</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>float_data.isna()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>0    False
1    False
2     True
3    False
dtype: bool</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode" id="cb6"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">### filtering out missing data</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>float_data.dropna()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>0    1.2
1   -3.5
3    0.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode" id="cb8"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">### or with notna()</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>float_data[float_data.notna()]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0    1.2
1   -3.5
3    0.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode" id="cb10"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame([[<span class="fl">1.</span>, <span class="fl">6.5</span>, <span class="fl">3.</span>, <span class="dv">4</span>], </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                     [<span class="fl">1.</span>, np.nan, np.nan, <span class="dv">4</span>], </span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                     [<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">22</span>, np.nan],</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                     [np.nan, <span class="dv">434</span>, <span class="dv">33</span>, <span class="dv">1</span>]])</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.5</td>
<td>3.0</td>
<td>4.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>NaN</td>
<td>NaN</td>
<td>4.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3.0</td>
<td>4.0</td>
<td>22.0</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>NaN</td>
<td>434.0</td>
<td>33.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode" id="cb11"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>data.dropna()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.5</td>
<td>3.0</td>
<td>4.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode" id="cb12"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># how = &#39;all&#39; will drop all rows taht are all NA</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>data.dropna(how<span class="op">=</span><span class="st">&#39;all&#39;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.5</td>
<td>3.0</td>
<td>4.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>NaN</td>
<td>NaN</td>
<td>4.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3.0</td>
<td>4.0</td>
<td>22.0</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>NaN</td>
<td>434.0</td>
<td>33.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode" id="cb13"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dropping columns by how= all</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>data[<span class="dv">4</span>] <span class="op">=</span> np.nan</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>data</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.5</td>
<td>3.0</td>
<td>4.0</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>NaN</td>
<td>NaN</td>
<td>4.0</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3.0</td>
<td>4.0</td>
<td>22.0</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>NaN</td>
<td>434.0</td>
<td>33.0</td>
<td>1.0</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode" id="cb14"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>data.dropna(axis <span class="op">=</span> <span class="st">&quot;columns&quot;</span>, how<span class="op">=</span><span class="st">&quot;all&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.5</td>
<td>3.0</td>
<td>4.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>NaN</td>
<td>NaN</td>
<td>4.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3.0</td>
<td>4.0</td>
<td>22.0</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>NaN</td>
<td>434.0</td>
<td>33.0</td>
<td>1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode" id="cb15"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(np.random.standard_normal((<span class="dv">7</span>, <span class="dv">3</span>)))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>1.430864</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>-0.425012</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>-0.618281</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>2.883936</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode" id="cb16"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make null- first four rows of second column</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df.iloc[:<span class="dv">4</span>, <span class="dv">1</span>] <span class="op">=</span> np.nan</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode" id="cb17"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df.dropna()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to learn more about this method</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(df.dropna())</span></code></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode" id="cb19"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#ça marche pas</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>df.dropna(thresh<span class="op">=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="filling-in-missing-data" class="level2">
<h2>filling in missing data</h2>
<div class="cell" data-execution_count="47">
<div class="sourceCode" id="cb20"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>df.fillna(<span class="dv">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>0.000000</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>0.000000</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>0.000000</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>0.000000</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode" id="cb21"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using different fillvalue for each column</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>df.fillna({<span class="dv">1</span>:<span class="fl">0.5</span>})</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>0.500000</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>0.500000</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>0.500000</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>0.500000</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode" id="cb22"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode" id="cb23"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># same interpolation using fillna()</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>df.fillna(method <span class="op">=</span> <span class="st">&quot;ffill&quot;</span>).astype(<span class="bu">float</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode" id="cb24"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> python <span class="op">--</span>version</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Python 3.9.13</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(df)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>boxplot <span class="op">=</span> df.boxplot()</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mlt</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>mtl.inline.boxplot.show()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode" id="cb28"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(pd.Series)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class Series in module pandas.core.series:

class Series(pandas.core.base.IndexOpsMixin, pandas.core.generic.NDFrame)
 |  Series(data=None, index=None, dtype: &#39;Dtype | None&#39; = None, name=None, copy: &#39;bool | None&#39; = None, fastpath: &#39;bool&#39; = False) -&gt; &#39;None&#39;
 |  
 |  One-dimensional ndarray with axis labels (including time series).
 |  
 |  Labels need not be unique but must be a hashable type. The object
 |  supports both integer- and label-based indexing and provides a host of
 |  methods for performing operations involving the index. Statistical
 |  methods from ndarray have been overridden to automatically exclude
 |  missing data (currently represented as NaN).
 |  
 |  Operations between Series (+, -, /, \*, \*\*) align values based on their
 |  associated index values-- they need not be the same length. The result
 |  index will be the sorted union of the two indexes.
 |  
 |  Parameters
 |  ----------
 |  data : array-like, Iterable, dict, or scalar value
 |      Contains data stored in Series. If data is a dict, argument order is
 |      maintained.
 |  index : array-like or Index (1d)
 |      Values must be hashable and have the same length as `data`.
 |      Non-unique index values are allowed. Will default to
 |      RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like
 |      and index is None, then the keys in the data are used as the index. If the
 |      index is not None, the resulting Series is reindexed with the index values.
 |  dtype : str, numpy.dtype, or ExtensionDtype, optional
 |      Data type for the output Series. If not specified, this will be
 |      inferred from `data`.
 |      See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.
 |  name : Hashable, default None
 |      The name to give to the Series.
 |  copy : bool, default False
 |      Copy input data. Only affects Series or 1d ndarray input. See examples.
 |  
 |  Notes
 |  -----
 |  Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.
 |  
 |  Examples
 |  --------
 |  Constructing Series from a dictionary with an Index specified
 |  
 |  &gt;&gt;&gt; d = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3}
 |  &gt;&gt;&gt; ser = pd.Series(data=d, index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |  &gt;&gt;&gt; ser
 |  a   1
 |  b   2
 |  c   3
 |  dtype: int64
 |  
 |  The keys of the dictionary match with the Index values, hence the Index
 |  values have no effect.
 |  
 |  &gt;&gt;&gt; d = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3}
 |  &gt;&gt;&gt; ser = pd.Series(data=d, index=[&#39;x&#39;, &#39;y&#39;, &#39;z&#39;])
 |  &gt;&gt;&gt; ser
 |  x   NaN
 |  y   NaN
 |  z   NaN
 |  dtype: float64
 |  
 |  Note that the Index is first build with the keys from the dictionary.
 |  After this the Series is reindexed with the given Index values, hence we
 |  get all NaN as a result.
 |  
 |  Constructing Series from a list with `copy=False`.
 |  
 |  &gt;&gt;&gt; r = [1, 2]
 |  &gt;&gt;&gt; ser = pd.Series(r, copy=False)
 |  &gt;&gt;&gt; ser.iloc[0] = 999
 |  &gt;&gt;&gt; r
 |  [1, 2]
 |  &gt;&gt;&gt; ser
 |  0    999
 |  1      2
 |  dtype: int64
 |  
 |  Due to input data type the Series has a `copy` of
 |  the original data even though `copy=False`, so
 |  the data is unchanged.
 |  
 |  Constructing Series from a 1d ndarray with `copy=False`.
 |  
 |  &gt;&gt;&gt; r = np.array([1, 2])
 |  &gt;&gt;&gt; ser = pd.Series(r, copy=False)
 |  &gt;&gt;&gt; ser.iloc[0] = 999
 |  &gt;&gt;&gt; r
 |  array([999,   2])
 |  &gt;&gt;&gt; ser
 |  0    999
 |  1      2
 |  dtype: int64
 |  
 |  Due to input data type the Series has a `view` on
 |  the original data, so
 |  the data is changed as well.
 |  
 |  Method resolution order:
 |      Series
 |      pandas.core.base.IndexOpsMixin
 |      pandas.core.arraylike.OpsMixin
 |      pandas.core.generic.NDFrame
 |      pandas.core.base.PandasObject
 |      pandas.core.accessor.DirNamesMixin
 |      pandas.core.indexing.IndexingMixin
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __array__(self, dtype: &#39;npt.DTypeLike | None&#39; = None) -&gt; &#39;np.ndarray&#39;
 |      Return the values as a NumPy array.
 |      
 |      Users should not call this directly. Rather, it is invoked by
 |      :func:`numpy.array` and :func:`numpy.asarray`.
 |      
 |      Parameters
 |      ----------
 |      dtype : str or numpy.dtype, optional
 |          The dtype to use for the resulting NumPy array. By default,
 |          the dtype is inferred from the data.
 |      
 |      Returns
 |      -------
 |      numpy.ndarray
 |          The values in the series converted to a :class:`numpy.ndarray`
 |          with the specified `dtype`.
 |      
 |      See Also
 |      --------
 |      array : Create a new array from data.
 |      Series.array : Zero-copy view to the array backing the Series.
 |      Series.to_numpy : Series method for similar behavior.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; ser = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; np.asarray(ser)
 |      array([1, 2, 3])
 |      
 |      For timezone-aware data, the timezones may be retained with
 |      ``dtype=&#39;object&#39;``
 |      
 |      &gt;&gt;&gt; tzser = pd.Series(pd.date_range(&#39;2000&#39;, periods=2, tz=&quot;CET&quot;))
 |      &gt;&gt;&gt; np.asarray(tzser, dtype=&quot;object&quot;)
 |      array([Timestamp(&#39;2000-01-01 00:00:00+0100&#39;, tz=&#39;CET&#39;),
 |             Timestamp(&#39;2000-01-02 00:00:00+0100&#39;, tz=&#39;CET&#39;)],
 |            dtype=object)
 |      
 |      Or the values may be localized to UTC and the tzinfo discarded with
 |      ``dtype=&#39;datetime64[ns]&#39;``
 |      
 |      &gt;&gt;&gt; np.asarray(tzser, dtype=&quot;datetime64[ns]&quot;)  # doctest: +ELLIPSIS
 |      array([&#39;1999-12-31T23:00:00.000000000&#39;, ...],
 |            dtype=&#39;datetime64[ns]&#39;)
 |  
 |  __float__(self)
 |  
 |  __getitem__(self, key)
 |  
 |  __init__(self, data=None, index=None, dtype: &#39;Dtype | None&#39; = None, name=None, copy: &#39;bool | None&#39; = None, fastpath: &#39;bool&#39; = False) -&gt; &#39;None&#39;
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  __int__(self)
 |  
 |  __len__(self) -&gt; &#39;int&#39;
 |      Return the length of the Series.
 |  
 |  __matmul__(self, other)
 |      Matrix multiplication using binary `@` operator in Python&gt;=3.5.
 |  
 |  __repr__(self) -&gt; &#39;str&#39;
 |      Return a string representation for a particular Series.
 |  
 |  __rmatmul__(self, other)
 |      Matrix multiplication using binary `@` operator in Python&gt;=3.5.
 |  
 |  __setitem__(self, key, value) -&gt; &#39;None&#39;
 |  
 |  add(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Addition of series and other, element-wise (binary operator `add`).
 |      
 |      Equivalent to ``series + other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.radd : Reverse of the Addition operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.add(b, fill_value=0)
 |      a    2.0
 |      b    1.0
 |      c    1.0
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |  
 |  agg = aggregate(self, func=None, axis: &#39;Axis&#39; = 0, *args, **kwargs)
 |  
 |  aggregate(self, func=None, axis: &#39;Axis&#39; = 0, *args, **kwargs)
 |      Aggregate using one or more operations over the specified axis.
 |      
 |      Parameters
 |      ----------
 |      func : function, str, list or dict
 |          Function to use for aggregating the data. If a function, must either
 |          work when passed a Series or when passed to Series.apply.
 |      
 |          Accepted combinations are:
 |      
 |          - function
 |          - string function name
 |          - list of functions and/or function names, e.g. ``[np.sum, &#39;mean&#39;]``
 |          - dict of axis labels -&gt; functions, function names or list of such.
 |      axis : {0 or &#39;index&#39;}
 |              Unused. Parameter needed for compatibility with DataFrame.
 |      *args
 |          Positional arguments to pass to `func`.
 |      **kwargs
 |          Keyword arguments to pass to `func`.
 |      
 |      Returns
 |      -------
 |      scalar, Series or DataFrame
 |      
 |          The return can be:
 |      
 |          * scalar : when Series.agg is called with single function
 |          * Series : when DataFrame.agg is called with a single function
 |          * DataFrame : when DataFrame.agg is called with several functions
 |      
 |          Return scalar, Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      Series.apply : Invoke function on a Series.
 |      Series.transform : Transform function producing a Series with like indexes.
 |      
 |      Notes
 |      -----
 |      `agg` is an alias for `aggregate`. Use the alias.
 |      
 |      Functions that mutate the passed object can produce unexpected
 |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
 |      for more details.
 |      
 |      A passed user-defined-function will be passed a Series for evaluation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.agg(&#39;min&#39;)
 |      1
 |      
 |      &gt;&gt;&gt; s.agg([&#39;min&#39;, &#39;max&#39;])
 |      min   1
 |      max   4
 |      dtype: int64
 |  
 |  align(self, other: &#39;Series&#39;, join: &#39;AlignJoin&#39; = &#39;outer&#39;, axis: &#39;Axis | None&#39; = None, level: &#39;Level&#39; = None, copy: &#39;bool | None&#39; = None, fill_value: &#39;Hashable&#39; = None, method: &#39;FillnaOptions | None&#39; = None, limit: &#39;int | None&#39; = None, fill_axis: &#39;Axis&#39; = 0, broadcast_axis: &#39;Axis | None&#39; = None) -&gt; &#39;Series&#39;
 |      Align two objects on their axes with the specified join method.
 |      
 |      Join method is specified for each axis Index.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame or Series
 |      join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
 |      axis : allowed axis of the other object, default None
 |          Align on index (0), columns (1), or both (None).
 |      level : int or level name, default None
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      copy : bool, default True
 |          Always returns new objects. If copy=False and no reindexing is
 |          required then original objects are returned.
 |      fill_value : scalar, default np.NaN
 |          Value to use for missing values. Defaults to NaN, but can be any
 |          &quot;compatible&quot; value.
 |      method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
 |          Method to use for filling holes in reindexed Series:
 |      
 |          - pad / ffill: propagate last valid observation forward to next valid.
 |          - backfill / bfill: use NEXT valid observation to fill gap.
 |      
 |      limit : int, default None
 |          If method is specified, this is the maximum number of consecutive
 |          NaN values to forward/backward fill. In other words, if there is
 |          a gap with more than this number of consecutive NaNs, it will only
 |          be partially filled. If method is not specified, this is the
 |          maximum number of entries along the entire axis where NaNs will be
 |          filled. Must be greater than 0 if not None.
 |      fill_axis : {0 or &#39;index&#39;}, default 0
 |          Filling axis, method and limit.
 |      broadcast_axis : {0 or &#39;index&#39;}, default None
 |          Broadcast values along this axis, if aligning two objects of
 |          different dimensions.
 |      
 |      Returns
 |      -------
 |      tuple of (Series, type of other)
 |          Aligned objects.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     [[1, 2, 3, 4], [6, 7, 8, 9]], columns=[&quot;D&quot;, &quot;B&quot;, &quot;E&quot;, &quot;A&quot;], index=[1, 2]
 |      ... )
 |      &gt;&gt;&gt; other = pd.DataFrame(
 |      ...     [[10, 20, 30, 40], [60, 70, 80, 90], [600, 700, 800, 900]],
 |      ...     columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;],
 |      ...     index=[2, 3, 4],
 |      ... )
 |      &gt;&gt;&gt; df
 |         D  B  E  A
 |      1  1  2  3  4
 |      2  6  7  8  9
 |      &gt;&gt;&gt; other
 |          A    B    C    D
 |      2   10   20   30   40
 |      3   60   70   80   90
 |      4  600  700  800  900
 |      
 |      Align on columns:
 |      
 |      &gt;&gt;&gt; left, right = df.align(other, join=&quot;outer&quot;, axis=1)
 |      &gt;&gt;&gt; left
 |         A  B   C  D  E
 |      1  4  2 NaN  1  3
 |      2  9  7 NaN  6  8
 |      &gt;&gt;&gt; right
 |          A    B    C    D   E
 |      2   10   20   30   40 NaN
 |      3   60   70   80   90 NaN
 |      4  600  700  800  900 NaN
 |      
 |      We can also align on the index:
 |      
 |      &gt;&gt;&gt; left, right = df.align(other, join=&quot;outer&quot;, axis=0)
 |      &gt;&gt;&gt; left
 |          D    B    E    A
 |      1  1.0  2.0  3.0  4.0
 |      2  6.0  7.0  8.0  9.0
 |      3  NaN  NaN  NaN  NaN
 |      4  NaN  NaN  NaN  NaN
 |      &gt;&gt;&gt; right
 |          A      B      C      D
 |      1    NaN    NaN    NaN    NaN
 |      2   10.0   20.0   30.0   40.0
 |      3   60.0   70.0   80.0   90.0
 |      4  600.0  700.0  800.0  900.0
 |      
 |      Finally, the default `axis=None` will align on both index and columns:
 |      
 |      &gt;&gt;&gt; left, right = df.align(other, join=&quot;outer&quot;, axis=None)
 |      &gt;&gt;&gt; left
 |           A    B   C    D    E
 |      1  4.0  2.0 NaN  1.0  3.0
 |      2  9.0  7.0 NaN  6.0  8.0
 |      3  NaN  NaN NaN  NaN  NaN
 |      4  NaN  NaN NaN  NaN  NaN
 |      &gt;&gt;&gt; right
 |             A      B      C      D   E
 |      1    NaN    NaN    NaN    NaN NaN
 |      2   10.0   20.0   30.0   40.0 NaN
 |      3   60.0   70.0   80.0   90.0 NaN
 |      4  600.0  700.0  800.0  900.0 NaN
 |  
 |  all(self, axis: &#39;Axis&#39; = 0, bool_only=None, skipna: &#39;bool_t&#39; = True, **kwargs)
 |      Return whether all elements are True, potentially over an axis.
 |      
 |      Returns True unless there at least one element within a series or
 |      along a Dataframe axis that is False or equivalent (e.g. zero or
 |      empty).
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default 0
 |          Indicate which axis or axes should be reduced. For `Series` this parameter
 |          is unused and defaults to 0.
 |      
 |          * 0 / &#39;index&#39; : reduce the index, return a Series whose index is the
 |            original column labels.
 |          * 1 / &#39;columns&#39; : reduce the columns, return a Series whose index is the
 |            original index.
 |          * None : reduce all axes, return a scalar.
 |      
 |      bool_only : bool, default None
 |          Include only boolean columns. If None, will attempt to use everything,
 |          then use only boolean data. Not implemented for Series.
 |      skipna : bool, default True
 |          Exclude NA/null values. If the entire row/column is NA and skipna is
 |          True, then the result will be True, as for an empty row/column.
 |          If skipna is False, then NA are treated as True, because these are not
 |          equal to zero.
 |      **kwargs : any, default None
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      scalar or Series
 |          If level is specified, then, Series is returned; otherwise, scalar
 |          is returned.
 |      
 |      See Also
 |      --------
 |      Series.all : Return True if all elements are True.
 |      DataFrame.any : Return True if one (or more) elements are True.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; pd.Series([True, True]).all()
 |      True
 |      &gt;&gt;&gt; pd.Series([True, False]).all()
 |      False
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).all()
 |      True
 |      &gt;&gt;&gt; pd.Series([np.nan]).all()
 |      True
 |      &gt;&gt;&gt; pd.Series([np.nan]).all(skipna=False)
 |      True
 |      
 |      **DataFrames**
 |      
 |      Create a dataframe from a dictionary.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [True, True], &#39;col2&#39;: [True, False]})
 |      &gt;&gt;&gt; df
 |         col1   col2
 |      0  True   True
 |      1  True  False
 |      
 |      Default behaviour checks if values in each column all return True.
 |      
 |      &gt;&gt;&gt; df.all()
 |      col1     True
 |      col2    False
 |      dtype: bool
 |      
 |      Specify ``axis=&#39;columns&#39;`` to check if values in each row all return True.
 |      
 |      &gt;&gt;&gt; df.all(axis=&#39;columns&#39;)
 |      0     True
 |      1    False
 |      dtype: bool
 |      
 |      Or ``axis=None`` for whether every value is True.
 |      
 |      &gt;&gt;&gt; df.all(axis=None)
 |      False
 |  
 |  any(self, *, axis: &#39;Axis&#39; = 0, bool_only=None, skipna: &#39;bool_t&#39; = True, **kwargs)
 |      Return whether any element is True, potentially over an axis.
 |      
 |      Returns False unless there is at least one element within a series or
 |      along a Dataframe axis that is True or equivalent (e.g. non-zero or
 |      non-empty).
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default 0
 |          Indicate which axis or axes should be reduced. For `Series` this parameter
 |          is unused and defaults to 0.
 |      
 |          * 0 / &#39;index&#39; : reduce the index, return a Series whose index is the
 |            original column labels.
 |          * 1 / &#39;columns&#39; : reduce the columns, return a Series whose index is the
 |            original index.
 |          * None : reduce all axes, return a scalar.
 |      
 |      bool_only : bool, default None
 |          Include only boolean columns. If None, will attempt to use everything,
 |          then use only boolean data. Not implemented for Series.
 |      skipna : bool, default True
 |          Exclude NA/null values. If the entire row/column is NA and skipna is
 |          True, then the result will be False, as for an empty row/column.
 |          If skipna is False, then NA are treated as True, because these are not
 |          equal to zero.
 |      **kwargs : any, default None
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      scalar or Series
 |          If level is specified, then, Series is returned; otherwise, scalar
 |          is returned.
 |      
 |      See Also
 |      --------
 |      numpy.any : Numpy version of this method.
 |      Series.any : Return whether any element is True.
 |      Series.all : Return whether all elements are True.
 |      DataFrame.any : Return whether any element is True over requested axis.
 |      DataFrame.all : Return whether all elements are True over requested axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      For Series input, the output is a scalar indicating whether any element
 |      is True.
 |      
 |      &gt;&gt;&gt; pd.Series([False, False]).any()
 |      False
 |      &gt;&gt;&gt; pd.Series([True, False]).any()
 |      True
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).any()
 |      False
 |      &gt;&gt;&gt; pd.Series([np.nan]).any()
 |      False
 |      &gt;&gt;&gt; pd.Series([np.nan]).any(skipna=False)
 |      True
 |      
 |      **DataFrame**
 |      
 |      Whether each column contains at least one True element (the default).
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [0, 2], &quot;C&quot;: [0, 0]})
 |      &gt;&gt;&gt; df
 |         A  B  C
 |      0  1  0  0
 |      1  2  2  0
 |      
 |      &gt;&gt;&gt; df.any()
 |      A     True
 |      B     True
 |      C    False
 |      dtype: bool
 |      
 |      Aggregating over the columns.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [True, False], &quot;B&quot;: [1, 2]})
 |      &gt;&gt;&gt; df
 |             A  B
 |      0   True  1
 |      1  False  2
 |      
 |      &gt;&gt;&gt; df.any(axis=&#39;columns&#39;)
 |      0    True
 |      1    True
 |      dtype: bool
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [True, False], &quot;B&quot;: [1, 0]})
 |      &gt;&gt;&gt; df
 |             A  B
 |      0   True  1
 |      1  False  0
 |      
 |      &gt;&gt;&gt; df.any(axis=&#39;columns&#39;)
 |      0    True
 |      1    False
 |      dtype: bool
 |      
 |      Aggregating over the entire DataFrame with ``axis=None``.
 |      
 |      &gt;&gt;&gt; df.any(axis=None)
 |      True
 |      
 |      `any` for an empty DataFrame is an empty Series.
 |      
 |      &gt;&gt;&gt; pd.DataFrame([]).any()
 |      Series([], dtype: bool)
 |  
 |  apply(self, func: &#39;AggFuncType&#39;, convert_dtype: &#39;bool&#39; = True, args: &#39;tuple[Any, ...]&#39; = (), **kwargs) -&gt; &#39;DataFrame | Series&#39;
 |      Invoke function on values of Series.
 |      
 |      Can be ufunc (a NumPy function that applies to the entire Series)
 |      or a Python function that only works on single values.
 |      
 |      Parameters
 |      ----------
 |      func : function
 |          Python function or NumPy ufunc to apply.
 |      convert_dtype : bool, default True
 |          Try to find better dtype for elementwise function results. If
 |          False, leave as dtype=object. Note that the dtype is always
 |          preserved for some extension array dtypes, such as Categorical.
 |      args : tuple
 |          Positional arguments passed to func after the series value.
 |      **kwargs
 |          Additional keyword arguments passed to func.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          If func returns a Series object the result will be a DataFrame.
 |      
 |      See Also
 |      --------
 |      Series.map: For element-wise operations.
 |      Series.agg: Only perform aggregating type operations.
 |      Series.transform: Only perform transforming type operations.
 |      
 |      Notes
 |      -----
 |      Functions that mutate the passed object can produce unexpected
 |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
 |      for more details.
 |      
 |      Examples
 |      --------
 |      Create a series with typical summer temperatures for each city.
 |      
 |      &gt;&gt;&gt; s = pd.Series([20, 21, 12],
 |      ...               index=[&#39;London&#39;, &#39;New York&#39;, &#39;Helsinki&#39;])
 |      &gt;&gt;&gt; s
 |      London      20
 |      New York    21
 |      Helsinki    12
 |      dtype: int64
 |      
 |      Square the values by defining a function and passing it as an
 |      argument to ``apply()``.
 |      
 |      &gt;&gt;&gt; def square(x):
 |      ...     return x ** 2
 |      &gt;&gt;&gt; s.apply(square)
 |      London      400
 |      New York    441
 |      Helsinki    144
 |      dtype: int64
 |      
 |      Square the values by passing an anonymous function as an
 |      argument to ``apply()``.
 |      
 |      &gt;&gt;&gt; s.apply(lambda x: x ** 2)
 |      London      400
 |      New York    441
 |      Helsinki    144
 |      dtype: int64
 |      
 |      Define a custom function that needs additional positional
 |      arguments and pass these additional arguments using the
 |      ``args`` keyword.
 |      
 |      &gt;&gt;&gt; def subtract_custom_value(x, custom_value):
 |      ...     return x - custom_value
 |      
 |      &gt;&gt;&gt; s.apply(subtract_custom_value, args=(5,))
 |      London      15
 |      New York    16
 |      Helsinki     7
 |      dtype: int64
 |      
 |      Define a custom function that takes keyword arguments
 |      and pass these arguments to ``apply``.
 |      
 |      &gt;&gt;&gt; def add_custom_values(x, **kwargs):
 |      ...     for month in kwargs:
 |      ...         x += kwargs[month]
 |      ...     return x
 |      
 |      &gt;&gt;&gt; s.apply(add_custom_values, june=30, july=20, august=25)
 |      London      95
 |      New York    96
 |      Helsinki    87
 |      dtype: int64
 |      
 |      Use a function from the Numpy library.
 |      
 |      &gt;&gt;&gt; s.apply(np.log)
 |      London      2.995732
 |      New York    3.044522
 |      Helsinki    2.484907
 |      dtype: float64
 |  
 |  argsort(self, axis: &#39;Axis&#39; = 0, kind: &#39;SortKind&#39; = &#39;quicksort&#39;, order: &#39;None&#39; = None) -&gt; &#39;Series&#39;
 |      Return the integer indices that would sort the Series values.
 |      
 |      Override ndarray.argsort. Argsorts the value, omitting NA/null values,
 |      and places the result in the same locations as the non-NA values.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      kind : {&#39;mergesort&#39;, &#39;quicksort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
 |          Choice of sorting algorithm. See :func:`numpy.sort` for more
 |          information. &#39;mergesort&#39; and &#39;stable&#39; are the only stable algorithms.
 |      order : None
 |          Has no effect but is accepted for compatibility with numpy.
 |      
 |      Returns
 |      -------
 |      Series[np.intp]
 |          Positions of values within the sort order with -1 indicating
 |          nan values.
 |      
 |      See Also
 |      --------
 |      numpy.ndarray.argsort : Returns the indices that would sort this array.
 |  
 |  asfreq(self, freq: &#39;Frequency&#39;, method: &#39;FillnaOptions | None&#39; = None, how: &#39;str | None&#39; = None, normalize: &#39;bool&#39; = False, fill_value: &#39;Hashable&#39; = None) -&gt; &#39;Series&#39;
 |      Convert time series to specified frequency.
 |      
 |      Returns the original data conformed to a new index with the specified
 |      frequency.
 |      
 |      If the index of this Series is a :class:`~pandas.PeriodIndex`, the new index
 |      is the result of transforming the original index with
 |      :meth:`PeriodIndex.asfreq &lt;pandas.PeriodIndex.asfreq&gt;` (so the original index
 |      will map one-to-one to the new index).
 |      
 |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,
 |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and
 |      last entries in the original index (see :func:`pandas.date_range`). The
 |      values corresponding to any timesteps in the new index which were not present
 |      in the original index will be null (``NaN``), unless a method for filling
 |      such unknowns is provided (see the ``method`` parameter below).
 |      
 |      The :meth:`resample` method is more appropriate if an operation on each group of
 |      timesteps (such as an aggregate) is necessary to represent the data at the new
 |      frequency.
 |      
 |      Parameters
 |      ----------
 |      freq : DateOffset or str
 |          Frequency DateOffset or string.
 |      method : {&#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;}, default None
 |          Method to use for filling holes in reindexed Series (note this
 |          does not fill NaNs that already were present):
 |      
 |          * &#39;pad&#39; / &#39;ffill&#39;: propagate last valid observation forward to next
 |            valid
 |          * &#39;backfill&#39; / &#39;bfill&#39;: use NEXT valid observation to fill.
 |      how : {&#39;start&#39;, &#39;end&#39;}, default end
 |          For PeriodIndex only (see PeriodIndex.asfreq).
 |      normalize : bool, default False
 |          Whether to reset output index to midnight.
 |      fill_value : scalar, optional
 |          Value to use for missing values, applied during upsampling (note
 |          this does not fill NaNs that already were present).
 |      
 |      Returns
 |      -------
 |      Series
 |          Series object reindexed to the specified frequency.
 |      
 |      See Also
 |      --------
 |      reindex : Conform DataFrame to new index with optional filling logic.
 |      
 |      Notes
 |      -----
 |      To learn more about the frequency strings, please see `this link
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases&gt;`__.
 |      
 |      Examples
 |      --------
 |      Start by creating a series with 4 one minute timestamps.
 |      
 |      &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=4, freq=&#39;T&#39;)
 |      &gt;&gt;&gt; series = pd.Series([0.0, None, 2.0, 3.0], index=index)
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;s&#39;: series})
 |      &gt;&gt;&gt; df
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:03:00    3.0
 |      
 |      Upsample the series into 30 second bins.
 |      
 |      &gt;&gt;&gt; df.asfreq(freq=&#39;30S&#39;)
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:00:30    NaN
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:01:30    NaN
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:02:30    NaN
 |      2000-01-01 00:03:00    3.0
 |      
 |      Upsample again, providing a ``fill value``.
 |      
 |      &gt;&gt;&gt; df.asfreq(freq=&#39;30S&#39;, fill_value=9.0)
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:00:30    9.0
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:01:30    9.0
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:02:30    9.0
 |      2000-01-01 00:03:00    3.0
 |      
 |      Upsample again, providing a ``method``.
 |      
 |      &gt;&gt;&gt; df.asfreq(freq=&#39;30S&#39;, method=&#39;bfill&#39;)
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:00:30    NaN
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:01:30    2.0
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:02:30    3.0
 |      2000-01-01 00:03:00    3.0
 |  
 |  autocorr(self, lag: &#39;int&#39; = 1) -&gt; &#39;float&#39;
 |      Compute the lag-N autocorrelation.
 |      
 |      This method computes the Pearson correlation between
 |      the Series and its shifted self.
 |      
 |      Parameters
 |      ----------
 |      lag : int, default 1
 |          Number of lags to apply before performing autocorrelation.
 |      
 |      Returns
 |      -------
 |      float
 |          The Pearson correlation between self and self.shift(lag).
 |      
 |      See Also
 |      --------
 |      Series.corr : Compute the correlation between two Series.
 |      Series.shift : Shift index by desired number of periods.
 |      DataFrame.corr : Compute pairwise correlation of columns.
 |      DataFrame.corrwith : Compute pairwise correlation between rows or
 |          columns of two DataFrame objects.
 |      
 |      Notes
 |      -----
 |      If the Pearson correlation is not well defined return &#39;NaN&#39;.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([0.25, 0.5, 0.2, -0.05])
 |      &gt;&gt;&gt; s.autocorr()  # doctest: +ELLIPSIS
 |      0.10355...
 |      &gt;&gt;&gt; s.autocorr(lag=2)  # doctest: +ELLIPSIS
 |      -0.99999...
 |      
 |      If the Pearson correlation is not well defined, then &#39;NaN&#39; is returned.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 0, 0, 0])
 |      &gt;&gt;&gt; s.autocorr()
 |      nan
 |  
 |  between(self, left, right, inclusive: &quot;Literal[&#39;both&#39;, &#39;neither&#39;, &#39;left&#39;, &#39;right&#39;]&quot; = &#39;both&#39;) -&gt; &#39;Series&#39;
 |      Return boolean Series equivalent to left &lt;= series &lt;= right.
 |      
 |      This function returns a boolean vector containing `True` wherever the
 |      corresponding Series element is between the boundary values `left` and
 |      `right`. NA values are treated as `False`.
 |      
 |      Parameters
 |      ----------
 |      left : scalar or list-like
 |          Left boundary.
 |      right : scalar or list-like
 |          Right boundary.
 |      inclusive : {&quot;both&quot;, &quot;neither&quot;, &quot;left&quot;, &quot;right&quot;}
 |          Include boundaries. Whether to set each bound as closed or open.
 |      
 |          .. versionchanged:: 1.3.0
 |      
 |      Returns
 |      -------
 |      Series
 |          Series representing whether each element is between left and
 |          right (inclusive).
 |      
 |      See Also
 |      --------
 |      Series.gt : Greater than of series and other.
 |      Series.lt : Less than of series and other.
 |      
 |      Notes
 |      -----
 |      This function is equivalent to ``(left &lt;= ser) &amp; (ser &lt;= right)``
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([2, 0, 4, 8, np.nan])
 |      
 |      Boundary values are included by default:
 |      
 |      &gt;&gt;&gt; s.between(1, 4)
 |      0     True
 |      1    False
 |      2     True
 |      3    False
 |      4    False
 |      dtype: bool
 |      
 |      With `inclusive` set to ``&quot;neither&quot;`` boundary values are excluded:
 |      
 |      &gt;&gt;&gt; s.between(1, 4, inclusive=&quot;neither&quot;)
 |      0     True
 |      1    False
 |      2    False
 |      3    False
 |      4    False
 |      dtype: bool
 |      
 |      `left` and `right` can be any scalar value:
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;Alice&#39;, &#39;Bob&#39;, &#39;Carol&#39;, &#39;Eve&#39;])
 |      &gt;&gt;&gt; s.between(&#39;Anna&#39;, &#39;Daniel&#39;)
 |      0    False
 |      1     True
 |      2     True
 |      3    False
 |      dtype: bool
 |  
 |  bfill(self, *, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool&#39; = False, limit: &#39;None | int&#39; = None, downcast: &#39;dict | None&#39; = None) -&gt; &#39;Series | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;bfill&#39;``.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  clip(self: &#39;Series&#39;, lower=None, upper=None, *, axis: &#39;Axis | None&#39; = None, inplace: &#39;bool&#39; = False, **kwargs) -&gt; &#39;Series | None&#39;
 |      Trim values at input threshold(s).
 |      
 |      Assigns values outside boundary to boundary values. Thresholds
 |      can be singular values or array like, and in the latter case
 |      the clipping is performed element-wise in the specified axis.
 |      
 |      Parameters
 |      ----------
 |      lower : float or array-like, default None
 |          Minimum threshold value. All values below this
 |          threshold will be set to it. A missing
 |          threshold (e.g `NA`) will not clip the value.
 |      upper : float or array-like, default None
 |          Maximum threshold value. All values above this
 |          threshold will be set to it. A missing
 |          threshold (e.g `NA`) will not clip the value.
 |      axis : {{0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}}, default None
 |          Align object with lower and upper along the given axis.
 |          For `Series` this parameter is unused and defaults to `None`.
 |      inplace : bool, default False
 |          Whether to perform the operation in place on the data.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted
 |          for compatibility with numpy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame or None
 |          Same type as calling object with the values outside the
 |          clip boundaries replaced or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.clip : Trim values at input threshold in series.
 |      DataFrame.clip : Trim values at input threshold in dataframe.
 |      numpy.clip : Clip (limit) the values in an array.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; data = {&#39;col_0&#39;: [9, -3, 0, -1, 5], &#39;col_1&#39;: [-2, -7, 6, 8, -5]}
 |      &gt;&gt;&gt; df = pd.DataFrame(data)
 |      &gt;&gt;&gt; df
 |         col_0  col_1
 |      0      9     -2
 |      1     -3     -7
 |      2      0      6
 |      3     -1      8
 |      4      5     -5
 |      
 |      Clips per column using lower and upper thresholds:
 |      
 |      &gt;&gt;&gt; df.clip(-4, 6)
 |         col_0  col_1
 |      0      6     -2
 |      1     -3     -4
 |      2      0      6
 |      3     -1      6
 |      4      5     -4
 |      
 |      Clips using specific lower and upper thresholds per column element:
 |      
 |      &gt;&gt;&gt; t = pd.Series([2, -4, -1, 6, 3])
 |      &gt;&gt;&gt; t
 |      0    2
 |      1   -4
 |      2   -1
 |      3    6
 |      4    3
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.clip(t, t + 4, axis=0)
 |         col_0  col_1
 |      0      6      2
 |      1     -3     -4
 |      2      0      3
 |      3      6      8
 |      4      5      3
 |      
 |      Clips using specific lower threshold per column element, with missing values:
 |      
 |      &gt;&gt;&gt; t = pd.Series([2, -4, np.NaN, 6, 3])
 |      &gt;&gt;&gt; t
 |      0    2.0
 |      1   -4.0
 |      2    NaN
 |      3    6.0
 |      4    3.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; df.clip(t, axis=0)
 |      col_0  col_1
 |      0      9      2
 |      1     -3     -4
 |      2      0      6
 |      3      6      8
 |      4      5      3
 |  
 |  combine(self, other: &#39;Series | Hashable&#39;, func: &#39;Callable[[Hashable, Hashable], Hashable]&#39;, fill_value: &#39;Hashable&#39; = None) -&gt; &#39;Series&#39;
 |      Combine the Series with a Series or scalar according to `func`.
 |      
 |      Combine the Series and `other` using `func` to perform elementwise
 |      selection for combined Series.
 |      `fill_value` is assumed when value is missing at some index
 |      from one of the two objects being combined.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar
 |          The value(s) to be combined with the `Series`.
 |      func : function
 |          Function that takes two scalars as inputs and returns an element.
 |      fill_value : scalar, optional
 |          The value to assume when an index is missing from
 |          one Series or the other. The default specifies to use the
 |          appropriate NaN value for the underlying dtype of the Series.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of combining the Series with the other object.
 |      
 |      See Also
 |      --------
 |      Series.combine_first : Combine Series values, choosing the calling
 |          Series&#39; values first.
 |      
 |      Examples
 |      --------
 |      Consider 2 Datasets ``s1`` and ``s2`` containing
 |      highest clocked speeds of different birds.
 |      
 |      &gt;&gt;&gt; s1 = pd.Series({&#39;falcon&#39;: 330.0, &#39;eagle&#39;: 160.0})
 |      &gt;&gt;&gt; s1
 |      falcon    330.0
 |      eagle     160.0
 |      dtype: float64
 |      &gt;&gt;&gt; s2 = pd.Series({&#39;falcon&#39;: 345.0, &#39;eagle&#39;: 200.0, &#39;duck&#39;: 30.0})
 |      &gt;&gt;&gt; s2
 |      falcon    345.0
 |      eagle     200.0
 |      duck       30.0
 |      dtype: float64
 |      
 |      Now, to combine the two datasets and view the highest speeds
 |      of the birds across the two datasets
 |      
 |      &gt;&gt;&gt; s1.combine(s2, max)
 |      duck        NaN
 |      eagle     200.0
 |      falcon    345.0
 |      dtype: float64
 |      
 |      In the previous example, the resulting value for duck is missing,
 |      because the maximum of a NaN and a float is a NaN.
 |      So, in the example, we set ``fill_value=0``,
 |      so the maximum value returned will be the value from some dataset.
 |      
 |      &gt;&gt;&gt; s1.combine(s2, max, fill_value=0)
 |      duck       30.0
 |      eagle     200.0
 |      falcon    345.0
 |      dtype: float64
 |  
 |  combine_first(self, other) -&gt; &#39;Series&#39;
 |      Update null elements with value in the same location in &#39;other&#39;.
 |      
 |      Combine two Series objects by filling null values in one Series with
 |      non-null values from the other Series. Result index will be the union
 |      of the two indexes.
 |      
 |      Parameters
 |      ----------
 |      other : Series
 |          The value(s) to be used for filling null values.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of combining the provided Series with the other object.
 |      
 |      See Also
 |      --------
 |      Series.combine : Perform element-wise operation on two Series
 |          using a given function.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s1 = pd.Series([1, np.nan])
 |      &gt;&gt;&gt; s2 = pd.Series([3, 4, 5])
 |      &gt;&gt;&gt; s1.combine_first(s2)
 |      0    1.0
 |      1    4.0
 |      2    5.0
 |      dtype: float64
 |      
 |      Null values still persist if the location of that null value
 |      does not exist in `other`
 |      
 |      &gt;&gt;&gt; s1 = pd.Series({&#39;falcon&#39;: np.nan, &#39;eagle&#39;: 160.0})
 |      &gt;&gt;&gt; s2 = pd.Series({&#39;eagle&#39;: 200.0, &#39;duck&#39;: 30.0})
 |      &gt;&gt;&gt; s1.combine_first(s2)
 |      duck       30.0
 |      eagle     160.0
 |      falcon      NaN
 |      dtype: float64
 |  
 |  compare(self, other: &#39;Series&#39;, align_axis: &#39;Axis&#39; = 1, keep_shape: &#39;bool&#39; = False, keep_equal: &#39;bool&#39; = False, result_names: &#39;Suffixes&#39; = (&#39;self&#39;, &#39;other&#39;)) -&gt; &#39;DataFrame | Series&#39;
 |      Compare to another Series and show the differences.
 |      
 |      .. versionadded:: 1.1.0
 |      
 |      Parameters
 |      ----------
 |      other : Series
 |          Object to compare with.
 |      
 |      align_axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 1
 |          Determine which axis to align the comparison on.
 |      
 |          * 0, or &#39;index&#39; : Resulting differences are stacked vertically
 |              with rows drawn alternately from self and other.
 |          * 1, or &#39;columns&#39; : Resulting differences are aligned horizontally
 |              with columns drawn alternately from self and other.
 |      
 |      keep_shape : bool, default False
 |          If true, all rows and columns are kept.
 |          Otherwise, only the ones with different values are kept.
 |      
 |      keep_equal : bool, default False
 |          If true, the result keeps values that are equal.
 |          Otherwise, equal values are shown as NaNs.
 |      
 |      result_names : tuple, default (&#39;self&#39;, &#39;other&#39;)
 |          Set the dataframes names in the comparison.
 |      
 |          .. versionadded:: 1.5.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          If axis is 0 or &#39;index&#39; the result will be a Series.
 |          The resulting index will be a MultiIndex with &#39;self&#39; and &#39;other&#39;
 |          stacked alternately at the inner level.
 |      
 |          If axis is 1 or &#39;columns&#39; the result will be a DataFrame.
 |          It will have two columns namely &#39;self&#39; and &#39;other&#39;.
 |      
 |      See Also
 |      --------
 |      DataFrame.compare : Compare with another DataFrame and show differences.
 |      
 |      Notes
 |      -----
 |      Matching NaNs will not appear as a difference.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s1 = pd.Series([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;])
 |      &gt;&gt;&gt; s2 = pd.Series([&quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;, &quot;e&quot;])
 |      
 |      Align the differences on columns
 |      
 |      &gt;&gt;&gt; s1.compare(s2)
 |        self other
 |      1    b     a
 |      3    d     b
 |      
 |      Stack the differences on indices
 |      
 |      &gt;&gt;&gt; s1.compare(s2, align_axis=0)
 |      1  self     b
 |         other    a
 |      3  self     d
 |         other    b
 |      dtype: object
 |      
 |      Keep all original rows
 |      
 |      &gt;&gt;&gt; s1.compare(s2, keep_shape=True)
 |        self other
 |      0  NaN   NaN
 |      1    b     a
 |      2  NaN   NaN
 |      3    d     b
 |      4  NaN   NaN
 |      
 |      Keep all original rows and also all original values
 |      
 |      &gt;&gt;&gt; s1.compare(s2, keep_shape=True, keep_equal=True)
 |        self other
 |      0    a     a
 |      1    b     a
 |      2    c     c
 |      3    d     b
 |      4    e     e
 |  
 |  corr(self, other: &#39;Series&#39;, method: &#39;CorrelationMethod&#39; = &#39;pearson&#39;, min_periods: &#39;int | None&#39; = None) -&gt; &#39;float&#39;
 |      Compute correlation with `other` Series, excluding missing values.
 |      
 |      The two `Series` objects are not required to be the same length and will be
 |      aligned internally before the correlation function is applied.
 |      
 |      Parameters
 |      ----------
 |      other : Series
 |          Series with which to compute the correlation.
 |      method : {&#39;pearson&#39;, &#39;kendall&#39;, &#39;spearman&#39;} or callable
 |          Method used to compute correlation:
 |      
 |          - pearson : Standard correlation coefficient
 |          - kendall : Kendall Tau correlation coefficient
 |          - spearman : Spearman rank correlation
 |          - callable: Callable with input two 1d ndarrays and returning a float.
 |      
 |          .. warning::
 |              Note that the returned matrix from corr will have 1 along the
 |              diagonals and will be symmetric regardless of the callable&#39;s
 |              behavior.
 |      min_periods : int, optional
 |          Minimum number of observations needed to have a valid result.
 |      
 |      Returns
 |      -------
 |      float
 |          Correlation with other.
 |      
 |      See Also
 |      --------
 |      DataFrame.corr : Compute pairwise correlation between columns.
 |      DataFrame.corrwith : Compute pairwise correlation with another
 |          DataFrame or Series.
 |      
 |      Notes
 |      -----
 |      Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.
 |      
 |      * `Pearson correlation coefficient &lt;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&gt;`_
 |      * `Kendall rank correlation coefficient &lt;https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient&gt;`_
 |      * `Spearman&#39;s rank correlation coefficient &lt;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&gt;`_
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; def histogram_intersection(a, b):
 |      ...     v = np.minimum(a, b).sum().round(decimals=1)
 |      ...     return v
 |      &gt;&gt;&gt; s1 = pd.Series([.2, .0, .6, .2])
 |      &gt;&gt;&gt; s2 = pd.Series([.3, .6, .0, .1])
 |      &gt;&gt;&gt; s1.corr(s2, method=histogram_intersection)
 |      0.3
 |  
 |  count(self)
 |      Return number of non-NA/null observations in the Series.
 |      
 |      Returns
 |      -------
 |      int or Series (if level specified)
 |          Number of non-null values in the Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.count : Count non-NA cells for each column or row.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([0.0, 1.0, np.nan])
 |      &gt;&gt;&gt; s.count()
 |      2
 |  
 |  cov(self, other: &#39;Series&#39;, min_periods: &#39;int | None&#39; = None, ddof: &#39;int | None&#39; = 1) -&gt; &#39;float&#39;
 |      Compute covariance with Series, excluding missing values.
 |      
 |      The two `Series` objects are not required to be the same length and
 |      will be aligned internally before the covariance is calculated.
 |      
 |      Parameters
 |      ----------
 |      other : Series
 |          Series with which to compute the covariance.
 |      min_periods : int, optional
 |          Minimum number of observations needed to have a valid result.
 |      ddof : int, default 1
 |          Delta degrees of freedom.  The divisor used in calculations
 |          is ``N - ddof``, where ``N`` represents the number of elements.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      float
 |          Covariance between Series and other normalized by N-1
 |          (unbiased estimator).
 |      
 |      See Also
 |      --------
 |      DataFrame.cov : Compute pairwise covariance of columns.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])
 |      &gt;&gt;&gt; s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])
 |      &gt;&gt;&gt; s1.cov(s2)
 |      -0.01685762652715874
 |  
 |  cummax(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, *args, **kwargs)
 |      Return cumulative maximum over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      maximum.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      scalar or Series
 |          Return cumulative maximum of scalar or Series.
 |      
 |      See Also
 |      --------
 |      core.window.expanding.Expanding.max : Similar functionality
 |          but ignores ``NaN`` values.
 |      Series.max : Return the maximum over
 |          Series axis.
 |      Series.cummax : Return cumulative maximum over Series axis.
 |      Series.cummin : Return cumulative minimum over Series axis.
 |      Series.cumsum : Return cumulative sum over Series axis.
 |      Series.cumprod : Return cumulative product over Series axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cummax()
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3    5.0
 |      4    5.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cummax(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                   columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the maximum
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cummax()
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  3.0  1.0
 |      
 |      To iterate over columns and find the maximum in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cummax(axis=1)
 |           A    B
 |      0  2.0  2.0
 |      1  3.0  NaN
 |      2  1.0  1.0
 |  
 |  cummin(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, *args, **kwargs)
 |      Return cumulative minimum over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      minimum.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      scalar or Series
 |          Return cumulative minimum of scalar or Series.
 |      
 |      See Also
 |      --------
 |      core.window.expanding.Expanding.min : Similar functionality
 |          but ignores ``NaN`` values.
 |      Series.min : Return the minimum over
 |          Series axis.
 |      Series.cummax : Return cumulative maximum over Series axis.
 |      Series.cummin : Return cumulative minimum over Series axis.
 |      Series.cumsum : Return cumulative sum over Series axis.
 |      Series.cumprod : Return cumulative product over Series axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cummin()
 |      0    2.0
 |      1    NaN
 |      2    2.0
 |      3   -1.0
 |      4   -1.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cummin(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                   columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the minimum
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cummin()
 |           A    B
 |      0  2.0  1.0
 |      1  2.0  NaN
 |      2  1.0  0.0
 |      
 |      To iterate over columns and find the minimum in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cummin(axis=1)
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |  
 |  cumprod(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, *args, **kwargs)
 |      Return cumulative product over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      product.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      scalar or Series
 |          Return cumulative product of scalar or Series.
 |      
 |      See Also
 |      --------
 |      core.window.expanding.Expanding.prod : Similar functionality
 |          but ignores ``NaN`` values.
 |      Series.prod : Return the product over
 |          Series axis.
 |      Series.cummax : Return cumulative maximum over Series axis.
 |      Series.cummin : Return cumulative minimum over Series axis.
 |      Series.cumsum : Return cumulative sum over Series axis.
 |      Series.cumprod : Return cumulative product over Series axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cumprod()
 |      0     2.0
 |      1     NaN
 |      2    10.0
 |      3   -10.0
 |      4    -0.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cumprod(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                   columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the product
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cumprod()
 |           A    B
 |      0  2.0  1.0
 |      1  6.0  NaN
 |      2  6.0  0.0
 |      
 |      To iterate over columns and find the product in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cumprod(axis=1)
 |           A    B
 |      0  2.0  2.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |  
 |  cumsum(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, *args, **kwargs)
 |      Return cumulative sum over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      sum.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      scalar or Series
 |          Return cumulative sum of scalar or Series.
 |      
 |      See Also
 |      --------
 |      core.window.expanding.Expanding.sum : Similar functionality
 |          but ignores ``NaN`` values.
 |      Series.sum : Return the sum over
 |          Series axis.
 |      Series.cummax : Return cumulative maximum over Series axis.
 |      Series.cummin : Return cumulative minimum over Series axis.
 |      Series.cumsum : Return cumulative sum over Series axis.
 |      Series.cumprod : Return cumulative product over Series axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cumsum()
 |      0    2.0
 |      1    NaN
 |      2    7.0
 |      3    6.0
 |      4    6.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cumsum(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                   columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the sum
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cumsum()
 |           A    B
 |      0  2.0  1.0
 |      1  5.0  NaN
 |      2  6.0  1.0
 |      
 |      To iterate over columns and find the sum in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cumsum(axis=1)
 |           A    B
 |      0  2.0  3.0
 |      1  3.0  NaN
 |      2  1.0  1.0
 |  
 |  diff(self, periods: &#39;int&#39; = 1) -&gt; &#39;Series&#39;
 |      First discrete difference of element.
 |      
 |      Calculates the difference of a Series element compared with another
 |      element in the Series (default is element in previous row).
 |      
 |      Parameters
 |      ----------
 |      periods : int, default 1
 |          Periods to shift for calculating difference, accepts negative
 |          values.
 |      
 |      Returns
 |      -------
 |      Series
 |          First differences of the Series.
 |      
 |      See Also
 |      --------
 |      Series.pct_change: Percent change over given number of periods.
 |      Series.shift: Shift index by desired number of periods with an
 |          optional time freq.
 |      DataFrame.diff: First discrete difference of object.
 |      
 |      Notes
 |      -----
 |      For boolean dtypes, this uses :meth:`operator.xor` rather than
 |      :meth:`operator.sub`.
 |      The result is calculated according to current dtype in Series,
 |      however dtype of the result is always float64.
 |      
 |      Examples
 |      --------
 |      
 |      Difference with previous row
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 1, 2, 3, 5, 8])
 |      &gt;&gt;&gt; s.diff()
 |      0    NaN
 |      1    0.0
 |      2    1.0
 |      3    1.0
 |      4    2.0
 |      5    3.0
 |      dtype: float64
 |      
 |      Difference with 3rd previous row
 |      
 |      &gt;&gt;&gt; s.diff(periods=3)
 |      0    NaN
 |      1    NaN
 |      2    NaN
 |      3    2.0
 |      4    4.0
 |      5    6.0
 |      dtype: float64
 |      
 |      Difference with following row
 |      
 |      &gt;&gt;&gt; s.diff(periods=-1)
 |      0    0.0
 |      1   -1.0
 |      2   -1.0
 |      3   -2.0
 |      4   -3.0
 |      5    NaN
 |      dtype: float64
 |      
 |      Overflow in input dtype
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 0], dtype=np.uint8)
 |      &gt;&gt;&gt; s.diff()
 |      0      NaN
 |      1    255.0
 |      dtype: float64
 |  
 |  div = truediv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |  
 |  divide = truediv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |  
 |  divmod(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Integer division and modulo of series and other, element-wise (binary operator `divmod`).
 |      
 |      Equivalent to ``divmod(series, other)``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      2-Tuple of Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rdivmod : Reverse of the Integer division and modulo operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.divmod(b, fill_value=0)
 |      (a    1.0
 |       b    NaN
 |       c    NaN
 |       d    0.0
 |       e    NaN
 |       dtype: float64,
 |       a    0.0
 |       b    NaN
 |       c    NaN
 |       d    0.0
 |       e    NaN
 |       dtype: float64)
 |  
 |  dot(self, other: &#39;AnyArrayLike&#39;) -&gt; &#39;Series | np.ndarray&#39;
 |      Compute the dot product between the Series and the columns of other.
 |      
 |      This method computes the dot product between the Series and another
 |      one, or the Series and each columns of a DataFrame, or the Series and
 |      each columns of an array.
 |      
 |      It can also be called using `self @ other` in Python &gt;= 3.5.
 |      
 |      Parameters
 |      ----------
 |      other : Series, DataFrame or array-like
 |          The other object to compute the dot product with its columns.
 |      
 |      Returns
 |      -------
 |      scalar, Series or numpy.ndarray
 |          Return the dot product of the Series and other if other is a
 |          Series, the Series of the dot product of Series and each rows of
 |          other if other is a DataFrame or a numpy.ndarray between the Series
 |          and each columns of the numpy array.
 |      
 |      See Also
 |      --------
 |      DataFrame.dot: Compute the matrix product with the DataFrame.
 |      Series.mul: Multiplication of series and other, element-wise.
 |      
 |      Notes
 |      -----
 |      The Series and other has to share the same index if other is a Series
 |      or a DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([0, 1, 2, 3])
 |      &gt;&gt;&gt; other = pd.Series([-1, 2, -3, 4])
 |      &gt;&gt;&gt; s.dot(other)
 |      8
 |      &gt;&gt;&gt; s @ other
 |      8
 |      &gt;&gt;&gt; df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])
 |      &gt;&gt;&gt; s.dot(df)
 |      0    24
 |      1    14
 |      dtype: int64
 |      &gt;&gt;&gt; arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])
 |      &gt;&gt;&gt; s.dot(arr)
 |      array([24, 14])
 |  
 |  drop(self, labels: &#39;IndexLabel&#39; = None, *, axis: &#39;Axis&#39; = 0, index: &#39;IndexLabel&#39; = None, columns: &#39;IndexLabel&#39; = None, level: &#39;Level | None&#39; = None, inplace: &#39;bool&#39; = False, errors: &#39;IgnoreRaise&#39; = &#39;raise&#39;) -&gt; &#39;Series | None&#39;
 |      Return Series with specified index labels removed.
 |      
 |      Remove elements of a Series based on specifying the index labels.
 |      When using a multi-index, labels on different levels can be removed
 |      by specifying the level.
 |      
 |      Parameters
 |      ----------
 |      labels : single label or list-like
 |          Index labels to drop.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      index : single label or list-like
 |          Redundant for application on Series, but &#39;index&#39; can be used instead
 |          of &#39;labels&#39;.
 |      columns : single label or list-like
 |          No change is made to the Series; use &#39;index&#39; or &#39;labels&#39; instead.
 |      level : int or level name, optional
 |          For MultiIndex, level for which the labels will be removed.
 |      inplace : bool, default False
 |          If True, do operation inplace and return None.
 |      errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
 |          If &#39;ignore&#39;, suppress error and only existing labels are dropped.
 |      
 |      Returns
 |      -------
 |      Series or None
 |          Series with specified index labels removed or None if ``inplace=True``.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          If none of the labels are found in the index.
 |      
 |      See Also
 |      --------
 |      Series.reindex : Return only specified index labels of Series.
 |      Series.dropna : Return series without null values.
 |      Series.drop_duplicates : Return Series with duplicate values removed.
 |      DataFrame.drop : Drop specified labels from rows or columns.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(data=np.arange(3), index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; s
 |      A  0
 |      B  1
 |      C  2
 |      dtype: int64
 |      
 |      Drop labels B en C
 |      
 |      &gt;&gt;&gt; s.drop(labels=[&#39;B&#39;, &#39;C&#39;])
 |      A  0
 |      dtype: int64
 |      
 |      Drop 2nd level label in MultiIndex Series
 |      
 |      &gt;&gt;&gt; midx = pd.MultiIndex(levels=[[&#39;lama&#39;, &#39;cow&#39;, &#39;falcon&#39;],
 |      ...                              [&#39;speed&#39;, &#39;weight&#39;, &#39;length&#39;]],
 |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
 |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])
 |      &gt;&gt;&gt; s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],
 |      ...               index=midx)
 |      &gt;&gt;&gt; s
 |      lama    speed      45.0
 |              weight    200.0
 |              length      1.2
 |      cow     speed      30.0
 |              weight    250.0
 |              length      1.5
 |      falcon  speed     320.0
 |              weight      1.0
 |              length      0.3
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.drop(labels=&#39;weight&#39;, level=1)
 |      lama    speed      45.0
 |              length      1.2
 |      cow     speed      30.0
 |              length      1.5
 |      falcon  speed     320.0
 |              length      0.3
 |      dtype: float64
 |  
 |  drop_duplicates(self, *, keep: &#39;DropKeep&#39; = &#39;first&#39;, inplace: &#39;bool&#39; = False, ignore_index: &#39;bool&#39; = False) -&gt; &#39;Series | None&#39;
 |      Return Series with duplicate values removed.
 |      
 |      Parameters
 |      ----------
 |      keep : {&#39;first&#39;, &#39;last&#39;, ``False``}, default &#39;first&#39;
 |          Method to handle dropping duplicates:
 |      
 |          - &#39;first&#39; : Drop duplicates except for the first occurrence.
 |          - &#39;last&#39; : Drop duplicates except for the last occurrence.
 |          - ``False`` : Drop all duplicates.
 |      
 |      inplace : bool, default ``False``
 |          If ``True``, performs operation inplace and returns None.
 |      
 |      ignore_index : bool, default ``False``
 |          If ``True``, the resulting axis will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      Returns
 |      -------
 |      Series or None
 |          Series with duplicates dropped or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Index.drop_duplicates : Equivalent method on Index.
 |      DataFrame.drop_duplicates : Equivalent method on DataFrame.
 |      Series.duplicated : Related method on Series, indicating duplicate
 |          Series values.
 |      Series.unique : Return unique values as an array.
 |      
 |      Examples
 |      --------
 |      Generate a Series with duplicated entries.
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;lama&#39;, &#39;cow&#39;, &#39;lama&#39;, &#39;beetle&#39;, &#39;lama&#39;, &#39;hippo&#39;],
 |      ...               name=&#39;animal&#39;)
 |      &gt;&gt;&gt; s
 |      0      lama
 |      1       cow
 |      2      lama
 |      3    beetle
 |      4      lama
 |      5     hippo
 |      Name: animal, dtype: object
 |      
 |      With the &#39;keep&#39; parameter, the selection behaviour of duplicated values
 |      can be changed. The value &#39;first&#39; keeps the first occurrence for each
 |      set of duplicated entries. The default value of keep is &#39;first&#39;.
 |      
 |      &gt;&gt;&gt; s.drop_duplicates()
 |      0      lama
 |      1       cow
 |      3    beetle
 |      5     hippo
 |      Name: animal, dtype: object
 |      
 |      The value &#39;last&#39; for parameter &#39;keep&#39; keeps the last occurrence for
 |      each set of duplicated entries.
 |      
 |      &gt;&gt;&gt; s.drop_duplicates(keep=&#39;last&#39;)
 |      1       cow
 |      3    beetle
 |      4      lama
 |      5     hippo
 |      Name: animal, dtype: object
 |      
 |      The value ``False`` for parameter &#39;keep&#39; discards all sets of
 |      duplicated entries.
 |      
 |      &gt;&gt;&gt; s.drop_duplicates(keep=False)
 |      1       cow
 |      3    beetle
 |      5     hippo
 |      Name: animal, dtype: object
 |  
 |  dropna(self, *, axis: &#39;Axis&#39; = 0, inplace: &#39;bool&#39; = False, how: &#39;AnyAll | None&#39; = None, ignore_index: &#39;bool&#39; = False) -&gt; &#39;Series | None&#39;
 |      Return a new Series with missing values removed.
 |      
 |      See the :ref:`User Guide &lt;missing_data&gt;` for more on which values are
 |      considered missing, and how to work with missing data.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      inplace : bool, default False
 |          If True, do operation inplace and return None.
 |      how : str, optional
 |          Not in use. Kept for compatibility.
 |      ignore_index : bool, default ``False``
 |          If ``True``, the resulting axis will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      Returns
 |      -------
 |      Series or None
 |          Series with NA entries dropped from it or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.isna: Indicate missing values.
 |      Series.notna : Indicate existing (non-missing) values.
 |      Series.fillna : Replace missing values.
 |      DataFrame.dropna : Drop rows or columns which contain NA values.
 |      Index.dropna : Drop missing indices.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; ser = pd.Series([1., 2., np.nan])
 |      &gt;&gt;&gt; ser
 |      0    1.0
 |      1    2.0
 |      2    NaN
 |      dtype: float64
 |      
 |      Drop NA values from a Series.
 |      
 |      &gt;&gt;&gt; ser.dropna()
 |      0    1.0
 |      1    2.0
 |      dtype: float64
 |      
 |      Empty strings are not considered NA values. ``None`` is considered an
 |      NA value.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([np.NaN, 2, pd.NaT, &#39;&#39;, None, &#39;I stay&#39;])
 |      &gt;&gt;&gt; ser
 |      0       NaN
 |      1         2
 |      2       NaT
 |      3
 |      4      None
 |      5    I stay
 |      dtype: object
 |      &gt;&gt;&gt; ser.dropna()
 |      1         2
 |      3
 |      5    I stay
 |      dtype: object
 |  
 |  duplicated(self, keep: &#39;DropKeep&#39; = &#39;first&#39;) -&gt; &#39;Series&#39;
 |      Indicate duplicate Series values.
 |      
 |      Duplicated values are indicated as ``True`` values in the resulting
 |      Series. Either all duplicates, all except the first or all except the
 |      last occurrence of duplicates can be indicated.
 |      
 |      Parameters
 |      ----------
 |      keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
 |          Method to handle dropping duplicates:
 |      
 |          - &#39;first&#39; : Mark duplicates as ``True`` except for the first
 |            occurrence.
 |          - &#39;last&#39; : Mark duplicates as ``True`` except for the last
 |            occurrence.
 |          - ``False`` : Mark all duplicates as ``True``.
 |      
 |      Returns
 |      -------
 |      Series[bool]
 |          Series indicating whether each value has occurred in the
 |          preceding values.
 |      
 |      See Also
 |      --------
 |      Index.duplicated : Equivalent method on pandas.Index.
 |      DataFrame.duplicated : Equivalent method on pandas.DataFrame.
 |      Series.drop_duplicates : Remove duplicate values from Series.
 |      
 |      Examples
 |      --------
 |      By default, for each set of duplicated values, the first occurrence is
 |      set on False and all others on True:
 |      
 |      &gt;&gt;&gt; animals = pd.Series([&#39;lama&#39;, &#39;cow&#39;, &#39;lama&#39;, &#39;beetle&#39;, &#39;lama&#39;])
 |      &gt;&gt;&gt; animals.duplicated()
 |      0    False
 |      1    False
 |      2     True
 |      3    False
 |      4     True
 |      dtype: bool
 |      
 |      which is equivalent to
 |      
 |      &gt;&gt;&gt; animals.duplicated(keep=&#39;first&#39;)
 |      0    False
 |      1    False
 |      2     True
 |      3    False
 |      4     True
 |      dtype: bool
 |      
 |      By using &#39;last&#39;, the last occurrence of each set of duplicated values
 |      is set on False and all others on True:
 |      
 |      &gt;&gt;&gt; animals.duplicated(keep=&#39;last&#39;)
 |      0     True
 |      1    False
 |      2     True
 |      3    False
 |      4    False
 |      dtype: bool
 |      
 |      By setting keep on ``False``, all duplicates are True:
 |      
 |      &gt;&gt;&gt; animals.duplicated(keep=False)
 |      0     True
 |      1    False
 |      2     True
 |      3    False
 |      4     True
 |      dtype: bool
 |  
 |  eq(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Equal to of series and other, element-wise (binary operator `eq`).
 |      
 |      Equivalent to ``series == other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.eq(b, fill_value=0)
 |      a     True
 |      b    False
 |      c    False
 |      d    False
 |      e    False
 |      dtype: bool
 |  
 |  explode(self, ignore_index: &#39;bool&#39; = False) -&gt; &#39;Series&#39;
 |      Transform each element of a list-like to a row.
 |      
 |      Parameters
 |      ----------
 |      ignore_index : bool, default False
 |          If True, the resulting index will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      Series
 |          Exploded lists to rows; index will be duplicated for these rows.
 |      
 |      See Also
 |      --------
 |      Series.str.split : Split string values on specified separator.
 |      Series.unstack : Unstack, a.k.a. pivot, Series with MultiIndex
 |          to produce DataFrame.
 |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.
 |      DataFrame.explode : Explode a DataFrame from list-like
 |          columns to long format.
 |      
 |      Notes
 |      -----
 |      This routine will explode list-likes including lists, tuples, sets,
 |      Series, and np.ndarray. The result dtype of the subset rows will
 |      be object. Scalars will be returned unchanged, and empty list-likes will
 |      result in a np.nan for that row. In addition, the ordering of elements in
 |      the output will be non-deterministic when exploding sets.
 |      
 |      Reference :ref:`the user guide &lt;reshaping.explode&gt;` for more examples.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([[1, 2, 3], &#39;foo&#39;, [], [3, 4]])
 |      &gt;&gt;&gt; s
 |      0    [1, 2, 3]
 |      1          foo
 |      2           []
 |      3       [3, 4]
 |      dtype: object
 |      
 |      &gt;&gt;&gt; s.explode()
 |      0      1
 |      0      2
 |      0      3
 |      1    foo
 |      2    NaN
 |      3      3
 |      3      4
 |      dtype: object
 |  
 |  ffill(self, *, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool&#39; = False, limit: &#39;None | int&#39; = None, downcast: &#39;dict | None&#39; = None) -&gt; &#39;Series | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;ffill&#39;``.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  fillna(self, value: &#39;Hashable | Mapping | Series | DataFrame&#39; = None, *, method: &#39;FillnaOptions | None&#39; = None, axis: &#39;Axis | None&#39; = None, inplace: &#39;bool&#39; = False, limit: &#39;int | None&#39; = None, downcast: &#39;dict | None&#39; = None) -&gt; &#39;Series | None&#39;
 |      Fill NA/NaN values using the specified method.
 |      
 |      Parameters
 |      ----------
 |      value : scalar, dict, Series, or DataFrame
 |          Value to use to fill holes (e.g. 0), alternately a
 |          dict/Series/DataFrame of values specifying which value to use for
 |          each index (for a Series) or column (for a DataFrame).  Values not
 |          in the dict/Series/DataFrame will not be filled. This value cannot
 |          be a list.
 |      method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;ffill&#39;, None}, default None
 |          Method to use for filling holes in reindexed Series:
 |      
 |          * ffill: propagate last valid observation forward to next valid.
 |          * backfill / bfill: use next valid observation to fill gap.
 |      
 |      axis : {0 or &#39;index&#39;}
 |          Axis along which to fill missing values. For `Series`
 |          this parameter is unused and defaults to 0.
 |      inplace : bool, default False
 |          If True, fill in-place. Note: this will modify any
 |          other views on this object (e.g., a no-copy slice for a column in a
 |          DataFrame).
 |      limit : int, default None
 |          If method is specified, this is the maximum number of consecutive
 |          NaN values to forward/backward fill. In other words, if there is
 |          a gap with more than this number of consecutive NaNs, it will only
 |          be partially filled. If method is not specified, this is the
 |          maximum number of entries along the entire axis where NaNs will be
 |          filled. Must be greater than 0 if not None.
 |      downcast : dict, default is None
 |          A dict of item-&gt;dtype of what to downcast if possible,
 |          or the string &#39;infer&#39; which will try to downcast to an appropriate
 |          equal type (e.g. float64 to int64 if possible).
 |      
 |      Returns
 |      -------
 |      Series or None
 |          Object with missing values filled or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      interpolate : Fill NaN values using interpolation.
 |      reindex : Conform object to new index.
 |      asfreq : Convert TimeSeries to specified frequency.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[np.nan, 2, np.nan, 0],
 |      ...                    [3, 4, np.nan, 1],
 |      ...                    [np.nan, np.nan, np.nan, np.nan],
 |      ...                    [np.nan, 3, np.nan, 4]],
 |      ...                   columns=list(&quot;ABCD&quot;))
 |      &gt;&gt;&gt; df
 |           A    B   C    D
 |      0  NaN  2.0 NaN  0.0
 |      1  3.0  4.0 NaN  1.0
 |      2  NaN  NaN NaN  NaN
 |      3  NaN  3.0 NaN  4.0
 |      
 |      Replace all NaN elements with 0s.
 |      
 |      &gt;&gt;&gt; df.fillna(0)
 |           A    B    C    D
 |      0  0.0  2.0  0.0  0.0
 |      1  3.0  4.0  0.0  1.0
 |      2  0.0  0.0  0.0  0.0
 |      3  0.0  3.0  0.0  4.0
 |      
 |      We can also propagate non-null values forward or backward.
 |      
 |      &gt;&gt;&gt; df.fillna(method=&quot;ffill&quot;)
 |           A    B   C    D
 |      0  NaN  2.0 NaN  0.0
 |      1  3.0  4.0 NaN  1.0
 |      2  3.0  4.0 NaN  1.0
 |      3  3.0  3.0 NaN  4.0
 |      
 |      Replace all NaN elements in column &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, and &#39;D&#39;, with 0, 1,
 |      2, and 3 respectively.
 |      
 |      &gt;&gt;&gt; values = {&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;C&quot;: 2, &quot;D&quot;: 3}
 |      &gt;&gt;&gt; df.fillna(value=values)
 |           A    B    C    D
 |      0  0.0  2.0  2.0  0.0
 |      1  3.0  4.0  2.0  1.0
 |      2  0.0  1.0  2.0  3.0
 |      3  0.0  3.0  2.0  4.0
 |      
 |      Only replace the first NaN element.
 |      
 |      &gt;&gt;&gt; df.fillna(value=values, limit=1)
 |           A    B    C    D
 |      0  0.0  2.0  2.0  0.0
 |      1  3.0  4.0  NaN  1.0
 |      2  NaN  1.0  NaN  3.0
 |      3  NaN  3.0  NaN  4.0
 |      
 |      When filling using a DataFrame, replacement happens along
 |      the same column names and same indices
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(&quot;ABCE&quot;))
 |      &gt;&gt;&gt; df.fillna(df2)
 |           A    B    C    D
 |      0  0.0  2.0  0.0  0.0
 |      1  3.0  4.0  0.0  1.0
 |      2  0.0  0.0  0.0  NaN
 |      3  0.0  3.0  0.0  4.0
 |      
 |      Note that column D is not affected since it is not present in df2.
 |  
 |  floordiv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Integer division of series and other, element-wise (binary operator `floordiv`).
 |      
 |      Equivalent to ``series // other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rfloordiv : Reverse of the Integer division operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.floordiv(b, fill_value=0)
 |      a    1.0
 |      b    inf
 |      c    inf
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  ge(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Greater than or equal to of series and other, element-wise (binary operator `ge`).
 |      
 |      Equivalent to ``series &gt;= other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      e    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([0, 1, 2, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;f&#39;])
 |      &gt;&gt;&gt; b
 |      a    0.0
 |      b    1.0
 |      c    2.0
 |      d    NaN
 |      f    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; a.ge(b, fill_value=0)
 |      a     True
 |      b     True
 |      c    False
 |      d    False
 |      e     True
 |      f    False
 |      dtype: bool
 |  
 |  groupby(self, by=None, axis: &#39;Axis&#39; = 0, level: &#39;IndexLabel&#39; = None, as_index: &#39;bool&#39; = True, sort: &#39;bool&#39; = True, group_keys: &#39;bool&#39; = True, observed: &#39;bool&#39; = False, dropna: &#39;bool&#39; = True) -&gt; &#39;SeriesGroupBy&#39;
 |      Group Series using a mapper or by a Series of columns.
 |      
 |      A groupby operation involves some combination of splitting the
 |      object, applying a function, and combining the results. This can be
 |      used to group large amounts of data and compute operations on these
 |      groups.
 |      
 |      Parameters
 |      ----------
 |      by : mapping, function, label, pd.Grouper or list of such
 |          Used to determine the groups for the groupby.
 |          If ``by`` is a function, it&#39;s called on each value of the object&#39;s
 |          index. If a dict or Series is passed, the Series or dict VALUES
 |          will be used to determine the groups (the Series&#39; values are first
 |          aligned; see ``.align()`` method). If a list or ndarray of length
 |          equal to the selected axis is passed (see the `groupby user guide
 |          &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups&gt;`_),
 |          the values are used as-is to determine the groups. A label or list
 |          of labels may be passed to group by the columns in ``self``.
 |          Notice that a tuple is interpreted as a (single) key.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Split along rows (0) or columns (1). For `Series` this parameter
 |          is unused and defaults to 0.
 |      level : int, level name, or sequence of such, default None
 |          If the axis is a MultiIndex (hierarchical), group by a particular
 |          level or levels. Do not specify both ``by`` and ``level``.
 |      as_index : bool, default True
 |          For aggregated output, return object with group labels as the
 |          index. Only relevant for DataFrame input. as_index=False is
 |          effectively &quot;SQL-style&quot; grouped output.
 |      sort : bool, default True
 |          Sort group keys. Get better performance by turning this off.
 |          Note this does not influence the order of observations within each
 |          group. Groupby preserves the order of rows within each group.
 |      
 |          .. versionchanged:: 2.0.0
 |      
 |              Specifying ``sort=False`` with an ordered categorical grouper will no
 |              longer sort the values.
 |      
 |      group_keys : bool, default True
 |          When calling apply and the ``by`` argument produces a like-indexed
 |          (i.e. :ref:`a transform &lt;groupby.transform&gt;`) result, add group keys to
 |          index to identify pieces. By default group keys are not included
 |          when the result&#39;s index (and column) labels match the inputs, and
 |          are included otherwise.
 |      
 |          .. versionchanged:: 1.5.0
 |      
 |             Warns that ``group_keys`` will no longer be ignored when the
 |             result from ``apply`` is a like-indexed Series or DataFrame.
 |             Specify ``group_keys`` explicitly to include the group keys or
 |             not.
 |      
 |          .. versionchanged:: 2.0.0
 |      
 |             ``group_keys`` now defaults to ``True``.
 |      
 |      observed : bool, default False
 |          This only applies if any of the groupers are Categoricals.
 |          If True: only show observed values for categorical groupers.
 |          If False: show all values for categorical groupers.
 |      dropna : bool, default True
 |          If True, and if group keys contain NA values, NA values together
 |          with row/column will be dropped.
 |          If False, NA values will also be treated as the key in groups.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      SeriesGroupBy
 |          Returns a groupby object that contains information about the groups.
 |      
 |      See Also
 |      --------
 |      resample : Convenience method for frequency conversion and resampling
 |          of time series.
 |      
 |      Notes
 |      -----
 |      See the `user guide
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/groupby.html&gt;`__ for more
 |      detailed usage and examples, including splitting an object into groups,
 |      iterating through groups, selecting a group, aggregation, and more.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; ser = pd.Series([390., 350., 30., 20.],
 |      ...                 index=[&#39;Falcon&#39;, &#39;Falcon&#39;, &#39;Parrot&#39;, &#39;Parrot&#39;], name=&quot;Max Speed&quot;)
 |      &gt;&gt;&gt; ser
 |      Falcon    390.0
 |      Falcon    350.0
 |      Parrot     30.0
 |      Parrot     20.0
 |      Name: Max Speed, dtype: float64
 |      &gt;&gt;&gt; ser.groupby([&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;]).mean()
 |      a    210.0
 |      b    185.0
 |      Name: Max Speed, dtype: float64
 |      &gt;&gt;&gt; ser.groupby(level=0).mean()
 |      Falcon    370.0
 |      Parrot     25.0
 |      Name: Max Speed, dtype: float64
 |      &gt;&gt;&gt; ser.groupby(ser &gt; 100).mean()
 |      Max Speed
 |      False     25.0
 |      True     370.0
 |      Name: Max Speed, dtype: float64
 |      
 |      **Grouping by Indexes**
 |      
 |      We can groupby different levels of a hierarchical index
 |      using the `level` parameter:
 |      
 |      &gt;&gt;&gt; arrays = [[&#39;Falcon&#39;, &#39;Falcon&#39;, &#39;Parrot&#39;, &#39;Parrot&#39;],
 |      ...           [&#39;Captive&#39;, &#39;Wild&#39;, &#39;Captive&#39;, &#39;Wild&#39;]]
 |      &gt;&gt;&gt; index = pd.MultiIndex.from_arrays(arrays, names=(&#39;Animal&#39;, &#39;Type&#39;))
 |      &gt;&gt;&gt; ser = pd.Series([390., 350., 30., 20.], index=index, name=&quot;Max Speed&quot;)
 |      &gt;&gt;&gt; ser
 |      Animal  Type
 |      Falcon  Captive    390.0
 |              Wild       350.0
 |      Parrot  Captive     30.0
 |              Wild        20.0
 |      Name: Max Speed, dtype: float64
 |      &gt;&gt;&gt; ser.groupby(level=0).mean()
 |      Animal
 |      Falcon    370.0
 |      Parrot     25.0
 |      Name: Max Speed, dtype: float64
 |      &gt;&gt;&gt; ser.groupby(level=&quot;Type&quot;).mean()
 |      Type
 |      Captive    210.0
 |      Wild       185.0
 |      Name: Max Speed, dtype: float64
 |      
 |      We can also choose to include `NA` in group keys or not by defining
 |      `dropna` parameter, the default setting is `True`.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([1, 2, 3, 3], index=[&quot;a&quot;, &#39;a&#39;, &#39;b&#39;, np.nan])
 |      &gt;&gt;&gt; ser.groupby(level=0).sum()
 |      a    3
 |      b    3
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; ser.groupby(level=0, dropna=False).sum()
 |      a    3
 |      b    3
 |      NaN  3
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; arrays = [&#39;Falcon&#39;, &#39;Falcon&#39;, &#39;Parrot&#39;, &#39;Parrot&#39;]
 |      &gt;&gt;&gt; ser = pd.Series([390., 350., 30., 20.], index=arrays, name=&quot;Max Speed&quot;)
 |      &gt;&gt;&gt; ser.groupby([&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, np.nan]).mean()
 |      a    210.0
 |      b    350.0
 |      Name: Max Speed, dtype: float64
 |      
 |      &gt;&gt;&gt; ser.groupby([&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, np.nan], dropna=False).mean()
 |      a    210.0
 |      b    350.0
 |      NaN   20.0
 |      Name: Max Speed, dtype: float64
 |  
 |  gt(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Greater than of series and other, element-wise (binary operator `gt`).
 |      
 |      Equivalent to ``series &gt; other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      e    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([0, 1, 2, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;f&#39;])
 |      &gt;&gt;&gt; b
 |      a    0.0
 |      b    1.0
 |      c    2.0
 |      d    NaN
 |      f    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; a.gt(b, fill_value=0)
 |      a     True
 |      b    False
 |      c    False
 |      d    False
 |      e     True
 |      f    False
 |      dtype: bool
 |  
 |  hist = hist_series(self, by=None, ax=None, grid: &#39;bool&#39; = True, xlabelsize: &#39;int | None&#39; = None, xrot: &#39;float | None&#39; = None, ylabelsize: &#39;int | None&#39; = None, yrot: &#39;float | None&#39; = None, figsize: &#39;tuple[int, int] | None&#39; = None, bins: &#39;int | Sequence[int]&#39; = 10, backend: &#39;str | None&#39; = None, legend: &#39;bool&#39; = False, **kwargs)
 |      Draw histogram of the input series using matplotlib.
 |      
 |      Parameters
 |      ----------
 |      by : object, optional
 |          If passed, then used to form histograms for separate groups.
 |      ax : matplotlib axis object
 |          If not passed, uses gca().
 |      grid : bool, default True
 |          Whether to show axis grid lines.
 |      xlabelsize : int, default None
 |          If specified changes the x-axis label size.
 |      xrot : float, default None
 |          Rotation of x axis labels.
 |      ylabelsize : int, default None
 |          If specified changes the y-axis label size.
 |      yrot : float, default None
 |          Rotation of y axis labels.
 |      figsize : tuple, default None
 |          Figure size in inches by default.
 |      bins : int or sequence, default 10
 |          Number of histogram bins to be used. If an integer is given, bins + 1
 |          bin edges are calculated and returned. If bins is a sequence, gives
 |          bin edges, including left edge of first bin and right edge of last
 |          bin. In this case, bins is returned unmodified.
 |      backend : str, default None
 |          Backend to use instead of the backend specified in the option
 |          ``plotting.backend``. For instance, &#39;matplotlib&#39;. Alternatively, to
 |          specify the ``plotting.backend`` for the whole session, set
 |          ``pd.options.plotting.backend``.
 |      legend : bool, default False
 |          Whether to show the legend.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      **kwargs
 |          To be passed to the actual plotting function.
 |      
 |      Returns
 |      -------
 |      matplotlib.AxesSubplot
 |          A histogram plot.
 |      
 |      See Also
 |      --------
 |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.
 |  
 |  idxmax(self, axis: &#39;Axis&#39; = 0, skipna: &#39;bool&#39; = True, *args, **kwargs) -&gt; &#39;Hashable&#39;
 |      Return the row label of the maximum value.
 |      
 |      If multiple values equal the maximum, the first row label with that
 |      value is returned.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      skipna : bool, default True
 |          Exclude NA/null values. If the entire Series is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional arguments and keywords have no effect but might be
 |          accepted for compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Index
 |          Label of the maximum value.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          If the Series is empty.
 |      
 |      See Also
 |      --------
 |      numpy.argmax : Return indices of the maximum values
 |          along the given axis.
 |      DataFrame.idxmax : Return index of first occurrence of maximum
 |          over requested axis.
 |      Series.idxmin : Return index *label* of the first occurrence
 |          of minimum of values.
 |      
 |      Notes
 |      -----
 |      This method is the Series version of ``ndarray.argmax``. This method
 |      returns the label of the maximum, while ``ndarray.argmax`` returns
 |      the position. To get the position, use ``series.values.argmax()``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(data=[1, None, 4, 3, 4],
 |      ...               index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;])
 |      &gt;&gt;&gt; s
 |      A    1.0
 |      B    NaN
 |      C    4.0
 |      D    3.0
 |      E    4.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.idxmax()
 |      &#39;C&#39;
 |      
 |      If `skipna` is False and there is an NA value in the data,
 |      the function returns ``nan``.
 |      
 |      &gt;&gt;&gt; s.idxmax(skipna=False)
 |      nan
 |  
 |  idxmin(self, axis: &#39;Axis&#39; = 0, skipna: &#39;bool&#39; = True, *args, **kwargs) -&gt; &#39;Hashable&#39;
 |      Return the row label of the minimum value.
 |      
 |      If multiple values equal the minimum, the first row label with that
 |      value is returned.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      skipna : bool, default True
 |          Exclude NA/null values. If the entire Series is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional arguments and keywords have no effect but might be
 |          accepted for compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Index
 |          Label of the minimum value.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          If the Series is empty.
 |      
 |      See Also
 |      --------
 |      numpy.argmin : Return indices of the minimum values
 |          along the given axis.
 |      DataFrame.idxmin : Return index of first occurrence of minimum
 |          over requested axis.
 |      Series.idxmax : Return index *label* of the first occurrence
 |          of maximum of values.
 |      
 |      Notes
 |      -----
 |      This method is the Series version of ``ndarray.argmin``. This method
 |      returns the label of the minimum, while ``ndarray.argmin`` returns
 |      the position. To get the position, use ``series.values.argmin()``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(data=[1, None, 4, 1],
 |      ...               index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; s
 |      A    1.0
 |      B    NaN
 |      C    4.0
 |      D    1.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.idxmin()
 |      &#39;A&#39;
 |      
 |      If `skipna` is False and there is an NA value in the data,
 |      the function returns ``nan``.
 |      
 |      &gt;&gt;&gt; s.idxmin(skipna=False)
 |      nan
 |  
 |  info(self, verbose: &#39;bool | None&#39; = None, buf: &#39;IO[str] | None&#39; = None, max_cols: &#39;int | None&#39; = None, memory_usage: &#39;bool | str | None&#39; = None, show_counts: &#39;bool&#39; = True) -&gt; &#39;None&#39;
 |      Print a concise summary of a Series.
 |      
 |      This method prints information about a Series including
 |      the index dtype, non-null values and memory usage.
 |      
 |      .. versionadded:: 1.4.0
 |      
 |      Parameters
 |      ----------
 |      verbose : bool, optional
 |          Whether to print the full summary. By default, the setting in
 |          ``pandas.options.display.max_info_columns`` is followed.
 |      buf : writable buffer, defaults to sys.stdout
 |          Where to send the output. By default, the output is printed to
 |          sys.stdout. Pass a writable buffer if you need to further process
 |          the output.
 |      
 |      memory_usage : bool, str, optional
 |          Specifies whether total memory usage of the Series
 |          elements (including the index) should be displayed. By default,
 |          this follows the ``pandas.options.display.memory_usage`` setting.
 |      
 |          True always show memory usage. False never shows memory usage.
 |          A value of &#39;deep&#39; is equivalent to &quot;True with deep introspection&quot;.
 |          Memory usage is shown in human-readable units (base-2
 |          representation). Without deep introspection a memory estimation is
 |          made based in column dtype and number of rows assuming values
 |          consume the same memory amount for corresponding dtypes. With deep
 |          memory introspection, a real memory usage calculation is performed
 |          at the cost of computational resources. See the
 |          :ref:`Frequently Asked Questions &lt;df-memory-usage&gt;` for more
 |          details.
 |      show_counts : bool, optional
 |          Whether to show the non-null counts. By default, this is shown
 |          only if the DataFrame is smaller than
 |          ``pandas.options.display.max_info_rows`` and
 |          ``pandas.options.display.max_info_columns``. A value of True always
 |          shows the counts, and False never shows the counts.
 |      
 |      Returns
 |      -------
 |      None
 |          This method prints a summary of a Series and returns None.
 |      
 |      See Also
 |      --------
 |      Series.describe: Generate descriptive statistics of Series.
 |      Series.memory_usage: Memory usage of Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; int_values = [1, 2, 3, 4, 5]
 |      &gt;&gt;&gt; text_values = [&#39;alpha&#39;, &#39;beta&#39;, &#39;gamma&#39;, &#39;delta&#39;, &#39;epsilon&#39;]
 |      &gt;&gt;&gt; s = pd.Series(text_values, index=int_values)
 |      &gt;&gt;&gt; s.info()
 |      &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      Index: 5 entries, 1 to 5
 |      Series name: None
 |      Non-Null Count  Dtype
 |      --------------  -----
 |      5 non-null      object
 |      dtypes: object(1)
 |      memory usage: 80.0+ bytes
 |      
 |      Prints a summary excluding information about its values:
 |      
 |      &gt;&gt;&gt; s.info(verbose=False)
 |      &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      Index: 5 entries, 1 to 5
 |      dtypes: object(1)
 |      memory usage: 80.0+ bytes
 |      
 |      Pipe output of Series.info to buffer instead of sys.stdout, get
 |      buffer content and writes to a text file:
 |      
 |      &gt;&gt;&gt; import io
 |      &gt;&gt;&gt; buffer = io.StringIO()
 |      &gt;&gt;&gt; s.info(buf=buffer)
 |      &gt;&gt;&gt; s = buffer.getvalue()
 |      &gt;&gt;&gt; with open(&quot;df_info.txt&quot;, &quot;w&quot;,
 |      ...           encoding=&quot;utf-8&quot;) as f:  # doctest: +SKIP
 |      ...     f.write(s)
 |      260
 |      
 |      The `memory_usage` parameter allows deep introspection mode, specially
 |      useful for big Series and fine-tune memory optimization:
 |      
 |      &gt;&gt;&gt; random_strings_array = np.random.choice([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], 10 ** 6)
 |      &gt;&gt;&gt; s = pd.Series(np.random.choice([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], 10 ** 6))
 |      &gt;&gt;&gt; s.info()
 |      &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      RangeIndex: 1000000 entries, 0 to 999999
 |      Series name: None
 |      Non-Null Count    Dtype
 |      --------------    -----
 |      1000000 non-null  object
 |      dtypes: object(1)
 |      memory usage: 7.6+ MB
 |      
 |      &gt;&gt;&gt; s.info(memory_usage=&#39;deep&#39;)
 |      &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      RangeIndex: 1000000 entries, 0 to 999999
 |      Series name: None
 |      Non-Null Count    Dtype
 |      --------------    -----
 |      1000000 non-null  object
 |      dtypes: object(1)
 |      memory usage: 55.3 MB
 |  
 |  interpolate(self: &#39;Series&#39;, method: &#39;str&#39; = &#39;linear&#39;, *, axis: &#39;Axis&#39; = 0, limit: &#39;int | None&#39; = None, inplace: &#39;bool&#39; = False, limit_direction: &#39;str | None&#39; = None, limit_area: &#39;str | None&#39; = None, downcast: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;Series | None&#39;
 |      Fill NaN values using an interpolation method.
 |      
 |      Please note that only ``method=&#39;linear&#39;`` is supported for
 |      DataFrame/Series with a MultiIndex.
 |      
 |      Parameters
 |      ----------
 |      method : str, default &#39;linear&#39;
 |          Interpolation technique to use. One of:
 |      
 |          * &#39;linear&#39;: Ignore the index and treat the values as equally
 |            spaced. This is the only method supported on MultiIndexes.
 |          * &#39;time&#39;: Works on daily and higher resolution data to interpolate
 |            given length of interval.
 |          * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index.
 |          * &#39;pad&#39;: Fill in NaNs using existing values.
 |          * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;,
 |            &#39;barycentric&#39;, &#39;polynomial&#39;: Passed to
 |            `scipy.interpolate.interp1d`, whereas &#39;spline&#39; is passed to
 |            `scipy.interpolate.UnivariateSpline`. These methods use the numerical
 |            values of the index.  Both &#39;polynomial&#39; and &#39;spline&#39; require that
 |            you also specify an `order` (int), e.g.
 |            ``df.interpolate(method=&#39;polynomial&#39;, order=5)``. Note that,
 |            `slinear` method in Pandas refers to the Scipy first order `spline`
 |            instead of Pandas first order `spline`.
 |          * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, &#39;pchip&#39;, &#39;akima&#39;,
 |            &#39;cubicspline&#39;: Wrappers around the SciPy interpolation methods of
 |            similar names. See `Notes`.
 |          * &#39;from_derivatives&#39;: Refers to
 |            `scipy.interpolate.BPoly.from_derivatives` which
 |            replaces &#39;piecewise_polynomial&#39; interpolation method in
 |            scipy 0.18.
 |      
 |      axis : {{0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}}, default None
 |          Axis to interpolate along. For `Series` this parameter is unused
 |          and defaults to 0.
 |      limit : int, optional
 |          Maximum number of consecutive NaNs to fill. Must be greater than
 |          0.
 |      inplace : bool, default False
 |          Update the data in place if possible.
 |      limit_direction : {{&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}}, Optional
 |          Consecutive NaNs will be filled in this direction.
 |      
 |          If limit is specified:
 |              * If &#39;method&#39; is &#39;pad&#39; or &#39;ffill&#39;, &#39;limit_direction&#39; must be &#39;forward&#39;.
 |              * If &#39;method&#39; is &#39;backfill&#39; or &#39;bfill&#39;, &#39;limit_direction&#39; must be
 |                &#39;backwards&#39;.
 |      
 |          If &#39;limit&#39; is not specified:
 |              * If &#39;method&#39; is &#39;backfill&#39; or &#39;bfill&#39;, the default is &#39;backward&#39;
 |              * else the default is &#39;forward&#39;
 |      
 |          .. versionchanged:: 1.1.0
 |              raises ValueError if `limit_direction` is &#39;forward&#39; or &#39;both&#39; and
 |                  method is &#39;backfill&#39; or &#39;bfill&#39;.
 |              raises ValueError if `limit_direction` is &#39;backward&#39; or &#39;both&#39; and
 |                  method is &#39;pad&#39; or &#39;ffill&#39;.
 |      
 |      limit_area : {{`None`, &#39;inside&#39;, &#39;outside&#39;}}, default None
 |          If limit is specified, consecutive NaNs will be filled with this
 |          restriction.
 |      
 |          * ``None``: No fill restriction.
 |          * &#39;inside&#39;: Only fill NaNs surrounded by valid values
 |            (interpolate).
 |          * &#39;outside&#39;: Only fill NaNs outside valid values (extrapolate).
 |      
 |      downcast : optional, &#39;infer&#39; or None, defaults to None
 |          Downcast dtypes if possible.
 |      ``**kwargs`` : optional
 |          Keyword arguments to pass on to the interpolating function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame or None
 |          Returns the same object type as the caller, interpolated at
 |          some or all ``NaN`` values or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      fillna : Fill missing values using different methods.
 |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials
 |          (Akima interpolator).
 |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the
 |          Bernstein basis.
 |      scipy.interpolate.interp1d : Interpolate a 1-D function.
 |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh
 |          interpolator).
 |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic
 |          interpolation.
 |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.
 |      
 |      Notes
 |      -----
 |      The &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, &#39;pchip&#39; and &#39;akima&#39;
 |      methods are wrappers around the respective SciPy implementations of
 |      similar names. These use the actual numerical values of the index.
 |      For more information on their behavior, see the
 |      `SciPy documentation
 |      &lt;https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;`__.
 |      
 |      Examples
 |      --------
 |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear
 |      interpolation.
 |      
 |      &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
 |      &gt;&gt;&gt; s
 |      0    0.0
 |      1    1.0
 |      2    NaN
 |      3    3.0
 |      dtype: float64
 |      &gt;&gt;&gt; s.interpolate()
 |      0    0.0
 |      1    1.0
 |      2    2.0
 |      3    3.0
 |      dtype: float64
 |      
 |      Filling in ``NaN`` in a Series by padding, but filling at most two
 |      consecutive ``NaN`` at a time.
 |      
 |      &gt;&gt;&gt; s = pd.Series([np.nan, &quot;single_one&quot;, np.nan,
 |      ...                &quot;fill_two_more&quot;, np.nan, np.nan, np.nan,
 |      ...                4.71, np.nan])
 |      &gt;&gt;&gt; s
 |      0              NaN
 |      1       single_one
 |      2              NaN
 |      3    fill_two_more
 |      4              NaN
 |      5              NaN
 |      6              NaN
 |      7             4.71
 |      8              NaN
 |      dtype: object
 |      &gt;&gt;&gt; s.interpolate(method=&#39;pad&#39;, limit=2)
 |      0              NaN
 |      1       single_one
 |      2       single_one
 |      3    fill_two_more
 |      4    fill_two_more
 |      5    fill_two_more
 |      6              NaN
 |      7             4.71
 |      8             4.71
 |      dtype: object
 |      
 |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:
 |      Both &#39;polynomial&#39; and &#39;spline&#39; methods require that you also specify
 |      an ``order`` (int).
 |      
 |      &gt;&gt;&gt; s = pd.Series([0, 2, np.nan, 8])
 |      &gt;&gt;&gt; s.interpolate(method=&#39;polynomial&#39;, order=2)
 |      0    0.000000
 |      1    2.000000
 |      2    4.666667
 |      3    8.000000
 |      dtype: float64
 |      
 |      Fill the DataFrame forward (that is, going down) along each column
 |      using linear interpolation.
 |      
 |      Note how the last entry in column &#39;a&#39; is interpolated differently,
 |      because there is no entry after it to use for interpolation.
 |      Note how the first entry in column &#39;b&#39; remains ``NaN``, because there
 |      is no entry before it to use for interpolation.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
 |      ...                    (np.nan, 2.0, np.nan, np.nan),
 |      ...                    (2.0, 3.0, np.nan, 9.0),
 |      ...                    (np.nan, 4.0, -4.0, 16.0)],
 |      ...                   columns=list(&#39;abcd&#39;))
 |      &gt;&gt;&gt; df
 |           a    b    c     d
 |      0  0.0  NaN -1.0   1.0
 |      1  NaN  2.0  NaN   NaN
 |      2  2.0  3.0  NaN   9.0
 |      3  NaN  4.0 -4.0  16.0
 |      &gt;&gt;&gt; df.interpolate(method=&#39;linear&#39;, limit_direction=&#39;forward&#39;, axis=0)
 |           a    b    c     d
 |      0  0.0  NaN -1.0   1.0
 |      1  1.0  2.0 -2.0   5.0
 |      2  2.0  3.0 -3.0   9.0
 |      3  2.0  4.0 -4.0  16.0
 |      
 |      Using polynomial interpolation.
 |      
 |      &gt;&gt;&gt; df[&#39;d&#39;].interpolate(method=&#39;polynomial&#39;, order=2)
 |      0     1.0
 |      1     4.0
 |      2     9.0
 |      3    16.0
 |      Name: d, dtype: float64
 |  
 |  isin(self, values) -&gt; &#39;Series&#39;
 |      Whether elements in Series are contained in `values`.
 |      
 |      Return a boolean Series showing whether each element in the Series
 |      matches an element in the passed sequence of `values` exactly.
 |      
 |      Parameters
 |      ----------
 |      values : set or list-like
 |          The sequence of values to test. Passing in a single string will
 |          raise a ``TypeError``. Instead, turn a single string into a
 |          list of one element.
 |      
 |      Returns
 |      -------
 |      Series
 |          Series of booleans indicating if each element is in values.
 |      
 |      Raises
 |      ------
 |      TypeError
 |        * If `values` is a string
 |      
 |      See Also
 |      --------
 |      DataFrame.isin : Equivalent method on DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&#39;lama&#39;, &#39;cow&#39;, &#39;lama&#39;, &#39;beetle&#39;, &#39;lama&#39;,
 |      ...                &#39;hippo&#39;], name=&#39;animal&#39;)
 |      &gt;&gt;&gt; s.isin([&#39;cow&#39;, &#39;lama&#39;])
 |      0     True
 |      1     True
 |      2     True
 |      3    False
 |      4     True
 |      5    False
 |      Name: animal, dtype: bool
 |      
 |      To invert the boolean values, use the ``~`` operator:
 |      
 |      &gt;&gt;&gt; ~s.isin([&#39;cow&#39;, &#39;lama&#39;])
 |      0    False
 |      1    False
 |      2    False
 |      3     True
 |      4    False
 |      5     True
 |      Name: animal, dtype: bool
 |      
 |      Passing a single string as ``s.isin(&#39;lama&#39;)`` will raise an error. Use
 |      a list of one element instead:
 |      
 |      &gt;&gt;&gt; s.isin([&#39;lama&#39;])
 |      0     True
 |      1    False
 |      2     True
 |      3    False
 |      4     True
 |      5    False
 |      Name: animal, dtype: bool
 |      
 |      Strings and integers are distinct and are therefore not comparable:
 |      
 |      &gt;&gt;&gt; pd.Series([1]).isin([&#39;1&#39;])
 |      0    False
 |      dtype: bool
 |      &gt;&gt;&gt; pd.Series([1.1]).isin([&#39;1.1&#39;])
 |      0    False
 |      dtype: bool
 |  
 |  isna(self) -&gt; &#39;Series&#39;
 |      Detect missing values.
 |      
 |      Return a boolean same-sized object indicating if the values are NA.
 |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True
 |      values.
 |      Everything else gets mapped to False values. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      
 |      Returns
 |      -------
 |      Series
 |          Mask of bool values for each element in Series that
 |          indicates whether an element is an NA value.
 |      
 |      See Also
 |      --------
 |      Series.isnull : Alias of isna.
 |      Series.notna : Boolean inverse of isna.
 |      Series.dropna : Omit axes labels with missing values.
 |      isna : Top-level isna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                        born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                              pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                        name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                        toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.isna()
 |           age   born   name    toy
 |      0  False   True  False   True
 |      1  False  False  False  False
 |      2   True  False  False  False
 |      
 |      Show which entries in a Series are NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.isna()
 |      0    False
 |      1    False
 |      2     True
 |      dtype: bool
 |  
 |  isnull(self) -&gt; &#39;Series&#39;
 |      Series.isnull is an alias for Series.isna.
 |      
 |      Detect missing values.
 |      
 |      Return a boolean same-sized object indicating if the values are NA.
 |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True
 |      values.
 |      Everything else gets mapped to False values. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      
 |      Returns
 |      -------
 |      Series
 |          Mask of bool values for each element in Series that
 |          indicates whether an element is an NA value.
 |      
 |      See Also
 |      --------
 |      Series.isnull : Alias of isna.
 |      Series.notna : Boolean inverse of isna.
 |      Series.dropna : Omit axes labels with missing values.
 |      isna : Top-level isna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                        born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                              pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                        name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                        toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.isna()
 |           age   born   name    toy
 |      0  False   True  False   True
 |      1  False  False  False  False
 |      2   True  False  False  False
 |      
 |      Show which entries in a Series are NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.isna()
 |      0    False
 |      1    False
 |      2     True
 |      dtype: bool
 |  
 |  items(self) -&gt; &#39;Iterable[tuple[Hashable, Any]]&#39;
 |      Lazily iterate over (index, value) tuples.
 |      
 |      This method returns an iterable tuple (index, value). This is
 |      convenient if you want to create a lazy iterator.
 |      
 |      Returns
 |      -------
 |      iterable
 |          Iterable of tuples containing the (index, value) pairs from a
 |          Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.items : Iterate over (column name, Series) pairs.
 |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; for index, value in s.items():
 |      ...     print(f&quot;Index : {index}, Value : {value}&quot;)
 |      Index : 0, Value : A
 |      Index : 1, Value : B
 |      Index : 2, Value : C
 |  
 |  keys(self) -&gt; &#39;Index&#39;
 |      Return alias for index.
 |      
 |      Returns
 |      -------
 |      Index
 |          Index of the Series.
 |  
 |  kurt(self, axis: &#39;Axis | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return unbiased kurtosis over requested axis.
 |      
 |      Kurtosis obtained using Fisher&#39;s definition of
 |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |  
 |  kurtosis = kurt(self, axis: &#39;Axis | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |  
 |  le(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Less than or equal to of series and other, element-wise (binary operator `le`).
 |      
 |      Equivalent to ``series &lt;= other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      e    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([0, 1, 2, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;f&#39;])
 |      &gt;&gt;&gt; b
 |      a    0.0
 |      b    1.0
 |      c    2.0
 |      d    NaN
 |      f    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; a.le(b, fill_value=0)
 |      a    False
 |      b     True
 |      c     True
 |      d    False
 |      e    False
 |      f     True
 |      dtype: bool
 |  
 |  lt(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Less than of series and other, element-wise (binary operator `lt`).
 |      
 |      Equivalent to ``series &lt; other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      e    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([0, 1, 2, np.nan, 1], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;f&#39;])
 |      &gt;&gt;&gt; b
 |      a    0.0
 |      b    1.0
 |      c    2.0
 |      d    NaN
 |      f    1.0
 |      dtype: float64
 |      &gt;&gt;&gt; a.lt(b, fill_value=0)
 |      a    False
 |      b    False
 |      c     True
 |      d    False
 |      e    False
 |      f     True
 |      dtype: bool
 |  
 |  map(self, arg: &#39;Callable | Mapping | Series&#39;, na_action: &quot;Literal[&#39;ignore&#39;] | None&quot; = None) -&gt; &#39;Series&#39;
 |      Map values of Series according to an input mapping or function.
 |      
 |      Used for substituting each value in a Series with another value,
 |      that may be derived from a function, a ``dict`` or
 |      a :class:`Series`.
 |      
 |      Parameters
 |      ----------
 |      arg : function, collections.abc.Mapping subclass or Series
 |          Mapping correspondence.
 |      na_action : {None, &#39;ignore&#39;}, default None
 |          If &#39;ignore&#39;, propagate NaN values, without passing them to the
 |          mapping correspondence.
 |      
 |      Returns
 |      -------
 |      Series
 |          Same index as caller.
 |      
 |      See Also
 |      --------
 |      Series.apply : For applying more complex functions on a Series.
 |      DataFrame.apply : Apply a function row-/column-wise.
 |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.
 |      
 |      Notes
 |      -----
 |      When ``arg`` is a dictionary, values in Series that are not in the
 |      dictionary (as keys) are converted to ``NaN``. However, if the
 |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.
 |      provides a method for default values), then this default is used
 |      rather than ``NaN``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&#39;cat&#39;, &#39;dog&#39;, np.nan, &#39;rabbit&#39;])
 |      &gt;&gt;&gt; s
 |      0      cat
 |      1      dog
 |      2      NaN
 |      3   rabbit
 |      dtype: object
 |      
 |      ``map`` accepts a ``dict`` or a ``Series``. Values that are not found
 |      in the ``dict`` are converted to ``NaN``, unless the dict has a default
 |      value (e.g. ``defaultdict``):
 |      
 |      &gt;&gt;&gt; s.map({&#39;cat&#39;: &#39;kitten&#39;, &#39;dog&#39;: &#39;puppy&#39;})
 |      0   kitten
 |      1    puppy
 |      2      NaN
 |      3      NaN
 |      dtype: object
 |      
 |      It also accepts a function:
 |      
 |      &gt;&gt;&gt; s.map(&#39;I am a {}&#39;.format)
 |      0       I am a cat
 |      1       I am a dog
 |      2       I am a nan
 |      3    I am a rabbit
 |      dtype: object
 |      
 |      To avoid applying the function to missing values (and keep them as
 |      ``NaN``) ``na_action=&#39;ignore&#39;`` can be used:
 |      
 |      &gt;&gt;&gt; s.map(&#39;I am a {}&#39;.format, na_action=&#39;ignore&#39;)
 |      0     I am a cat
 |      1     I am a dog
 |      2            NaN
 |      3  I am a rabbit
 |      dtype: object
 |  
 |  mask(self, cond, other=&lt;no_default&gt;, *, inplace: &#39;bool&#39; = False, axis: &#39;Axis | None&#39; = None, level: &#39;Level&#39; = None) -&gt; &#39;Series | None&#39;
 |      Replace values where the condition is True.
 |      
 |      Parameters
 |      ----------
 |      cond : bool Series/DataFrame, array-like, or callable
 |          Where `cond` is False, keep the original value. Where
 |          True, replace with corresponding value from `other`.
 |          If `cond` is callable, it is computed on the Series/DataFrame and
 |          should return boolean Series/DataFrame or array. The callable must
 |          not change input Series/DataFrame (though pandas doesn&#39;t check it).
 |      other : scalar, Series/DataFrame, or callable
 |          Entries where `cond` is True are replaced with
 |          corresponding value from `other`.
 |          If other is callable, it is computed on the Series/DataFrame and
 |          should return scalar or Series/DataFrame. The callable must not
 |          change input Series/DataFrame (though pandas doesn&#39;t check it).
 |          If not specified, entries will be filled with the corresponding
 |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension
 |          dtypes).
 |      inplace : bool, default False
 |          Whether to perform the operation in place on the data.
 |      axis : int, default None
 |          Alignment axis if needed. For `Series` this parameter is
 |          unused and defaults to 0.
 |      level : int, default None
 |          Alignment level if needed.
 |      
 |      Returns
 |      -------
 |      Same type as caller or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      :func:`DataFrame.where` : Return an object of same shape as
 |          self.
 |      
 |      Notes
 |      -----
 |      The mask method is an application of the if-then idiom. For each
 |      element in the calling DataFrame, if ``cond`` is ``False`` the
 |      element is used; otherwise the corresponding element from the DataFrame
 |      ``other`` is used. If the axis of ``other`` does not align with axis of
 |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with
 |      True.
 |      
 |      The signature for :func:`DataFrame.where` differs from
 |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to
 |      ``np.where(m, df1, df2)``.
 |      
 |      For further details and examples see the ``mask`` documentation in
 |      :ref:`indexing &lt;indexing.where_mask&gt;`.
 |      
 |      The dtype of the object takes precedence. The fill value is casted to
 |      the object&#39;s dtype, if this can be done losslessly.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(range(5))
 |      &gt;&gt;&gt; s.where(s &gt; 0)
 |      0    NaN
 |      1    1.0
 |      2    2.0
 |      3    3.0
 |      4    4.0
 |      dtype: float64
 |      &gt;&gt;&gt; s.mask(s &gt; 0)
 |      0    0.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(5))
 |      &gt;&gt;&gt; t = pd.Series([True, False])
 |      &gt;&gt;&gt; s.where(t, 99)
 |      0     0
 |      1    99
 |      2    99
 |      3    99
 |      4    99
 |      dtype: int64
 |      &gt;&gt;&gt; s.mask(t, 99)
 |      0    99
 |      1     1
 |      2    99
 |      3    99
 |      4    99
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.where(s &gt; 1, 10)
 |      0    10
 |      1    10
 |      2    2
 |      3    3
 |      4    4
 |      dtype: int64
 |      &gt;&gt;&gt; s.mask(s &gt; 1, 10)
 |      0     0
 |      1     1
 |      2    10
 |      3    10
 |      4    10
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=[&#39;A&#39;, &#39;B&#39;])
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  0  1
 |      1  2  3
 |      2  4  5
 |      3  6  7
 |      4  8  9
 |      &gt;&gt;&gt; m = df % 3 == 0
 |      &gt;&gt;&gt; df.where(m, -df)
 |         A  B
 |      0  0 -1
 |      1 -2  3
 |      2 -4 -5
 |      3  6 -7
 |      4 -8  9
 |      &gt;&gt;&gt; df.where(m, -df) == np.where(m, df, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |      &gt;&gt;&gt; df.where(m, -df) == df.mask(~m, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |  
 |  max(self, axis: &#39;AxisInt | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return the maximum of the values over the requested axis.
 |      
 |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.MultiIndex.from_arrays([
 |      ...     [&#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;],
 |      ...     [&#39;dog&#39;, &#39;falcon&#39;, &#39;fish&#39;, &#39;spider&#39;]],
 |      ...     names=[&#39;blooded&#39;, &#39;animal&#39;])
 |      &gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=&#39;legs&#39;, index=idx)
 |      &gt;&gt;&gt; s
 |      blooded  animal
 |      warm     dog       4
 |               falcon    2
 |      cold     fish      0
 |               spider    8
 |      Name: legs, dtype: int64
 |      
 |      &gt;&gt;&gt; s.max()
 |      8
 |  
 |  mean(self, axis: &#39;AxisInt | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return the mean of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |  
 |  median(self, axis: &#39;AxisInt | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return the median of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |  
 |  memory_usage(self, index: &#39;bool&#39; = True, deep: &#39;bool&#39; = False) -&gt; &#39;int&#39;
 |      Return the memory usage of the Series.
 |      
 |      The memory usage can optionally include the contribution of
 |      the index and of elements of `object` dtype.
 |      
 |      Parameters
 |      ----------
 |      index : bool, default True
 |          Specifies whether to include the memory usage of the Series index.
 |      deep : bool, default False
 |          If True, introspect the data deeply by interrogating
 |          `object` dtypes for system-level memory consumption, and include
 |          it in the returned value.
 |      
 |      Returns
 |      -------
 |      int
 |          Bytes of memory consumed.
 |      
 |      See Also
 |      --------
 |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the
 |          array.
 |      DataFrame.memory_usage : Bytes consumed by a DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(range(3))
 |      &gt;&gt;&gt; s.memory_usage()
 |      152
 |      
 |      Not including the index gives the size of the rest of the data, which
 |      is necessarily smaller:
 |      
 |      &gt;&gt;&gt; s.memory_usage(index=False)
 |      24
 |      
 |      The memory footprint of `object` values is ignored by default:
 |      
 |      &gt;&gt;&gt; s = pd.Series([&quot;a&quot;, &quot;b&quot;])
 |      &gt;&gt;&gt; s.values
 |      array([&#39;a&#39;, &#39;b&#39;], dtype=object)
 |      &gt;&gt;&gt; s.memory_usage()
 |      144
 |      &gt;&gt;&gt; s.memory_usage(deep=True)
 |      244
 |  
 |  min(self, axis: &#39;AxisInt | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return the minimum of the values over the requested axis.
 |      
 |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.MultiIndex.from_arrays([
 |      ...     [&#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;],
 |      ...     [&#39;dog&#39;, &#39;falcon&#39;, &#39;fish&#39;, &#39;spider&#39;]],
 |      ...     names=[&#39;blooded&#39;, &#39;animal&#39;])
 |      &gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=&#39;legs&#39;, index=idx)
 |      &gt;&gt;&gt; s
 |      blooded  animal
 |      warm     dog       4
 |               falcon    2
 |      cold     fish      0
 |               spider    8
 |      Name: legs, dtype: int64
 |      
 |      &gt;&gt;&gt; s.min()
 |      0
 |  
 |  mod(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Modulo of series and other, element-wise (binary operator `mod`).
 |      
 |      Equivalent to ``series % other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rmod : Reverse of the Modulo operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.mod(b, fill_value=0)
 |      a    0.0
 |      b    NaN
 |      c    NaN
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  mode(self, dropna: &#39;bool&#39; = True) -&gt; &#39;Series&#39;
 |      Return the mode(s) of the Series.
 |      
 |      The mode is the value that appears most often. There can be multiple modes.
 |      
 |      Always returns Series even if only one value is returned.
 |      
 |      Parameters
 |      ----------
 |      dropna : bool, default True
 |          Don&#39;t consider counts of NaN/NaT.
 |      
 |      Returns
 |      -------
 |      Series
 |          Modes of the Series in sorted order.
 |  
 |  mul(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Multiplication of series and other, element-wise (binary operator `mul`).
 |      
 |      Equivalent to ``series * other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rmul : Reverse of the Multiplication operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.multiply(b, fill_value=0)
 |      a    1.0
 |      b    0.0
 |      c    0.0
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  multiply = mul(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |  
 |  ne(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Not equal to of series and other, element-wise (binary operator `ne`).
 |      
 |      Equivalent to ``series != other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.ne(b, fill_value=0)
 |      a    False
 |      b     True
 |      c     True
 |      d     True
 |      e     True
 |      dtype: bool
 |  
 |  nlargest(self, n: &#39;int&#39; = 5, keep: &quot;Literal[&#39;first&#39;, &#39;last&#39;, &#39;all&#39;]&quot; = &#39;first&#39;) -&gt; &#39;Series&#39;
 |      Return the largest `n` elements.
 |      
 |      Parameters
 |      ----------
 |      n : int, default 5
 |          Return this many descending sorted values.
 |      keep : {&#39;first&#39;, &#39;last&#39;, &#39;all&#39;}, default &#39;first&#39;
 |          When there are duplicate values that cannot all fit in a
 |          Series of `n` elements:
 |      
 |          - ``first`` : return the first `n` occurrences in order
 |            of appearance.
 |          - ``last`` : return the last `n` occurrences in reverse
 |            order of appearance.
 |          - ``all`` : keep all occurrences. This can result in a Series of
 |            size larger than `n`.
 |      
 |      Returns
 |      -------
 |      Series
 |          The `n` largest values in the Series, sorted in decreasing order.
 |      
 |      See Also
 |      --------
 |      Series.nsmallest: Get the `n` smallest elements.
 |      Series.sort_values: Sort Series by values.
 |      Series.head: Return the first `n` rows.
 |      
 |      Notes
 |      -----
 |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`
 |      relative to the size of the ``Series`` object.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; countries_population = {&quot;Italy&quot;: 59000000, &quot;France&quot;: 65000000,
 |      ...                         &quot;Malta&quot;: 434000, &quot;Maldives&quot;: 434000,
 |      ...                         &quot;Brunei&quot;: 434000, &quot;Iceland&quot;: 337000,
 |      ...                         &quot;Nauru&quot;: 11300, &quot;Tuvalu&quot;: 11300,
 |      ...                         &quot;Anguilla&quot;: 11300, &quot;Montserrat&quot;: 5200}
 |      &gt;&gt;&gt; s = pd.Series(countries_population)
 |      &gt;&gt;&gt; s
 |      Italy       59000000
 |      France      65000000
 |      Malta         434000
 |      Maldives      434000
 |      Brunei        434000
 |      Iceland       337000
 |      Nauru          11300
 |      Tuvalu         11300
 |      Anguilla       11300
 |      Montserrat      5200
 |      dtype: int64
 |      
 |      The `n` largest elements where ``n=5`` by default.
 |      
 |      &gt;&gt;&gt; s.nlargest()
 |      France      65000000
 |      Italy       59000000
 |      Malta         434000
 |      Maldives      434000
 |      Brunei        434000
 |      dtype: int64
 |      
 |      The `n` largest elements where ``n=3``. Default `keep` value is &#39;first&#39;
 |      so Malta will be kept.
 |      
 |      &gt;&gt;&gt; s.nlargest(3)
 |      France    65000000
 |      Italy     59000000
 |      Malta       434000
 |      dtype: int64
 |      
 |      The `n` largest elements where ``n=3`` and keeping the last duplicates.
 |      Brunei will be kept since it is the last with value 434000 based on
 |      the index order.
 |      
 |      &gt;&gt;&gt; s.nlargest(3, keep=&#39;last&#39;)
 |      France      65000000
 |      Italy       59000000
 |      Brunei        434000
 |      dtype: int64
 |      
 |      The `n` largest elements where ``n=3`` with all duplicates kept. Note
 |      that the returned Series has five elements due to the three duplicates.
 |      
 |      &gt;&gt;&gt; s.nlargest(3, keep=&#39;all&#39;)
 |      France      65000000
 |      Italy       59000000
 |      Malta         434000
 |      Maldives      434000
 |      Brunei        434000
 |      dtype: int64
 |  
 |  notna(self) -&gt; &#39;Series&#39;
 |      Detect existing (non-missing) values.
 |      
 |      Return a boolean same-sized object indicating if the values are not NA.
 |      Non-missing values get mapped to True. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False
 |      values.
 |      
 |      Returns
 |      -------
 |      Series
 |          Mask of bool values for each element in Series that
 |          indicates whether an element is not an NA value.
 |      
 |      See Also
 |      --------
 |      Series.notnull : Alias of notna.
 |      Series.isna : Boolean inverse of notna.
 |      Series.dropna : Omit axes labels with missing values.
 |      notna : Top-level notna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are not NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                        born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                              pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                        name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                        toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.notna()
 |           age   born  name    toy
 |      0   True  False  True  False
 |      1   True   True  True   True
 |      2  False   True  True   True
 |      
 |      Show which entries in a Series are not NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.notna()
 |      0     True
 |      1     True
 |      2    False
 |      dtype: bool
 |  
 |  notnull(self) -&gt; &#39;Series&#39;
 |      Series.notnull is an alias for Series.notna.
 |      
 |      Detect existing (non-missing) values.
 |      
 |      Return a boolean same-sized object indicating if the values are not NA.
 |      Non-missing values get mapped to True. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False
 |      values.
 |      
 |      Returns
 |      -------
 |      Series
 |          Mask of bool values for each element in Series that
 |          indicates whether an element is not an NA value.
 |      
 |      See Also
 |      --------
 |      Series.notnull : Alias of notna.
 |      Series.isna : Boolean inverse of notna.
 |      Series.dropna : Omit axes labels with missing values.
 |      notna : Top-level notna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are not NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                        born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                              pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                        name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                        toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.notna()
 |           age   born  name    toy
 |      0   True  False  True  False
 |      1   True   True  True   True
 |      2  False   True  True   True
 |      
 |      Show which entries in a Series are not NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.notna()
 |      0     True
 |      1     True
 |      2    False
 |      dtype: bool
 |  
 |  nsmallest(self, n: &#39;int&#39; = 5, keep: &#39;str&#39; = &#39;first&#39;) -&gt; &#39;Series&#39;
 |      Return the smallest `n` elements.
 |      
 |      Parameters
 |      ----------
 |      n : int, default 5
 |          Return this many ascending sorted values.
 |      keep : {&#39;first&#39;, &#39;last&#39;, &#39;all&#39;}, default &#39;first&#39;
 |          When there are duplicate values that cannot all fit in a
 |          Series of `n` elements:
 |      
 |          - ``first`` : return the first `n` occurrences in order
 |            of appearance.
 |          - ``last`` : return the last `n` occurrences in reverse
 |            order of appearance.
 |          - ``all`` : keep all occurrences. This can result in a Series of
 |            size larger than `n`.
 |      
 |      Returns
 |      -------
 |      Series
 |          The `n` smallest values in the Series, sorted in increasing order.
 |      
 |      See Also
 |      --------
 |      Series.nlargest: Get the `n` largest elements.
 |      Series.sort_values: Sort Series by values.
 |      Series.head: Return the first `n` rows.
 |      
 |      Notes
 |      -----
 |      Faster than ``.sort_values().head(n)`` for small `n` relative to
 |      the size of the ``Series`` object.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; countries_population = {&quot;Italy&quot;: 59000000, &quot;France&quot;: 65000000,
 |      ...                         &quot;Brunei&quot;: 434000, &quot;Malta&quot;: 434000,
 |      ...                         &quot;Maldives&quot;: 434000, &quot;Iceland&quot;: 337000,
 |      ...                         &quot;Nauru&quot;: 11300, &quot;Tuvalu&quot;: 11300,
 |      ...                         &quot;Anguilla&quot;: 11300, &quot;Montserrat&quot;: 5200}
 |      &gt;&gt;&gt; s = pd.Series(countries_population)
 |      &gt;&gt;&gt; s
 |      Italy       59000000
 |      France      65000000
 |      Brunei        434000
 |      Malta         434000
 |      Maldives      434000
 |      Iceland       337000
 |      Nauru          11300
 |      Tuvalu         11300
 |      Anguilla       11300
 |      Montserrat      5200
 |      dtype: int64
 |      
 |      The `n` smallest elements where ``n=5`` by default.
 |      
 |      &gt;&gt;&gt; s.nsmallest()
 |      Montserrat    5200
 |      Nauru        11300
 |      Tuvalu       11300
 |      Anguilla     11300
 |      Iceland     337000
 |      dtype: int64
 |      
 |      The `n` smallest elements where ``n=3``. Default `keep` value is
 |      &#39;first&#39; so Nauru and Tuvalu will be kept.
 |      
 |      &gt;&gt;&gt; s.nsmallest(3)
 |      Montserrat   5200
 |      Nauru       11300
 |      Tuvalu      11300
 |      dtype: int64
 |      
 |      The `n` smallest elements where ``n=3`` and keeping the last
 |      duplicates. Anguilla and Tuvalu will be kept since they are the last
 |      with value 11300 based on the index order.
 |      
 |      &gt;&gt;&gt; s.nsmallest(3, keep=&#39;last&#39;)
 |      Montserrat   5200
 |      Anguilla    11300
 |      Tuvalu      11300
 |      dtype: int64
 |      
 |      The `n` smallest elements where ``n=3`` with all duplicates kept. Note
 |      that the returned Series has four elements due to the three duplicates.
 |      
 |      &gt;&gt;&gt; s.nsmallest(3, keep=&#39;all&#39;)
 |      Montserrat   5200
 |      Nauru       11300
 |      Tuvalu      11300
 |      Anguilla    11300
 |      dtype: int64
 |  
 |  pop(self, item: &#39;Hashable&#39;) -&gt; &#39;Any&#39;
 |      Return item and drops from series. Raise KeyError if not found.
 |      
 |      Parameters
 |      ----------
 |      item : label
 |          Index of the element that needs to be removed.
 |      
 |      Returns
 |      -------
 |      Value that is popped from series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; ser = pd.Series([1,2,3])
 |      
 |      &gt;&gt;&gt; ser.pop(0)
 |      1
 |      
 |      &gt;&gt;&gt; ser
 |      1    2
 |      2    3
 |      dtype: int64
 |  
 |  pow(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Exponential power of series and other, element-wise (binary operator `pow`).
 |      
 |      Equivalent to ``series ** other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rpow : Reverse of the Exponential power operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.pow(b, fill_value=0)
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  prod(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, min_count: &#39;int&#39; = 0, **kwargs)
 |      Return the product of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      min_count : int, default 0
 |          The required number of valid values to perform the operation. If fewer than
 |          ``min_count`` non-NA values are present the result will be NA.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      By default, the product of an empty or all-NA Series is ``1``
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).prod()
 |      1.0
 |      
 |      This can be controlled with the ``min_count`` parameter
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).prod(min_count=1)
 |      nan
 |      
 |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and
 |      empty series identically.
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).prod()
 |      1.0
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).prod(min_count=1)
 |      nan
 |  
 |  product = prod(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, min_count: &#39;int&#39; = 0, **kwargs)
 |  
 |  quantile(self, q: &#39;float | Sequence[float] | AnyArrayLike&#39; = 0.5, interpolation: &#39;QuantileInterpolation&#39; = &#39;linear&#39;) -&gt; &#39;float | Series&#39;
 |      Return value at the given quantile.
 |      
 |      Parameters
 |      ----------
 |      q : float or array-like, default 0.5 (50% quantile)
 |          The quantile(s) to compute, which can lie in range: 0 &lt;= q &lt;= 1.
 |      interpolation : {&#39;linear&#39;, &#39;lower&#39;, &#39;higher&#39;, &#39;midpoint&#39;, &#39;nearest&#39;}
 |          This optional parameter specifies the interpolation method to use,
 |          when the desired quantile lies between two data points `i` and `j`:
 |      
 |              * linear: `i + (j - i) * fraction`, where `fraction` is the
 |                fractional part of the index surrounded by `i` and `j`.
 |              * lower: `i`.
 |              * higher: `j`.
 |              * nearest: `i` or `j` whichever is nearest.
 |              * midpoint: (`i` + `j`) / 2.
 |      
 |      Returns
 |      -------
 |      float or Series
 |          If ``q`` is an array, a Series will be returned where the
 |          index is ``q`` and the values are the quantiles, otherwise
 |          a float will be returned.
 |      
 |      See Also
 |      --------
 |      core.window.Rolling.quantile : Calculate the rolling quantile.
 |      numpy.percentile : Returns the q-th percentile(s) of the array elements.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s.quantile(.5)
 |      2.5
 |      &gt;&gt;&gt; s.quantile([.25, .5, .75])
 |      0.25    1.75
 |      0.50    2.50
 |      0.75    3.25
 |      dtype: float64
 |  
 |  radd(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Addition of series and other, element-wise (binary operator `radd`).
 |      
 |      Equivalent to ``other + series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.add : Element-wise Addition, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.add(b, fill_value=0)
 |      a    2.0
 |      b    1.0
 |      c    1.0
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |  
 |  ravel(self, order: &#39;str&#39; = &#39;C&#39;) -&gt; &#39;ArrayLike&#39;
 |      Return the flattened underlying data as an ndarray or ExtensionArray.
 |      
 |      Returns
 |      -------
 |      numpy.ndarray or ExtensionArray
 |          Flattened data of the Series.
 |      
 |      See Also
 |      --------
 |      numpy.ndarray.ravel : Return a flattened array.
 |  
 |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |  
 |  rdivmod(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Integer division and modulo of series and other, element-wise (binary operator `rdivmod`).
 |      
 |      Equivalent to ``other divmod series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      2-Tuple of Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.divmod : Element-wise Integer division and modulo, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.divmod(b, fill_value=0)
 |      (a    1.0
 |       b    NaN
 |       c    NaN
 |       d    0.0
 |       e    NaN
 |       dtype: float64,
 |       a    0.0
 |       b    NaN
 |       c    NaN
 |       d    0.0
 |       e    NaN
 |       dtype: float64)
 |  
 |  reindex(self, index=None, *, axis: &#39;Axis | None&#39; = None, method: &#39;str | None&#39; = None, copy: &#39;bool | None&#39; = None, level: &#39;Level | None&#39; = None, fill_value: &#39;Scalar | None&#39; = None, limit: &#39;int | None&#39; = None, tolerance=None) -&gt; &#39;Series&#39;
 |      Conform Series to new index with optional filling logic.
 |      
 |      Places NA/NaN in locations having no value in the previous index. A new object
 |      is produced unless the new index is equivalent to the current one and
 |      ``copy=False``.
 |      
 |      Parameters
 |      ----------
 |      
 |      index : array-like, optional
 |          New labels for the index. Preferably an Index object to avoid
 |          duplicating data.
 |      axis : int or str, optional
 |          Unused.
 |      method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}
 |          Method to use for filling holes in reindexed DataFrame.
 |          Please note: this is only applicable to DataFrames/Series with a
 |          monotonically increasing/decreasing index.
 |      
 |          * None (default): don&#39;t fill gaps
 |          * pad / ffill: Propagate last valid observation forward to next
 |            valid.
 |          * backfill / bfill: Use next valid observation to fill gap.
 |          * nearest: Use nearest valid observations to fill gap.
 |      
 |      copy : bool, default True
 |          Return a new object, even if the passed indexes are the same.
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : scalar, default np.NaN
 |          Value to use for missing values. Defaults to NaN, but can be any
 |          &quot;compatible&quot; value.
 |      limit : int, default None
 |          Maximum number of consecutive elements to forward or backward fill.
 |      tolerance : optional
 |          Maximum distance between original and new labels for inexact
 |          matches. The values of the index at the matching locations most
 |          satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
 |      
 |          Tolerance may be a scalar value, which applies the same tolerance
 |          to all values, or list-like, which applies variable tolerance per
 |          element. List-like includes list, tuple, array, Series, and must be
 |          the same size as the index and its dtype must exactly match the
 |          index&#39;s type.
 |      
 |      Returns
 |      -------
 |      Series with changed index.
 |      
 |      See Also
 |      --------
 |      DataFrame.set_index : Set row labels.
 |      DataFrame.reset_index : Remove row labels or move them to new columns.
 |      DataFrame.reindex_like : Change to same indices as other DataFrame.
 |      
 |      Examples
 |      --------
 |      ``DataFrame.reindex`` supports two calling conventions
 |      
 |      * ``(index=index_labels, columns=column_labels, ...)``
 |      * ``(labels, axis={&#39;index&#39;, &#39;columns&#39;}, ...)``
 |      
 |      We *highly* recommend using keyword arguments to clarify your
 |      intent.
 |      
 |      Create a dataframe with some fictional data.
 |      
 |      &gt;&gt;&gt; index = [&#39;Firefox&#39;, &#39;Chrome&#39;, &#39;Safari&#39;, &#39;IE10&#39;, &#39;Konqueror&#39;]
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;http_status&#39;: [200, 200, 404, 404, 301],
 |      ...                   &#39;response_time&#39;: [0.04, 0.02, 0.07, 0.08, 1.0]},
 |      ...                   index=index)
 |      &gt;&gt;&gt; df
 |                 http_status  response_time
 |      Firefox            200           0.04
 |      Chrome             200           0.02
 |      Safari             404           0.07
 |      IE10               404           0.08
 |      Konqueror          301           1.00
 |      
 |      Create a new index and reindex the dataframe. By default
 |      values in the new index that do not have corresponding
 |      records in the dataframe are assigned ``NaN``.
 |      
 |      &gt;&gt;&gt; new_index = [&#39;Safari&#39;, &#39;Iceweasel&#39;, &#39;Comodo Dragon&#39;, &#39;IE10&#39;,
 |      ...              &#39;Chrome&#39;]
 |      &gt;&gt;&gt; df.reindex(new_index)
 |                     http_status  response_time
 |      Safari               404.0           0.07
 |      Iceweasel              NaN            NaN
 |      Comodo Dragon          NaN            NaN
 |      IE10                 404.0           0.08
 |      Chrome               200.0           0.02
 |      
 |      We can fill in the missing values by passing a value to
 |      the keyword ``fill_value``. Because the index is not monotonically
 |      increasing or decreasing, we cannot use arguments to the keyword
 |      ``method`` to fill the ``NaN`` values.
 |      
 |      &gt;&gt;&gt; df.reindex(new_index, fill_value=0)
 |                     http_status  response_time
 |      Safari                 404           0.07
 |      Iceweasel                0           0.00
 |      Comodo Dragon            0           0.00
 |      IE10                   404           0.08
 |      Chrome                 200           0.02
 |      
 |      &gt;&gt;&gt; df.reindex(new_index, fill_value=&#39;missing&#39;)
 |                    http_status response_time
 |      Safari                404          0.07
 |      Iceweasel         missing       missing
 |      Comodo Dragon     missing       missing
 |      IE10                  404          0.08
 |      Chrome                200          0.02
 |      
 |      We can also reindex the columns.
 |      
 |      &gt;&gt;&gt; df.reindex(columns=[&#39;http_status&#39;, &#39;user_agent&#39;])
 |                 http_status  user_agent
 |      Firefox            200         NaN
 |      Chrome             200         NaN
 |      Safari             404         NaN
 |      IE10               404         NaN
 |      Konqueror          301         NaN
 |      
 |      Or we can use &quot;axis-style&quot; keyword arguments
 |      
 |      &gt;&gt;&gt; df.reindex([&#39;http_status&#39;, &#39;user_agent&#39;], axis=&quot;columns&quot;)
 |                 http_status  user_agent
 |      Firefox            200         NaN
 |      Chrome             200         NaN
 |      Safari             404         NaN
 |      IE10               404         NaN
 |      Konqueror          301         NaN
 |      
 |      To further illustrate the filling functionality in
 |      ``reindex``, we will create a dataframe with a
 |      monotonically increasing index (for example, a sequence
 |      of dates).
 |      
 |      &gt;&gt;&gt; date_index = pd.date_range(&#39;1/1/2010&#39;, periods=6, freq=&#39;D&#39;)
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&quot;prices&quot;: [100, 101, np.nan, 100, 89, 88]},
 |      ...                    index=date_index)
 |      &gt;&gt;&gt; df2
 |                  prices
 |      2010-01-01   100.0
 |      2010-01-02   101.0
 |      2010-01-03     NaN
 |      2010-01-04   100.0
 |      2010-01-05    89.0
 |      2010-01-06    88.0
 |      
 |      Suppose we decide to expand the dataframe to cover a wider
 |      date range.
 |      
 |      &gt;&gt;&gt; date_index2 = pd.date_range(&#39;12/29/2009&#39;, periods=10, freq=&#39;D&#39;)
 |      &gt;&gt;&gt; df2.reindex(date_index2)
 |                  prices
 |      2009-12-29     NaN
 |      2009-12-30     NaN
 |      2009-12-31     NaN
 |      2010-01-01   100.0
 |      2010-01-02   101.0
 |      2010-01-03     NaN
 |      2010-01-04   100.0
 |      2010-01-05    89.0
 |      2010-01-06    88.0
 |      2010-01-07     NaN
 |      
 |      The index entries that did not have a value in the original data frame
 |      (for example, &#39;2009-12-29&#39;) are by default filled with ``NaN``.
 |      If desired, we can fill in the missing values using one of several
 |      options.
 |      
 |      For example, to back-propagate the last valid value to fill the ``NaN``
 |      values, pass ``bfill`` as an argument to the ``method`` keyword.
 |      
 |      &gt;&gt;&gt; df2.reindex(date_index2, method=&#39;bfill&#39;)
 |                  prices
 |      2009-12-29   100.0
 |      2009-12-30   100.0
 |      2009-12-31   100.0
 |      2010-01-01   100.0
 |      2010-01-02   101.0
 |      2010-01-03     NaN
 |      2010-01-04   100.0
 |      2010-01-05    89.0
 |      2010-01-06    88.0
 |      2010-01-07     NaN
 |      
 |      Please note that the ``NaN`` value present in the original dataframe
 |      (at index value 2010-01-03) will not be filled by any of the
 |      value propagation schemes. This is because filling while reindexing
 |      does not look at dataframe values, but only compares the original and
 |      desired indexes. If you do want to fill in the ``NaN`` values present
 |      in the original dataframe, use the ``fillna()`` method.
 |      
 |      See the :ref:`user guide &lt;basics.reindexing&gt;` for more.
 |  
 |  rename(self, index: &#39;Renamer | Hashable | None&#39; = None, *, axis: &#39;Axis | None&#39; = None, copy: &#39;bool&#39; = True, inplace: &#39;bool&#39; = False, level: &#39;Level | None&#39; = None, errors: &#39;IgnoreRaise&#39; = &#39;ignore&#39;) -&gt; &#39;Series | None&#39;
 |      Alter Series index labels or name.
 |      
 |      Function / dict values must be unique (1-to-1). Labels not contained in
 |      a dict / Series will be left as-is. Extra labels listed don&#39;t throw an
 |      error.
 |      
 |      Alternatively, change ``Series.name`` with a scalar value.
 |      
 |      See the :ref:`user guide &lt;basics.rename&gt;` for more.
 |      
 |      Parameters
 |      ----------
 |      index : scalar, hashable sequence, dict-like or function optional
 |          Functions or dict-like are transformations to apply to
 |          the index.
 |          Scalar or hashable sequence-like will alter the ``Series.name``
 |          attribute.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      copy : bool, default True
 |          Also copy underlying data.
 |      inplace : bool, default False
 |          Whether to return a new Series. If True the value of copy is ignored.
 |      level : int or level name, default None
 |          In case of MultiIndex, only rename labels in the specified level.
 |      errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;ignore&#39;
 |          If &#39;raise&#39;, raise `KeyError` when a `dict-like mapper` or
 |          `index` contains labels that are not present in the index being transformed.
 |          If &#39;ignore&#39;, existing keys will be renamed and extra keys will be ignored.
 |      
 |      Returns
 |      -------
 |      Series or None
 |          Series with index labels or name altered or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.rename : Corresponding DataFrame method.
 |      Series.rename_axis : Set the name of the axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      dtype: int64
 |      &gt;&gt;&gt; s.rename(&quot;my_name&quot;)  # scalar, changes Series.name
 |      0    1
 |      1    2
 |      2    3
 |      Name: my_name, dtype: int64
 |      &gt;&gt;&gt; s.rename(lambda x: x ** 2)  # function, changes labels
 |      0    1
 |      1    2
 |      4    3
 |      dtype: int64
 |      &gt;&gt;&gt; s.rename({1: 3, 2: 5})  # mapping, changes labels
 |      0    1
 |      3    2
 |      5    3
 |      dtype: int64
 |  
 |  rename_axis(self: &#39;Series&#39;, mapper: &#39;IndexLabel | lib.NoDefault&#39; = &lt;no_default&gt;, *, index=&lt;no_default&gt;, axis: &#39;Axis&#39; = 0, copy: &#39;bool&#39; = True, inplace: &#39;bool&#39; = False) -&gt; &#39;Series | None&#39;
 |      Set the name of the axis for the index or columns.
 |      
 |      Parameters
 |      ----------
 |      mapper : scalar, list-like, optional
 |          Value to set the axis name attribute.
 |      index, columns : scalar, list-like, dict-like or function, optional
 |          A scalar, list-like, dict-like or functions transformations to
 |          apply to that axis&#39; values.
 |          Note that the ``columns`` parameter is not allowed if the
 |          object is a Series. This parameter only apply for DataFrame
 |          type objects.
 |      
 |          Use either ``mapper`` and ``axis`` to
 |          specify the axis to target with ``mapper``, or ``index``
 |          and/or ``columns``.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to rename. For `Series` this parameter is unused and defaults to 0.
 |      copy : bool, default None
 |          Also copy underlying data.
 |      inplace : bool, default False
 |          Modifies the object directly, instead of creating a new Series
 |          or DataFrame.
 |      
 |      Returns
 |      -------
 |      Series, DataFrame, or None
 |          The same type as the caller or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.rename : Alter Series index labels or name.
 |      DataFrame.rename : Alter DataFrame index labels or name.
 |      Index.rename : Set new names on index.
 |      
 |      Notes
 |      -----
 |      ``DataFrame.rename_axis`` supports two calling conventions
 |      
 |      * ``(index=index_mapper, columns=columns_mapper, ...)``
 |      * ``(mapper, axis={&#39;index&#39;, &#39;columns&#39;}, ...)``
 |      
 |      The first calling convention will only modify the names of
 |      the index and/or the names of the Index object that is the columns.
 |      In this case, the parameter ``copy`` is ignored.
 |      
 |      The second calling convention will modify the names of the
 |      corresponding index if mapper is a list or a scalar.
 |      However, if mapper is dict-like or a function, it will use the
 |      deprecated behavior of modifying the axis *labels*.
 |      
 |      We *highly* recommend using keyword arguments to clarify your
 |      intent.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([&quot;dog&quot;, &quot;cat&quot;, &quot;monkey&quot;])
 |      &gt;&gt;&gt; s
 |      0       dog
 |      1       cat
 |      2    monkey
 |      dtype: object
 |      &gt;&gt;&gt; s.rename_axis(&quot;animal&quot;)
 |      animal
 |      0    dog
 |      1    cat
 |      2    monkey
 |      dtype: object
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;num_legs&quot;: [4, 4, 2],
 |      ...                    &quot;num_arms&quot;: [0, 0, 2]},
 |      ...                   [&quot;dog&quot;, &quot;cat&quot;, &quot;monkey&quot;])
 |      &gt;&gt;&gt; df
 |              num_legs  num_arms
 |      dog            4         0
 |      cat            4         0
 |      monkey         2         2
 |      &gt;&gt;&gt; df = df.rename_axis(&quot;animal&quot;)
 |      &gt;&gt;&gt; df
 |              num_legs  num_arms
 |      animal
 |      dog            4         0
 |      cat            4         0
 |      monkey         2         2
 |      &gt;&gt;&gt; df = df.rename_axis(&quot;limbs&quot;, axis=&quot;columns&quot;)
 |      &gt;&gt;&gt; df
 |      limbs   num_legs  num_arms
 |      animal
 |      dog            4         0
 |      cat            4         0
 |      monkey         2         2
 |      
 |      **MultiIndex**
 |      
 |      &gt;&gt;&gt; df.index = pd.MultiIndex.from_product([[&#39;mammal&#39;],
 |      ...                                        [&#39;dog&#39;, &#39;cat&#39;, &#39;monkey&#39;]],
 |      ...                                       names=[&#39;type&#39;, &#39;name&#39;])
 |      &gt;&gt;&gt; df
 |      limbs          num_legs  num_arms
 |      type   name
 |      mammal dog            4         0
 |             cat            4         0
 |             monkey         2         2
 |      
 |      &gt;&gt;&gt; df.rename_axis(index={&#39;type&#39;: &#39;class&#39;})
 |      limbs          num_legs  num_arms
 |      class  name
 |      mammal dog            4         0
 |             cat            4         0
 |             monkey         2         2
 |      
 |      &gt;&gt;&gt; df.rename_axis(columns=str.upper)
 |      LIMBS          num_legs  num_arms
 |      type   name
 |      mammal dog            4         0
 |             cat            4         0
 |             monkey         2         2
 |  
 |  reorder_levels(self, order: &#39;Sequence[Level]&#39;) -&gt; &#39;Series&#39;
 |      Rearrange index levels using input order.
 |      
 |      May not drop or duplicate levels.
 |      
 |      Parameters
 |      ----------
 |      order : list of int representing new level order
 |          Reference level by number or key.
 |      
 |      Returns
 |      -------
 |      type of caller (new object)
 |  
 |  repeat(self, repeats: &#39;int | Sequence[int]&#39;, axis: &#39;None&#39; = None) -&gt; &#39;Series&#39;
 |      Repeat elements of a Series.
 |      
 |      Returns a new Series where each element of the current Series
 |      is repeated consecutively a given number of times.
 |      
 |      Parameters
 |      ----------
 |      repeats : int or array of ints
 |          The number of repetitions for each element. This should be a
 |          non-negative integer. Repeating 0 times will return an empty
 |          Series.
 |      axis : None
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          Newly created Series with repeated elements.
 |      
 |      See Also
 |      --------
 |      Index.repeat : Equivalent function for Index.
 |      numpy.repeat : Similar method for :class:`numpy.ndarray`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; s
 |      0    a
 |      1    b
 |      2    c
 |      dtype: object
 |      &gt;&gt;&gt; s.repeat(2)
 |      0    a
 |      0    a
 |      1    b
 |      1    b
 |      2    c
 |      2    c
 |      dtype: object
 |      &gt;&gt;&gt; s.repeat([1, 2, 3])
 |      0    a
 |      1    b
 |      1    b
 |      2    c
 |      2    c
 |      2    c
 |      dtype: object
 |  
 |  replace(self, to_replace=None, value=&lt;no_default&gt;, *, inplace: &#39;bool&#39; = False, limit: &#39;int | None&#39; = None, regex: &#39;bool&#39; = False, method: &quot;Literal[&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;] | lib.NoDefault&quot; = &lt;no_default&gt;) -&gt; &#39;Series | None&#39;
 |      Replace values given in `to_replace` with `value`.
 |      
 |      Values of the Series are replaced with other values dynamically.
 |      
 |      This differs from updating with ``.loc`` or ``.iloc``, which require
 |      you to specify a location to update with some value.
 |      
 |      Parameters
 |      ----------
 |      to_replace : str, regex, list, dict, Series, int, float, or None
 |          How to find the values that will be replaced.
 |      
 |          * numeric, str or regex:
 |      
 |              - numeric: numeric values equal to `to_replace` will be
 |                replaced with `value`
 |              - str: string exactly matching `to_replace` will be replaced
 |                with `value`
 |              - regex: regexs matching `to_replace` will be replaced with
 |                `value`
 |      
 |          * list of str, regex, or numeric:
 |      
 |              - First, if `to_replace` and `value` are both lists, they
 |                **must** be the same length.
 |              - Second, if ``regex=True`` then all of the strings in **both**
 |                lists will be interpreted as regexs otherwise they will match
 |                directly. This doesn&#39;t matter much for `value` since there
 |                are only a few possible substitution regexes you can use.
 |              - str, regex and numeric rules apply as above.
 |      
 |          * dict:
 |      
 |              - Dicts can be used to specify different replacement values
 |                for different existing values. For example,
 |                ``{&#39;a&#39;: &#39;b&#39;, &#39;y&#39;: &#39;z&#39;}`` replaces the value &#39;a&#39; with &#39;b&#39; and
 |                &#39;y&#39; with &#39;z&#39;. To use a dict in this way, the optional `value`
 |                parameter should not be given.
 |              - For a DataFrame a dict can specify that different values
 |                should be replaced in different columns. For example,
 |                ``{&#39;a&#39;: 1, &#39;b&#39;: &#39;z&#39;}`` looks for the value 1 in column &#39;a&#39;
 |                and the value &#39;z&#39; in column &#39;b&#39; and replaces these values
 |                with whatever is specified in `value`. The `value` parameter
 |                should not be ``None`` in this case. You can treat this as a
 |                special case of passing two lists except that you are
 |                specifying the column to search in.
 |              - For a DataFrame nested dictionaries, e.g.,
 |                ``{&#39;a&#39;: {&#39;b&#39;: np.nan}}``, are read as follows: look in column
 |                &#39;a&#39; for the value &#39;b&#39; and replace it with NaN. The optional `value`
 |                parameter should not be specified to use a nested dict in this
 |                way. You can nest regular expressions as well. Note that
 |                column names (the top-level dictionary keys in a nested
 |                dictionary) **cannot** be regular expressions.
 |      
 |          * None:
 |      
 |              - This means that the `regex` argument must be a string,
 |                compiled regular expression, or list, dict, ndarray or
 |                Series of such elements. If `value` is also ``None`` then
 |                this **must** be a nested dictionary or Series.
 |      
 |          See the examples section for examples of each of these.
 |      value : scalar, dict, list, str, regex, default None
 |          Value to replace any values matching `to_replace` with.
 |          For a DataFrame a dict of values can be used to specify which
 |          value to use for each column (columns not in the dict will not be
 |          filled). Regular expressions, strings and lists or dicts of such
 |          objects are also allowed.
 |      inplace : bool, default False
 |          If True, performs operation inplace and returns None.
 |      limit : int, default None
 |          Maximum size gap to forward or backward fill.
 |      regex : bool or same types as `to_replace`, default False
 |          Whether to interpret `to_replace` and/or `value` as regular
 |          expressions. If this is ``True`` then `to_replace` *must* be a
 |          string. Alternatively, this could be a regular expression or a
 |          list, dict, or array of regular expressions in which case
 |          `to_replace` must be ``None``.
 |      method : {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;}
 |          The method to use when for replacement, when `to_replace` is a
 |          scalar, list or tuple and `value` is ``None``.
 |      
 |      Returns
 |      -------
 |      Series
 |          Object after replacement.
 |      
 |      Raises
 |      ------
 |      AssertionError
 |          * If `regex` is not a ``bool`` and `to_replace` is not
 |            ``None``.
 |      
 |      TypeError
 |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``
 |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,
 |            ``dict``, ``ndarray``, or ``Series``
 |          * If `to_replace` is ``None`` and `regex` is not compilable
 |            into a regular expression or is a list, dict, ndarray, or
 |            Series.
 |          * When replacing multiple ``bool`` or ``datetime64`` objects and
 |            the arguments to `to_replace` does not match the type of the
 |            value being replaced
 |      
 |      ValueError
 |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and
 |            `value` but they are not the same length.
 |      
 |      See Also
 |      --------
 |      Series.fillna : Fill NA values.
 |      Series.where : Replace values based on boolean condition.
 |      Series.str.replace : Simple string replacement.
 |      
 |      Notes
 |      -----
 |      * Regex substitution is performed under the hood with ``re.sub``. The
 |        rules for substitution for ``re.sub`` are the same.
 |      * Regular expressions will only substitute on strings, meaning you
 |        cannot provide, for example, a regular expression matching floating
 |        point numbers and expect the columns in your frame that have a
 |        numeric dtype to be matched. However, if those floating point
 |        numbers *are* strings, then you can do this.
 |      * This method has *a lot* of options. You are encouraged to experiment
 |        and play with this method to gain intuition about how it works.
 |      * When dict is used as the `to_replace` value, it is like
 |        key(s) in the dict are the to_replace part and
 |        value(s) in the dict are the value parameter.
 |      
 |      Examples
 |      --------
 |      
 |      **Scalar `to_replace` and `value`**
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4, 5])
 |      &gt;&gt;&gt; s.replace(1, 5)
 |      0    5
 |      1    2
 |      2    3
 |      3    4
 |      4    5
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [0, 1, 2, 3, 4],
 |      ...                    &#39;B&#39;: [5, 6, 7, 8, 9],
 |      ...                    &#39;C&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]})
 |      &gt;&gt;&gt; df.replace(0, 5)
 |          A  B  C
 |      0  5  5  a
 |      1  1  6  b
 |      2  2  7  c
 |      3  3  8  d
 |      4  4  9  e
 |      
 |      **List-like `to_replace`**
 |      
 |      &gt;&gt;&gt; df.replace([0, 1, 2, 3], 4)
 |          A  B  C
 |      0  4  5  a
 |      1  4  6  b
 |      2  4  7  c
 |      3  4  8  d
 |      4  4  9  e
 |      
 |      &gt;&gt;&gt; df.replace([0, 1, 2, 3], [4, 3, 2, 1])
 |          A  B  C
 |      0  4  5  a
 |      1  3  6  b
 |      2  2  7  c
 |      3  1  8  d
 |      4  4  9  e
 |      
 |      &gt;&gt;&gt; s.replace([1, 2], method=&#39;bfill&#39;)
 |      0    3
 |      1    3
 |      2    3
 |      3    4
 |      4    5
 |      dtype: int64
 |      
 |      **dict-like `to_replace`**
 |      
 |      &gt;&gt;&gt; df.replace({0: 10, 1: 100})
 |              A  B  C
 |      0   10  5  a
 |      1  100  6  b
 |      2    2  7  c
 |      3    3  8  d
 |      4    4  9  e
 |      
 |      &gt;&gt;&gt; df.replace({&#39;A&#39;: 0, &#39;B&#39;: 5}, 100)
 |              A    B  C
 |      0  100  100  a
 |      1    1    6  b
 |      2    2    7  c
 |      3    3    8  d
 |      4    4    9  e
 |      
 |      &gt;&gt;&gt; df.replace({&#39;A&#39;: {0: 100, 4: 400}})
 |              A  B  C
 |      0  100  5  a
 |      1    1  6  b
 |      2    2  7  c
 |      3    3  8  d
 |      4  400  9  e
 |      
 |      **Regular expression `to_replace`**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;bat&#39;, &#39;foo&#39;, &#39;bait&#39;],
 |      ...                    &#39;B&#39;: [&#39;abc&#39;, &#39;bar&#39;, &#39;xyz&#39;]})
 |      &gt;&gt;&gt; df.replace(to_replace=r&#39;^ba.$&#39;, value=&#39;new&#39;, regex=True)
 |              A    B
 |      0   new  abc
 |      1   foo  new
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace({&#39;A&#39;: r&#39;^ba.$&#39;}, {&#39;A&#39;: &#39;new&#39;}, regex=True)
 |              A    B
 |      0   new  abc
 |      1   foo  bar
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace(regex=r&#39;^ba.$&#39;, value=&#39;new&#39;)
 |              A    B
 |      0   new  abc
 |      1   foo  new
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace(regex={r&#39;^ba.$&#39;: &#39;new&#39;, &#39;foo&#39;: &#39;xyz&#39;})
 |              A    B
 |      0   new  abc
 |      1   xyz  new
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace(regex=[r&#39;^ba.$&#39;, &#39;foo&#39;], value=&#39;new&#39;)
 |              A    B
 |      0   new  abc
 |      1   new  new
 |      2  bait  xyz
 |      
 |      Compare the behavior of ``s.replace({&#39;a&#39;: None})`` and
 |      ``s.replace(&#39;a&#39;, None)`` to understand the peculiarities
 |      of the `to_replace` parameter:
 |      
 |      &gt;&gt;&gt; s = pd.Series([10, &#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;a&#39;])
 |      
 |      When one uses a dict as the `to_replace` value, it is like the
 |      value(s) in the dict are equal to the `value` parameter.
 |      ``s.replace({&#39;a&#39;: None})`` is equivalent to
 |      ``s.replace(to_replace={&#39;a&#39;: None}, value=None, method=None)``:
 |      
 |      &gt;&gt;&gt; s.replace({&#39;a&#39;: None})
 |      0      10
 |      1    None
 |      2    None
 |      3       b
 |      4    None
 |      dtype: object
 |      
 |      When ``value`` is not explicitly passed and `to_replace` is a scalar, list
 |      or tuple, `replace` uses the method parameter (default &#39;pad&#39;) to do the
 |      replacement. So this is why the &#39;a&#39; values are being replaced by 10
 |      in rows 1 and 2 and &#39;b&#39; in row 4 in this case.
 |      
 |      &gt;&gt;&gt; s.replace(&#39;a&#39;)
 |      0    10
 |      1    10
 |      2    10
 |      3     b
 |      4     b
 |      dtype: object
 |      
 |      On the other hand, if ``None`` is explicitly passed for ``value``, it will
 |      be respected:
 |      
 |      &gt;&gt;&gt; s.replace(&#39;a&#39;, None)
 |      0      10
 |      1    None
 |      2    None
 |      3       b
 |      4    None
 |      dtype: object
 |      
 |          .. versionchanged:: 1.4.0
 |              Previously the explicit ``None`` was silently ignored.
 |  
 |  resample(self, rule, axis: &#39;Axis&#39; = 0, closed: &#39;str | None&#39; = None, label: &#39;str | None&#39; = None, convention: &#39;str&#39; = &#39;start&#39;, kind: &#39;str | None&#39; = None, on: &#39;Level&#39; = None, level: &#39;Level&#39; = None, origin: &#39;str | TimestampConvertibleTypes&#39; = &#39;start_day&#39;, offset: &#39;TimedeltaConvertibleTypes | None&#39; = None, group_keys: &#39;bool&#39; = False) -&gt; &#39;Resampler&#39;
 |      Resample time-series data.
 |      
 |      Convenience method for frequency conversion and resampling of time series.
 |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,
 |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like
 |      series/index to the ``on``/``level`` keyword parameter.
 |      
 |      Parameters
 |      ----------
 |      rule : DateOffset, Timedelta or str
 |          The offset string or object representing target conversion.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Which axis to use for up- or down-sampling. For `Series` this parameter
 |          is unused and defaults to 0. Must be
 |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.
 |      closed : {&#39;right&#39;, &#39;left&#39;}, default None
 |          Which side of bin interval is closed. The default is &#39;left&#39;
 |          for all frequency offsets except for &#39;M&#39;, &#39;A&#39;, &#39;Q&#39;, &#39;BM&#39;,
 |          &#39;BA&#39;, &#39;BQ&#39;, and &#39;W&#39; which all have a default of &#39;right&#39;.
 |      label : {&#39;right&#39;, &#39;left&#39;}, default None
 |          Which bin edge label to label bucket with. The default is &#39;left&#39;
 |          for all frequency offsets except for &#39;M&#39;, &#39;A&#39;, &#39;Q&#39;, &#39;BM&#39;,
 |          &#39;BA&#39;, &#39;BQ&#39;, and &#39;W&#39; which all have a default of &#39;right&#39;.
 |      convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}, default &#39;start&#39;
 |          For `PeriodIndex` only, controls whether to use the start or
 |          end of `rule`.
 |      kind : {&#39;timestamp&#39;, &#39;period&#39;}, optional, default None
 |          Pass &#39;timestamp&#39; to convert the resulting index to a
 |          `DateTimeIndex` or &#39;period&#39; to convert it to a `PeriodIndex`.
 |          By default the input representation is retained.
 |      
 |      on : str, optional
 |          For a DataFrame, column to use instead of index for resampling.
 |          Column must be datetime-like.
 |      level : str or int, optional
 |          For a MultiIndex, level (name or number) to use for
 |          resampling. `level` must be datetime-like.
 |      origin : Timestamp or str, default &#39;start_day&#39;
 |          The timestamp on which to adjust the grouping. The timezone of origin
 |          must match the timezone of the index.
 |          If string, must be one of the following:
 |      
 |          - &#39;epoch&#39;: `origin` is 1970-01-01
 |          - &#39;start&#39;: `origin` is the first value of the timeseries
 |          - &#39;start_day&#39;: `origin` is the first day at midnight of the timeseries
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          - &#39;end&#39;: `origin` is the last value of the timeseries
 |          - &#39;end_day&#39;: `origin` is the ceiling midnight of the last day
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      offset : Timedelta or str, default is None
 |          An offset timedelta added to the origin.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      group_keys : bool, default False
 |          Whether to include the group keys in the result index when using
 |          ``.apply()`` on the resampled object.
 |      
 |          .. versionadded:: 1.5.0
 |      
 |              Not specifying ``group_keys`` will retain values-dependent behavior
 |              from pandas 1.4 and earlier (see :ref:`pandas 1.5.0 Release notes
 |              &lt;whatsnew_150.enhancements.resample_group_keys&gt;` for examples).
 |      
 |          .. versionchanged:: 2.0.0
 |      
 |              ``group_keys`` now defaults to ``False``.
 |      
 |      Returns
 |      -------
 |      pandas.core.Resampler
 |          :class:`~pandas.core.Resampler` object.
 |      
 |      See Also
 |      --------
 |      Series.resample : Resample a Series.
 |      DataFrame.resample : Resample a DataFrame.
 |      groupby : Group Series by mapping, function, label, or list of labels.
 |      asfreq : Reindex a Series with the given frequency without grouping.
 |      
 |      Notes
 |      -----
 |      See the `user guide
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling&gt;`__
 |      for more.
 |      
 |      To learn more about the offset strings, please see `this link
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects&gt;`__.
 |      
 |      Examples
 |      --------
 |      Start by creating a series with 9 one minute timestamps.
 |      
 |      &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
 |      &gt;&gt;&gt; series = pd.Series(range(9), index=index)
 |      &gt;&gt;&gt; series
 |      2000-01-01 00:00:00    0
 |      2000-01-01 00:01:00    1
 |      2000-01-01 00:02:00    2
 |      2000-01-01 00:03:00    3
 |      2000-01-01 00:04:00    4
 |      2000-01-01 00:05:00    5
 |      2000-01-01 00:06:00    6
 |      2000-01-01 00:07:00    7
 |      2000-01-01 00:08:00    8
 |      Freq: T, dtype: int64
 |      
 |      Downsample the series into 3 minute bins and sum the values
 |      of the timestamps falling into a bin.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;).sum()
 |      2000-01-01 00:00:00     3
 |      2000-01-01 00:03:00    12
 |      2000-01-01 00:06:00    21
 |      Freq: 3T, dtype: int64
 |      
 |      Downsample the series into 3 minute bins as above, but label each
 |      bin using the right edge instead of the left. Please note that the
 |      value in the bucket used as the label is not included in the bucket,
 |      which it labels. For example, in the original series the
 |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
 |      value in the resampled bucket with the label ``2000-01-01 00:03:00``
 |      does not include 3 (if it did, the summed value would be 6, not 3).
 |      To include this value close the right side of the bin interval as
 |      illustrated in the example below this one.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;, label=&#39;right&#39;).sum()
 |      2000-01-01 00:03:00     3
 |      2000-01-01 00:06:00    12
 |      2000-01-01 00:09:00    21
 |      Freq: 3T, dtype: int64
 |      
 |      Downsample the series into 3 minute bins as above, but close the right
 |      side of the bin interval.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;, label=&#39;right&#39;, closed=&#39;right&#39;).sum()
 |      2000-01-01 00:00:00     0
 |      2000-01-01 00:03:00     6
 |      2000-01-01 00:06:00    15
 |      2000-01-01 00:09:00    15
 |      Freq: 3T, dtype: int64
 |      
 |      Upsample the series into 30 second bins.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;30S&#39;).asfreq()[0:5]   # Select first 5 rows
 |      2000-01-01 00:00:00   0.0
 |      2000-01-01 00:00:30   NaN
 |      2000-01-01 00:01:00   1.0
 |      2000-01-01 00:01:30   NaN
 |      2000-01-01 00:02:00   2.0
 |      Freq: 30S, dtype: float64
 |      
 |      Upsample the series into 30 second bins and fill the ``NaN``
 |      values using the ``ffill`` method.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;30S&#39;).ffill()[0:5]
 |      2000-01-01 00:00:00    0
 |      2000-01-01 00:00:30    0
 |      2000-01-01 00:01:00    1
 |      2000-01-01 00:01:30    1
 |      2000-01-01 00:02:00    2
 |      Freq: 30S, dtype: int64
 |      
 |      Upsample the series into 30 second bins and fill the
 |      ``NaN`` values using the ``bfill`` method.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;30S&#39;).bfill()[0:5]
 |      2000-01-01 00:00:00    0
 |      2000-01-01 00:00:30    1
 |      2000-01-01 00:01:00    1
 |      2000-01-01 00:01:30    2
 |      2000-01-01 00:02:00    2
 |      Freq: 30S, dtype: int64
 |      
 |      Pass a custom function via ``apply``
 |      
 |      &gt;&gt;&gt; def custom_resampler(arraylike):
 |      ...     return np.sum(arraylike) + 5
 |      ...
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;).apply(custom_resampler)
 |      2000-01-01 00:00:00     8
 |      2000-01-01 00:03:00    17
 |      2000-01-01 00:06:00    26
 |      Freq: 3T, dtype: int64
 |      
 |      For a Series with a PeriodIndex, the keyword `convention` can be
 |      used to control whether to use the start or end of `rule`.
 |      
 |      Resample a year by quarter using &#39;start&#39; `convention`. Values are
 |      assigned to the first quarter of the period.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2], index=pd.period_range(&#39;2012-01-01&#39;,
 |      ...                                             freq=&#39;A&#39;,
 |      ...                                             periods=2))
 |      &gt;&gt;&gt; s
 |      2012    1
 |      2013    2
 |      Freq: A-DEC, dtype: int64
 |      &gt;&gt;&gt; s.resample(&#39;Q&#39;, convention=&#39;start&#39;).asfreq()
 |      2012Q1    1.0
 |      2012Q2    NaN
 |      2012Q3    NaN
 |      2012Q4    NaN
 |      2013Q1    2.0
 |      2013Q2    NaN
 |      2013Q3    NaN
 |      2013Q4    NaN
 |      Freq: Q-DEC, dtype: float64
 |      
 |      Resample quarters by month using &#39;end&#39; `convention`. Values are
 |      assigned to the last month of the period.
 |      
 |      &gt;&gt;&gt; q = pd.Series([1, 2, 3, 4], index=pd.period_range(&#39;2018-01-01&#39;,
 |      ...                                                   freq=&#39;Q&#39;,
 |      ...                                                   periods=4))
 |      &gt;&gt;&gt; q
 |      2018Q1    1
 |      2018Q2    2
 |      2018Q3    3
 |      2018Q4    4
 |      Freq: Q-DEC, dtype: int64
 |      &gt;&gt;&gt; q.resample(&#39;M&#39;, convention=&#39;end&#39;).asfreq()
 |      2018-03    1.0
 |      2018-04    NaN
 |      2018-05    NaN
 |      2018-06    2.0
 |      2018-07    NaN
 |      2018-08    NaN
 |      2018-09    3.0
 |      2018-10    NaN
 |      2018-11    NaN
 |      2018-12    4.0
 |      Freq: M, dtype: float64
 |      
 |      For DataFrame objects, the keyword `on` can be used to specify the
 |      column instead of the index for resampling.
 |      
 |      &gt;&gt;&gt; d = {&#39;price&#39;: [10, 11, 9, 13, 14, 18, 17, 19],
 |      ...      &#39;volume&#39;: [50, 60, 40, 100, 50, 100, 40, 50]}
 |      &gt;&gt;&gt; df = pd.DataFrame(d)
 |      &gt;&gt;&gt; df[&#39;week_starting&#39;] = pd.date_range(&#39;01/01/2018&#39;,
 |      ...                                     periods=8,
 |      ...                                     freq=&#39;W&#39;)
 |      &gt;&gt;&gt; df
 |         price  volume week_starting
 |      0     10      50    2018-01-07
 |      1     11      60    2018-01-14
 |      2      9      40    2018-01-21
 |      3     13     100    2018-01-28
 |      4     14      50    2018-02-04
 |      5     18     100    2018-02-11
 |      6     17      40    2018-02-18
 |      7     19      50    2018-02-25
 |      &gt;&gt;&gt; df.resample(&#39;M&#39;, on=&#39;week_starting&#39;).mean()
 |                     price  volume
 |      week_starting
 |      2018-01-31     10.75    62.5
 |      2018-02-28     17.00    60.0
 |      
 |      For a DataFrame with MultiIndex, the keyword `level` can be used to
 |      specify on which level the resampling needs to take place.
 |      
 |      &gt;&gt;&gt; days = pd.date_range(&#39;1/1/2000&#39;, periods=4, freq=&#39;D&#39;)
 |      &gt;&gt;&gt; d2 = {&#39;price&#39;: [10, 11, 9, 13, 14, 18, 17, 19],
 |      ...       &#39;volume&#39;: [50, 60, 40, 100, 50, 100, 40, 50]}
 |      &gt;&gt;&gt; df2 = pd.DataFrame(
 |      ...     d2,
 |      ...     index=pd.MultiIndex.from_product(
 |      ...         [days, [&#39;morning&#39;, &#39;afternoon&#39;]]
 |      ...     )
 |      ... )
 |      &gt;&gt;&gt; df2
 |                            price  volume
 |      2000-01-01 morning       10      50
 |                 afternoon     11      60
 |      2000-01-02 morning        9      40
 |                 afternoon     13     100
 |      2000-01-03 morning       14      50
 |                 afternoon     18     100
 |      2000-01-04 morning       17      40
 |                 afternoon     19      50
 |      &gt;&gt;&gt; df2.resample(&#39;D&#39;, level=0).sum()
 |                  price  volume
 |      2000-01-01     21     110
 |      2000-01-02     22     140
 |      2000-01-03     32     150
 |      2000-01-04     36      90
 |      
 |      If you want to adjust the start of the bins based on a fixed timestamp:
 |      
 |      &gt;&gt;&gt; start, end = &#39;2000-10-01 23:30:00&#39;, &#39;2000-10-02 00:30:00&#39;
 |      &gt;&gt;&gt; rng = pd.date_range(start, end, freq=&#39;7min&#39;)
 |      &gt;&gt;&gt; ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
 |      &gt;&gt;&gt; ts
 |      2000-10-01 23:30:00     0
 |      2000-10-01 23:37:00     3
 |      2000-10-01 23:44:00     6
 |      2000-10-01 23:51:00     9
 |      2000-10-01 23:58:00    12
 |      2000-10-02 00:05:00    15
 |      2000-10-02 00:12:00    18
 |      2000-10-02 00:19:00    21
 |      2000-10-02 00:26:00    24
 |      Freq: 7T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;).sum()
 |      2000-10-01 23:14:00     0
 |      2000-10-01 23:31:00     9
 |      2000-10-01 23:48:00    21
 |      2000-10-02 00:05:00    54
 |      2000-10-02 00:22:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;epoch&#39;).sum()
 |      2000-10-01 23:18:00     0
 |      2000-10-01 23:35:00    18
 |      2000-10-01 23:52:00    27
 |      2000-10-02 00:09:00    39
 |      2000-10-02 00:26:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;2000-01-01&#39;).sum()
 |      2000-10-01 23:24:00     3
 |      2000-10-01 23:41:00    15
 |      2000-10-01 23:58:00    45
 |      2000-10-02 00:15:00    45
 |      Freq: 17T, dtype: int64
 |      
 |      If you want to adjust the start of the bins with an `offset` Timedelta, the two
 |      following lines are equivalent:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;start&#39;).sum()
 |      2000-10-01 23:30:00     9
 |      2000-10-01 23:47:00    21
 |      2000-10-02 00:04:00    54
 |      2000-10-02 00:21:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, offset=&#39;23h30min&#39;).sum()
 |      2000-10-01 23:30:00     9
 |      2000-10-01 23:47:00    21
 |      2000-10-02 00:04:00    54
 |      2000-10-02 00:21:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      If you want to take the largest Timestamp as the end of the bins:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;end&#39;).sum()
 |      2000-10-01 23:35:00     0
 |      2000-10-01 23:52:00    18
 |      2000-10-02 00:09:00    27
 |      2000-10-02 00:26:00    63
 |      Freq: 17T, dtype: int64
 |      
 |      In contrast with the `start_day`, you can use `end_day` to take the ceiling
 |      midnight of the largest Timestamp as the end of the bins and drop the bins
 |      not containing data:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;end_day&#39;).sum()
 |      2000-10-01 23:38:00     3
 |      2000-10-01 23:55:00    15
 |      2000-10-02 00:12:00    45
 |      2000-10-02 00:29:00    45
 |      Freq: 17T, dtype: int64
 |  
 |  reset_index(self, level: &#39;IndexLabel&#39; = None, *, drop: &#39;bool&#39; = False, name: &#39;Level&#39; = &lt;no_default&gt;, inplace: &#39;bool&#39; = False, allow_duplicates: &#39;bool&#39; = False) -&gt; &#39;DataFrame | Series | None&#39;
 |      Generate a new DataFrame or Series with the index reset.
 |      
 |      This is useful when the index needs to be treated as a column, or
 |      when the index is meaningless and needs to be reset to the default
 |      before another operation.
 |      
 |      Parameters
 |      ----------
 |      level : int, str, tuple, or list, default optional
 |          For a Series with a MultiIndex, only remove the specified levels
 |          from the index. Removes all levels by default.
 |      drop : bool, default False
 |          Just reset the index, without inserting it as a column in
 |          the new DataFrame.
 |      name : object, optional
 |          The name to use for the column containing the original Series
 |          values. Uses ``self.name`` by default. This argument is ignored
 |          when `drop` is True.
 |      inplace : bool, default False
 |          Modify the Series in place (do not create a new object).
 |      allow_duplicates : bool, default False
 |          Allow duplicate column labels to be created.
 |      
 |          .. versionadded:: 1.5.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame or None
 |          When `drop` is False (the default), a DataFrame is returned.
 |          The newly created columns will come first in the DataFrame,
 |          followed by the original Series values.
 |          When `drop` is True, a `Series` is returned.
 |          In either case, if ``inplace=True``, no value is returned.
 |      
 |      See Also
 |      --------
 |      DataFrame.reset_index: Analogous function for DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4], name=&#39;foo&#39;,
 |      ...               index=pd.Index([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;], name=&#39;idx&#39;))
 |      
 |      Generate a DataFrame with default index.
 |      
 |      &gt;&gt;&gt; s.reset_index()
 |        idx  foo
 |      0   a    1
 |      1   b    2
 |      2   c    3
 |      3   d    4
 |      
 |      To specify the name of the new column use `name`.
 |      
 |      &gt;&gt;&gt; s.reset_index(name=&#39;values&#39;)
 |        idx  values
 |      0   a       1
 |      1   b       2
 |      2   c       3
 |      3   d       4
 |      
 |      To generate a new Series with the default set `drop` to True.
 |      
 |      &gt;&gt;&gt; s.reset_index(drop=True)
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      Name: foo, dtype: int64
 |      
 |      The `level` parameter is interesting for Series with a multi-level
 |      index.
 |      
 |      &gt;&gt;&gt; arrays = [np.array([&#39;bar&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;baz&#39;]),
 |      ...           np.array([&#39;one&#39;, &#39;two&#39;, &#39;one&#39;, &#39;two&#39;])]
 |      &gt;&gt;&gt; s2 = pd.Series(
 |      ...     range(4), name=&#39;foo&#39;,
 |      ...     index=pd.MultiIndex.from_arrays(arrays,
 |      ...                                     names=[&#39;a&#39;, &#39;b&#39;]))
 |      
 |      To remove a specific level from the Index, use `level`.
 |      
 |      &gt;&gt;&gt; s2.reset_index(level=&#39;a&#39;)
 |             a  foo
 |      b
 |      one  bar    0
 |      two  bar    1
 |      one  baz    2
 |      two  baz    3
 |      
 |      If `level` is not set, all levels are removed from the Index.
 |      
 |      &gt;&gt;&gt; s2.reset_index()
 |           a    b  foo
 |      0  bar  one    0
 |      1  bar  two    1
 |      2  baz  one    2
 |      3  baz  two    3
 |  
 |  rfloordiv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Integer division of series and other, element-wise (binary operator `rfloordiv`).
 |      
 |      Equivalent to ``other // series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.floordiv : Element-wise Integer division, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.floordiv(b, fill_value=0)
 |      a    1.0
 |      b    inf
 |      c    inf
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  rmod(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Modulo of series and other, element-wise (binary operator `rmod`).
 |      
 |      Equivalent to ``other % series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.mod : Element-wise Modulo, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.mod(b, fill_value=0)
 |      a    0.0
 |      b    NaN
 |      c    NaN
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  rmul(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Multiplication of series and other, element-wise (binary operator `rmul`).
 |      
 |      Equivalent to ``other * series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.mul : Element-wise Multiplication, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.multiply(b, fill_value=0)
 |      a    1.0
 |      b    0.0
 |      c    0.0
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  round(self, decimals: &#39;int&#39; = 0, *args, **kwargs) -&gt; &#39;Series&#39;
 |      Round each value in a Series to the given number of decimals.
 |      
 |      Parameters
 |      ----------
 |      decimals : int, default 0
 |          Number of decimal places to round to. If decimals is negative,
 |          it specifies the number of positions to the left of the decimal point.
 |      *args, **kwargs
 |          Additional arguments and keywords have no effect but might be
 |          accepted for compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series
 |          Rounded values of the Series.
 |      
 |      See Also
 |      --------
 |      numpy.around : Round values of an np.array.
 |      DataFrame.round : Round values of a DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([0.1, 1.3, 2.7])
 |      &gt;&gt;&gt; s.round()
 |      0    0.0
 |      1    1.0
 |      2    3.0
 |      dtype: float64
 |  
 |  rpow(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Exponential power of series and other, element-wise (binary operator `rpow`).
 |      
 |      Equivalent to ``other ** series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.pow : Element-wise Exponential power, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.pow(b, fill_value=0)
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  rsub(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Subtraction of series and other, element-wise (binary operator `rsub`).
 |      
 |      Equivalent to ``other - series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.sub : Element-wise Subtraction, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.subtract(b, fill_value=0)
 |      a    0.0
 |      b    1.0
 |      c    1.0
 |      d   -1.0
 |      e    NaN
 |      dtype: float64
 |  
 |  rtruediv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Floating division of series and other, element-wise (binary operator `rtruediv`).
 |      
 |      Equivalent to ``other / series``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.truediv : Element-wise Floating division, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.divide(b, fill_value=0)
 |      a    1.0
 |      b    inf
 |      c    inf
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  searchsorted(self, value: &#39;NumpyValueArrayLike | ExtensionArray&#39;, side: &quot;Literal[&#39;left&#39;, &#39;right&#39;]&quot; = &#39;left&#39;, sorter: &#39;NumpySorter&#39; = None) -&gt; &#39;npt.NDArray[np.intp] | np.intp&#39;
 |      Find indices where elements should be inserted to maintain order.
 |      
 |      Find the indices into a sorted Series `self` such that, if the
 |      corresponding elements in `value` were inserted before the indices,
 |      the order of `self` would be preserved.
 |      
 |      .. note::
 |      
 |          The Series *must* be monotonically sorted, otherwise
 |          wrong locations will likely be returned. Pandas does *not*
 |          check this for you.
 |      
 |      Parameters
 |      ----------
 |      value : array-like or scalar
 |          Values to insert into `self`.
 |      side : {&#39;left&#39;, &#39;right&#39;}, optional
 |          If &#39;left&#39;, the index of the first suitable location found is given.
 |          If &#39;right&#39;, return the last such index.  If there is no suitable
 |          index, return either 0 or N (where N is the length of `self`).
 |      sorter : 1-D array-like, optional
 |          Optional array of integer indices that sort `self` into ascending
 |          order. They are typically the result of ``np.argsort``.
 |      
 |      Returns
 |      -------
 |      int or array of int
 |          A scalar or array of insertion points with the
 |          same shape as `value`.
 |      
 |      See Also
 |      --------
 |      sort_values : Sort by the values along either axis.
 |      numpy.searchsorted : Similar method from NumPy.
 |      
 |      Notes
 |      -----
 |      Binary search is used to find the required insertion points.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; ser = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; ser
 |      0    1
 |      1    2
 |      2    3
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; ser.searchsorted(4)
 |      3
 |      
 |      &gt;&gt;&gt; ser.searchsorted([0, 4])
 |      array([0, 3])
 |      
 |      &gt;&gt;&gt; ser.searchsorted([1, 3], side=&#39;left&#39;)
 |      array([0, 2])
 |      
 |      &gt;&gt;&gt; ser.searchsorted([1, 3], side=&#39;right&#39;)
 |      array([1, 3])
 |      
 |      &gt;&gt;&gt; ser = pd.Series(pd.to_datetime([&#39;3/11/2000&#39;, &#39;3/12/2000&#39;, &#39;3/13/2000&#39;]))
 |      &gt;&gt;&gt; ser
 |      0   2000-03-11
 |      1   2000-03-12
 |      2   2000-03-13
 |      dtype: datetime64[ns]
 |      
 |      &gt;&gt;&gt; ser.searchsorted(&#39;3/14/2000&#39;)
 |      3
 |      
 |      &gt;&gt;&gt; ser = pd.Categorical(
 |      ...     [&#39;apple&#39;, &#39;bread&#39;, &#39;bread&#39;, &#39;cheese&#39;, &#39;milk&#39;], ordered=True
 |      ... )
 |      &gt;&gt;&gt; ser
 |      [&#39;apple&#39;, &#39;bread&#39;, &#39;bread&#39;, &#39;cheese&#39;, &#39;milk&#39;]
 |      Categories (4, object): [&#39;apple&#39; &lt; &#39;bread&#39; &lt; &#39;cheese&#39; &lt; &#39;milk&#39;]
 |      
 |      &gt;&gt;&gt; ser.searchsorted(&#39;bread&#39;)
 |      1
 |      
 |      &gt;&gt;&gt; ser.searchsorted([&#39;bread&#39;], side=&#39;right&#39;)
 |      array([3])
 |      
 |      If the values are not monotonically sorted, wrong locations
 |      may be returned:
 |      
 |      &gt;&gt;&gt; ser = pd.Series([2, 1, 3])
 |      &gt;&gt;&gt; ser
 |      0    2
 |      1    1
 |      2    3
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; ser.searchsorted(1)  # doctest: +SKIP
 |      0  # wrong result, correct would be 1
 |  
 |  sem(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, ddof: &#39;int&#39; = 1, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return unbiased standard error of the mean over requested axis.
 |      
 |      Normalized by N-1 by default. This can be changed using the ddof argument
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      ddof : int, default 1
 |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
 |          where N represents the number of elements.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      Returns
 |      -------
 |      scalar or Series (if level specified)
 |  
 |  set_axis(self, labels, *, axis: &#39;Axis&#39; = 0, copy: &#39;bool | None&#39; = None) -&gt; &#39;Series&#39;
 |      Assign desired index to given axis.
 |      
 |      Indexes for row labels can be changed by assigning
 |      a list-like or Index.
 |      
 |      Parameters
 |      ----------
 |      labels : list-like, Index
 |          The values for the new index.
 |      
 |      axis : {0 or &#39;index&#39;}, default 0
 |          The axis to update. The value 0 identifies the rows. For `Series`
 |          this parameter is unused and defaults to 0.
 |      
 |      copy : bool, default True
 |          Whether to make a copy of the underlying data.
 |      
 |          .. versionadded:: 1.5.0
 |      
 |      Returns
 |      -------
 |      Series
 |          An object of type Series.
 |      
 |      See Also
 |      --------
 |      Series.rename_axis : Alter the name of the index.
 |      
 |              Examples
 |              --------
 |              &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |              &gt;&gt;&gt; s
 |              0    1
 |              1    2
 |              2    3
 |              dtype: int64
 |      
 |              &gt;&gt;&gt; s.set_axis([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], axis=0)
 |              a    1
 |              b    2
 |              c    3
 |              dtype: int64
 |  
 |  shift(self, periods: &#39;int&#39; = 1, freq=None, axis: &#39;Axis&#39; = 0, fill_value: &#39;Hashable&#39; = None) -&gt; &#39;Series&#39;
 |      Shift index by desired number of periods with an optional time `freq`.
 |      
 |      When `freq` is not passed, shift the index without realigning the data.
 |      If `freq` is passed (in this case, the index must be date or datetime,
 |      or it will raise a `NotImplementedError`), the index will be
 |      increased using the periods and the `freq`. `freq` can be inferred
 |      when specified as &quot;infer&quot; as long as either freq or inferred_freq
 |      attribute is set in the index.
 |      
 |      Parameters
 |      ----------
 |      periods : int
 |          Number of periods to shift. Can be positive or negative.
 |      freq : DateOffset, tseries.offsets, timedelta, or str, optional
 |          Offset to use from the tseries module or time rule (e.g. &#39;EOM&#39;).
 |          If `freq` is specified then the index values are shifted but the
 |          data is not realigned. That is, use `freq` if you would like to
 |          extend the index when shifting and preserve the original data.
 |          If `freq` is specified as &quot;infer&quot; then it will be inferred from
 |          the freq or inferred_freq attributes of the index. If neither of
 |          those attributes exist, a ValueError is thrown.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default None
 |          Shift direction. For `Series` this parameter is unused and defaults to 0.
 |      fill_value : object, optional
 |          The scalar value to use for newly introduced missing values.
 |          the default depends on the dtype of `self`.
 |          For numeric data, ``np.nan`` is used.
 |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.
 |          For extension dtypes, ``self.dtype.na_value`` is used.
 |      
 |          .. versionchanged:: 1.1.0
 |      
 |      Returns
 |      -------
 |      Series
 |          Copy of input object, shifted.
 |      
 |      See Also
 |      --------
 |      Index.shift : Shift values of Index.
 |      DatetimeIndex.shift : Shift values of DatetimeIndex.
 |      PeriodIndex.shift : Shift values of PeriodIndex.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;Col1&quot;: [10, 20, 15, 30, 45],
 |      ...                    &quot;Col2&quot;: [13, 23, 18, 33, 48],
 |      ...                    &quot;Col3&quot;: [17, 27, 22, 37, 52]},
 |      ...                   index=pd.date_range(&quot;2020-01-01&quot;, &quot;2020-01-05&quot;))
 |      &gt;&gt;&gt; df
 |                  Col1  Col2  Col3
 |      2020-01-01    10    13    17
 |      2020-01-02    20    23    27
 |      2020-01-03    15    18    22
 |      2020-01-04    30    33    37
 |      2020-01-05    45    48    52
 |      
 |      &gt;&gt;&gt; df.shift(periods=3)
 |                  Col1  Col2  Col3
 |      2020-01-01   NaN   NaN   NaN
 |      2020-01-02   NaN   NaN   NaN
 |      2020-01-03   NaN   NaN   NaN
 |      2020-01-04  10.0  13.0  17.0
 |      2020-01-05  20.0  23.0  27.0
 |      
 |      &gt;&gt;&gt; df.shift(periods=1, axis=&quot;columns&quot;)
 |                  Col1  Col2  Col3
 |      2020-01-01   NaN    10    13
 |      2020-01-02   NaN    20    23
 |      2020-01-03   NaN    15    18
 |      2020-01-04   NaN    30    33
 |      2020-01-05   NaN    45    48
 |      
 |      &gt;&gt;&gt; df.shift(periods=3, fill_value=0)
 |                  Col1  Col2  Col3
 |      2020-01-01     0     0     0
 |      2020-01-02     0     0     0
 |      2020-01-03     0     0     0
 |      2020-01-04    10    13    17
 |      2020-01-05    20    23    27
 |      
 |      &gt;&gt;&gt; df.shift(periods=3, freq=&quot;D&quot;)
 |                  Col1  Col2  Col3
 |      2020-01-04    10    13    17
 |      2020-01-05    20    23    27
 |      2020-01-06    15    18    22
 |      2020-01-07    30    33    37
 |      2020-01-08    45    48    52
 |      
 |      &gt;&gt;&gt; df.shift(periods=3, freq=&quot;infer&quot;)
 |                  Col1  Col2  Col3
 |      2020-01-04    10    13    17
 |      2020-01-05    20    23    27
 |      2020-01-06    15    18    22
 |      2020-01-07    30    33    37
 |      2020-01-08    45    48    52
 |  
 |  skew(self, axis: &#39;AxisInt | None&#39; = 0, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return unbiased skew over requested axis.
 |      
 |      Normalized by N-1.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |  
 |  sort_index(self, *, axis: &#39;Axis&#39; = 0, level: &#39;IndexLabel&#39; = None, ascending: &#39;bool | Sequence[bool]&#39; = True, inplace: &#39;bool&#39; = False, kind: &#39;SortKind&#39; = &#39;quicksort&#39;, na_position: &#39;NaPosition&#39; = &#39;last&#39;, sort_remaining: &#39;bool&#39; = True, ignore_index: &#39;bool&#39; = False, key: &#39;IndexKeyFunc&#39; = None) -&gt; &#39;Series | None&#39;
 |      Sort Series by index labels.
 |      
 |      Returns a new Series sorted by label if `inplace` argument is
 |      ``False``, otherwise updates the original series and returns None.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      level : int, optional
 |          If not None, sort on values in specified index level(s).
 |      ascending : bool or list-like of bools, default True
 |          Sort ascending vs. descending. When the index is a MultiIndex the
 |          sort direction can be controlled for each level individually.
 |      inplace : bool, default False
 |          If True, perform operation in-place.
 |      kind : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
 |          Choice of sorting algorithm. See also :func:`numpy.sort` for more
 |          information. &#39;mergesort&#39; and &#39;stable&#39; are the only stable algorithms. For
 |          DataFrames, this option is only applied when sorting on a single
 |          column or label.
 |      na_position : {&#39;first&#39;, &#39;last&#39;}, default &#39;last&#39;
 |          If &#39;first&#39; puts NaNs at the beginning, &#39;last&#39; puts NaNs at the end.
 |          Not implemented for MultiIndex.
 |      sort_remaining : bool, default True
 |          If True and sorting by level and index is multilevel, sort by other
 |          levels too (in order) after sorting by specified level.
 |      ignore_index : bool, default False
 |          If True, the resulting axis will be labeled 0, 1, …, n - 1.
 |      key : callable, optional
 |          If not None, apply the key function to the index values
 |          before sorting. This is similar to the `key` argument in the
 |          builtin :meth:`sorted` function, with the notable difference that
 |          this `key` function should be *vectorized*. It should expect an
 |          ``Index`` and return an ``Index`` of the same shape.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      Series or None
 |          The original Series sorted by the labels or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.sort_index: Sort DataFrame by the index.
 |      DataFrame.sort_values: Sort DataFrame by the value.
 |      Series.sort_values : Sort Series by the value.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;], index=[3, 2, 1, 4])
 |      &gt;&gt;&gt; s.sort_index()
 |      1    c
 |      2    b
 |      3    a
 |      4    d
 |      dtype: object
 |      
 |      Sort Descending
 |      
 |      &gt;&gt;&gt; s.sort_index(ascending=False)
 |      4    d
 |      3    a
 |      2    b
 |      1    c
 |      dtype: object
 |      
 |      By default NaNs are put at the end, but use `na_position` to place
 |      them at the beginning
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;], index=[3, 2, 1, np.nan])
 |      &gt;&gt;&gt; s.sort_index(na_position=&#39;first&#39;)
 |      NaN     d
 |       1.0    c
 |       2.0    b
 |       3.0    a
 |      dtype: object
 |      
 |      Specify index level to sort
 |      
 |      &gt;&gt;&gt; arrays = [np.array([&#39;qux&#39;, &#39;qux&#39;, &#39;foo&#39;, &#39;foo&#39;,
 |      ...                     &#39;baz&#39;, &#39;baz&#39;, &#39;bar&#39;, &#39;bar&#39;]),
 |      ...           np.array([&#39;two&#39;, &#39;one&#39;, &#39;two&#39;, &#39;one&#39;,
 |      ...                     &#39;two&#39;, &#39;one&#39;, &#39;two&#39;, &#39;one&#39;])]
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)
 |      &gt;&gt;&gt; s.sort_index(level=1)
 |      bar  one    8
 |      baz  one    6
 |      foo  one    4
 |      qux  one    2
 |      bar  two    7
 |      baz  two    5
 |      foo  two    3
 |      qux  two    1
 |      dtype: int64
 |      
 |      Does not sort by remaining levels when sorting by levels
 |      
 |      &gt;&gt;&gt; s.sort_index(level=1, sort_remaining=False)
 |      qux  one    2
 |      foo  one    4
 |      baz  one    6
 |      bar  one    8
 |      qux  two    1
 |      foo  two    3
 |      baz  two    5
 |      bar  two    7
 |      dtype: int64
 |      
 |      Apply a key function before sorting
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4], index=[&#39;A&#39;, &#39;b&#39;, &#39;C&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; s.sort_index(key=lambda x : x.str.lower())
 |      A    1
 |      b    2
 |      C    3
 |      d    4
 |      dtype: int64
 |  
 |  sort_values(self, *, axis: &#39;Axis&#39; = 0, ascending: &#39;bool | int | Sequence[bool] | Sequence[int]&#39; = True, inplace: &#39;bool&#39; = False, kind: &#39;str&#39; = &#39;quicksort&#39;, na_position: &#39;str&#39; = &#39;last&#39;, ignore_index: &#39;bool&#39; = False, key: &#39;ValueKeyFunc&#39; = None) -&gt; &#39;Series | None&#39;
 |      Sort by the values.
 |      
 |      Sort a Series in ascending or descending order by some
 |      criterion.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      ascending : bool or list of bools, default True
 |          If True, sort values in ascending order, otherwise descending.
 |      inplace : bool, default False
 |          If True, perform operation in-place.
 |      kind : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
 |          Choice of sorting algorithm. See also :func:`numpy.sort` for more
 |          information. &#39;mergesort&#39; and &#39;stable&#39; are the only stable  algorithms.
 |      na_position : {&#39;first&#39; or &#39;last&#39;}, default &#39;last&#39;
 |          Argument &#39;first&#39; puts NaNs at the beginning, &#39;last&#39; puts NaNs at
 |          the end.
 |      ignore_index : bool, default False
 |          If True, the resulting axis will be labeled 0, 1, …, n - 1.
 |      key : callable, optional
 |          If not None, apply the key function to the series values
 |          before sorting. This is similar to the `key` argument in the
 |          builtin :meth:`sorted` function, with the notable difference that
 |          this `key` function should be *vectorized*. It should expect a
 |          ``Series`` and return an array-like.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      Series or None
 |          Series ordered by values or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.sort_index : Sort by the Series indices.
 |      DataFrame.sort_values : Sort DataFrame by the values along either axis.
 |      DataFrame.sort_index : Sort DataFrame by indices.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([np.nan, 1, 3, 10, 5])
 |      &gt;&gt;&gt; s
 |      0     NaN
 |      1     1.0
 |      2     3.0
 |      3     10.0
 |      4     5.0
 |      dtype: float64
 |      
 |      Sort values ascending order (default behaviour)
 |      
 |      &gt;&gt;&gt; s.sort_values(ascending=True)
 |      1     1.0
 |      2     3.0
 |      4     5.0
 |      3    10.0
 |      0     NaN
 |      dtype: float64
 |      
 |      Sort values descending order
 |      
 |      &gt;&gt;&gt; s.sort_values(ascending=False)
 |      3    10.0
 |      4     5.0
 |      2     3.0
 |      1     1.0
 |      0     NaN
 |      dtype: float64
 |      
 |      Sort values putting NAs first
 |      
 |      &gt;&gt;&gt; s.sort_values(na_position=&#39;first&#39;)
 |      0     NaN
 |      1     1.0
 |      2     3.0
 |      4     5.0
 |      3    10.0
 |      dtype: float64
 |      
 |      Sort a series of strings
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;z&#39;, &#39;b&#39;, &#39;d&#39;, &#39;a&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; s
 |      0    z
 |      1    b
 |      2    d
 |      3    a
 |      4    c
 |      dtype: object
 |      
 |      &gt;&gt;&gt; s.sort_values()
 |      3    a
 |      1    b
 |      4    c
 |      2    d
 |      0    z
 |      dtype: object
 |      
 |      Sort using a key function. Your `key` function will be
 |      given the ``Series`` of values and should return an array-like.
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;B&#39;, &#39;c&#39;, &#39;D&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; s.sort_values()
 |      1    B
 |      3    D
 |      0    a
 |      2    c
 |      4    e
 |      dtype: object
 |      &gt;&gt;&gt; s.sort_values(key=lambda x: x.str.lower())
 |      0    a
 |      1    B
 |      2    c
 |      3    D
 |      4    e
 |      dtype: object
 |      
 |      NumPy ufuncs work well here. For example, we can
 |      sort by the ``sin`` of the value
 |      
 |      &gt;&gt;&gt; s = pd.Series([-4, -2, 0, 2, 4])
 |      &gt;&gt;&gt; s.sort_values(key=np.sin)
 |      1   -2
 |      4    4
 |      2    0
 |      0   -4
 |      3    2
 |      dtype: int64
 |      
 |      More complicated user-defined functions can be used,
 |      as long as they expect a Series and return an array-like
 |      
 |      &gt;&gt;&gt; s.sort_values(key=lambda x: (np.tan(x.cumsum())))
 |      0   -4
 |      3    2
 |      4    4
 |      1   -2
 |      2    0
 |      dtype: int64
 |  
 |  std(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, ddof: &#39;int&#39; = 1, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return sample standard deviation over requested axis.
 |      
 |      Normalized by N-1 by default. This can be changed using the ddof argument.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      ddof : int, default 1
 |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
 |          where N represents the number of elements.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      Returns
 |      -------
 |      scalar or Series (if level specified) 
 |      
 |      Notes
 |      -----
 |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the
 |      default `ddof=1`)
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;person_id&#39;: [0, 1, 2, 3],
 |      ...                    &#39;age&#39;: [21, 25, 62, 43],
 |      ...                    &#39;height&#39;: [1.61, 1.87, 1.49, 2.01]}
 |      ...                   ).set_index(&#39;person_id&#39;)
 |      &gt;&gt;&gt; df
 |                 age  height
 |      person_id
 |      0           21    1.61
 |      1           25    1.87
 |      2           62    1.49
 |      3           43    2.01
 |      
 |      The standard deviation of the columns can be found as follows:
 |      
 |      &gt;&gt;&gt; df.std()
 |      age       18.786076
 |      height     0.237417
 |      dtype: float64
 |      
 |      Alternatively, `ddof=0` can be set to normalize by N instead of N-1:
 |      
 |      &gt;&gt;&gt; df.std(ddof=0)
 |      age       16.269219
 |      height     0.205609
 |      dtype: float64
 |  
 |  sub(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Subtraction of series and other, element-wise (binary operator `sub`).
 |      
 |      Equivalent to ``series - other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rsub : Reverse of the Subtraction operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.subtract(b, fill_value=0)
 |      a    0.0
 |      b    1.0
 |      c    1.0
 |      d   -1.0
 |      e    NaN
 |      dtype: float64
 |  
 |  subtract = sub(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |  
 |  sum(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, numeric_only: &#39;bool_t&#39; = False, min_count: &#39;int&#39; = 0, **kwargs)
 |      Return the sum of the values over the requested axis.
 |      
 |      This is equivalent to the method ``numpy.sum``.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          Axis for the function to be applied on.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |          For DataFrames, specifying ``axis=None`` will apply the aggregation
 |          across both axes.
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      min_count : int, default 0
 |          The required number of valid values to perform the operation. If fewer than
 |          ``min_count`` non-NA values are present the result will be NA.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      scalar or scalar
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.MultiIndex.from_arrays([
 |      ...     [&#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;],
 |      ...     [&#39;dog&#39;, &#39;falcon&#39;, &#39;fish&#39;, &#39;spider&#39;]],
 |      ...     names=[&#39;blooded&#39;, &#39;animal&#39;])
 |      &gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=&#39;legs&#39;, index=idx)
 |      &gt;&gt;&gt; s
 |      blooded  animal
 |      warm     dog       4
 |               falcon    2
 |      cold     fish      0
 |               spider    8
 |      Name: legs, dtype: int64
 |      
 |      &gt;&gt;&gt; s.sum()
 |      14
 |      
 |      By default, the sum of an empty or all-NA Series is ``0``.
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).sum()  # min_count=0 is the default
 |      0.0
 |      
 |      This can be controlled with the ``min_count`` parameter. For example, if
 |      you&#39;d like the sum of an empty series to be NaN, pass ``min_count=1``.
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).sum(min_count=1)
 |      nan
 |      
 |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and
 |      empty series identically.
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).sum()
 |      0.0
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).sum(min_count=1)
 |      nan
 |  
 |  swaplevel(self, i: &#39;Level&#39; = -2, j: &#39;Level&#39; = -1, copy: &#39;bool | None&#39; = None) -&gt; &#39;Series&#39;
 |      Swap levels i and j in a :class:`MultiIndex`.
 |      
 |      Default is to swap the two innermost levels of the index.
 |      
 |      Parameters
 |      ----------
 |      i, j : int or str
 |          Levels of the indices to be swapped. Can pass level name as string.
 |      copy : bool, default True
 |                  Whether to copy underlying data.
 |      
 |      Returns
 |      -------
 |      Series
 |          Series with levels swapped in MultiIndex.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(
 |      ...     [&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;],
 |      ...     index=[
 |      ...         [&quot;Final exam&quot;, &quot;Final exam&quot;, &quot;Coursework&quot;, &quot;Coursework&quot;],
 |      ...         [&quot;History&quot;, &quot;Geography&quot;, &quot;History&quot;, &quot;Geography&quot;],
 |      ...         [&quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;],
 |      ...     ],
 |      ... )
 |      &gt;&gt;&gt; s
 |      Final exam  History     January      A
 |                  Geography   February     B
 |      Coursework  History     March        A
 |                  Geography   April        C
 |      dtype: object
 |      
 |      In the following example, we will swap the levels of the indices.
 |      Here, we will swap the levels column-wise, but levels can be swapped row-wise
 |      in a similar manner. Note that column-wise is the default behaviour.
 |      By not supplying any arguments for i and j, we swap the last and second to
 |      last indices.
 |      
 |      &gt;&gt;&gt; s.swaplevel()
 |      Final exam  January     History         A
 |                  February    Geography       B
 |      Coursework  March       History         A
 |                  April       Geography       C
 |      dtype: object
 |      
 |      By supplying one argument, we can choose which index to swap the last
 |      index with. We can for example swap the first index with the last one as
 |      follows.
 |      
 |      &gt;&gt;&gt; s.swaplevel(0)
 |      January     History     Final exam      A
 |      February    Geography   Final exam      B
 |      March       History     Coursework      A
 |      April       Geography   Coursework      C
 |      dtype: object
 |      
 |      We can also define explicitly which indices we want to swap by supplying values
 |      for both i and j. Here, we for example swap the first and second indices.
 |      
 |      &gt;&gt;&gt; s.swaplevel(0, 1)
 |      History     Final exam  January         A
 |      Geography   Final exam  February        B
 |      History     Coursework  March           A
 |      Geography   Coursework  April           C
 |      dtype: object
 |  
 |  take(self, indices, axis: &#39;Axis&#39; = 0, **kwargs) -&gt; &#39;Series&#39;
 |      Return the elements in the given *positional* indices along an axis.
 |      
 |      This means that we are not indexing according to actual values in
 |      the index attribute of the object. We are indexing according to the
 |      actual position of the element in the object.
 |      
 |      Parameters
 |      ----------
 |      indices : array-like
 |          An array of ints indicating which positions to take.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default 0
 |          The axis on which to select elements. ``0`` means that we are
 |          selecting rows, ``1`` means that we are selecting columns.
 |          For `Series` this parameter is unused and defaults to 0.
 |      **kwargs
 |          For compatibility with :meth:`numpy.take`. Has no effect on the
 |          output.
 |      
 |      Returns
 |      -------
 |      same type as caller
 |          An array-like containing the elements taken from the object.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Select a subset of a DataFrame by labels.
 |      DataFrame.iloc : Select a subset of a DataFrame by positions.
 |      numpy.take : Take elements from an array along an axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;falcon&#39;, &#39;bird&#39;, 389.0),
 |      ...                    (&#39;parrot&#39;, &#39;bird&#39;, 24.0),
 |      ...                    (&#39;lion&#39;, &#39;mammal&#39;, 80.5),
 |      ...                    (&#39;monkey&#39;, &#39;mammal&#39;, np.nan)],
 |      ...                   columns=[&#39;name&#39;, &#39;class&#39;, &#39;max_speed&#39;],
 |      ...                   index=[0, 2, 3, 1])
 |      &gt;&gt;&gt; df
 |           name   class  max_speed
 |      0  falcon    bird      389.0
 |      2  parrot    bird       24.0
 |      3    lion  mammal       80.5
 |      1  monkey  mammal        NaN
 |      
 |      Take elements at positions 0 and 3 along the axis 0 (default).
 |      
 |      Note how the actual indices selected (0 and 1) do not correspond to
 |      our selected indices 0 and 3. That&#39;s because we are selecting the 0th
 |      and 3rd rows, not rows whose indices equal 0 and 3.
 |      
 |      &gt;&gt;&gt; df.take([0, 3])
 |           name   class  max_speed
 |      0  falcon    bird      389.0
 |      1  monkey  mammal        NaN
 |      
 |      Take elements at indices 1 and 2 along the axis 1 (column selection).
 |      
 |      &gt;&gt;&gt; df.take([1, 2], axis=1)
 |          class  max_speed
 |      0    bird      389.0
 |      2    bird       24.0
 |      3  mammal       80.5
 |      1  mammal        NaN
 |      
 |      We may take elements using negative integers for positive indices,
 |      starting from the end of the object, just like with Python lists.
 |      
 |      &gt;&gt;&gt; df.take([-1, -2])
 |           name   class  max_speed
 |      1  monkey  mammal        NaN
 |      3    lion  mammal       80.5
 |  
 |  to_dict(self, into: &#39;type[dict]&#39; = &lt;class &#39;dict&#39;&gt;) -&gt; &#39;dict&#39;
 |      Convert Series to {label -&gt; value} dict or dict-like object.
 |      
 |      Parameters
 |      ----------
 |      into : class, default dict
 |          The collections.abc.Mapping subclass to use as the return
 |          object. Can be the actual class or an empty
 |          instance of the mapping type you want.  If you want a
 |          collections.defaultdict, you must pass it initialized.
 |      
 |      Returns
 |      -------
 |      collections.abc.Mapping
 |          Key-value representation of Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s.to_dict()
 |      {0: 1, 1: 2, 2: 3, 3: 4}
 |      &gt;&gt;&gt; from collections import OrderedDict, defaultdict
 |      &gt;&gt;&gt; s.to_dict(OrderedDict)
 |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])
 |      &gt;&gt;&gt; dd = defaultdict(list)
 |      &gt;&gt;&gt; s.to_dict(dd)
 |      defaultdict(&lt;class &#39;list&#39;&gt;, {0: 1, 1: 2, 2: 3, 3: 4})
 |  
 |  to_frame(self, name: &#39;Hashable&#39; = &lt;no_default&gt;) -&gt; &#39;DataFrame&#39;
 |      Convert Series to DataFrame.
 |      
 |      Parameters
 |      ----------
 |      name : object, optional
 |          The passed name should substitute for the series name (if it has
 |          one).
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          DataFrame representation of Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],
 |      ...               name=&quot;vals&quot;)
 |      &gt;&gt;&gt; s.to_frame()
 |        vals
 |      0    a
 |      1    b
 |      2    c
 |  
 |  to_markdown(self, buf: &#39;IO[str] | None&#39; = None, mode: &#39;str&#39; = &#39;wt&#39;, index: &#39;bool&#39; = True, storage_options: &#39;StorageOptions&#39; = None, **kwargs) -&gt; &#39;str | None&#39;
 |      Print Series in Markdown-friendly format.
 |      
 |      Parameters
 |      ----------
 |      buf : str, Path or StringIO-like, optional, default None
 |          Buffer to write to. If None, the output is returned as a string.
 |      mode : str, optional
 |          Mode in which file is opened, &quot;wt&quot; by default.
 |      index : bool, optional, default True
 |          Add index (row) labels.
 |      
 |          .. versionadded:: 1.1.0
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib.request.Request`` as header options. For other
 |          URLs (e.g. starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are
 |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more
 |          details, and for more examples on storage options refer `here
 |          &lt;https://pandas.pydata.org/docs/user_guide/io.html?
 |          highlight=storage_options#reading-writing-remote-files&gt;`_.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      **kwargs
 |          These parameters will be passed to `tabulate                 &lt;https://pypi.org/project/tabulate&gt;`_.
 |      
 |      Returns
 |      -------
 |      str
 |          Series in Markdown-friendly format.
 |      
 |      Notes
 |      -----
 |      Requires the `tabulate &lt;https://pypi.org/project/tabulate&gt;`_ package.
 |      
 |      Examples
 |                  --------
 |                  &gt;&gt;&gt; s = pd.Series([&quot;elk&quot;, &quot;pig&quot;, &quot;dog&quot;, &quot;quetzal&quot;], name=&quot;animal&quot;)
 |                  &gt;&gt;&gt; print(s.to_markdown())
 |                  |    | animal   |
 |                  |---:|:---------|
 |                  |  0 | elk      |
 |                  |  1 | pig      |
 |                  |  2 | dog      |
 |                  |  3 | quetzal  |
 |      
 |                  Output markdown with a tabulate option.
 |      
 |                  &gt;&gt;&gt; print(s.to_markdown(tablefmt=&quot;grid&quot;))
 |                  +----+----------+
 |                  |    | animal   |
 |                  +====+==========+
 |                  |  0 | elk      |
 |                  +----+----------+
 |                  |  1 | pig      |
 |                  +----+----------+
 |                  |  2 | dog      |
 |                  +----+----------+
 |                  |  3 | quetzal  |
 |                  +----+----------+
 |  
 |  to_period(self, freq: &#39;str | None&#39; = None, copy: &#39;bool | None&#39; = None) -&gt; &#39;Series&#39;
 |      Convert Series from DatetimeIndex to PeriodIndex.
 |      
 |      Parameters
 |      ----------
 |      freq : str, default None
 |          Frequency associated with the PeriodIndex.
 |      copy : bool, default True
 |          Whether or not to return a copy.
 |      
 |      Returns
 |      -------
 |      Series
 |          Series with index converted to PeriodIndex.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.DatetimeIndex([&#39;2023&#39;, &#39;2024&#39;, &#39;2025&#39;])
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3], index=idx)
 |      &gt;&gt;&gt; s = s.to_period()
 |      &gt;&gt;&gt; s
 |      2023    1
 |      2024    2
 |      2025    3
 |      Freq: A-DEC, dtype: int64
 |      
 |      Viewing the index
 |      
 |      &gt;&gt;&gt; s.index
 |      PeriodIndex([&#39;2023&#39;, &#39;2024&#39;, &#39;2025&#39;], dtype=&#39;period[A-DEC]&#39;)
 |  
 |  to_string(self, buf: &#39;FilePath | WriteBuffer[str] | None&#39; = None, na_rep: &#39;str&#39; = &#39;NaN&#39;, float_format: &#39;str | None&#39; = None, header: &#39;bool&#39; = True, index: &#39;bool&#39; = True, length: &#39;bool&#39; = False, dtype: &#39;bool&#39; = False, name: &#39;bool&#39; = False, max_rows: &#39;int | None&#39; = None, min_rows: &#39;int | None&#39; = None) -&gt; &#39;str | None&#39;
 |      Render a string representation of the Series.
 |      
 |      Parameters
 |      ----------
 |      buf : StringIO-like, optional
 |          Buffer to write to.
 |      na_rep : str, optional
 |          String representation of NaN to use, default &#39;NaN&#39;.
 |      float_format : one-parameter function, optional
 |          Formatter function to apply to columns&#39; elements if they are
 |          floats, default None.
 |      header : bool, default True
 |          Add the Series header (index name).
 |      index : bool, optional
 |          Add index (row) labels, default True.
 |      length : bool, default False
 |          Add the Series length.
 |      dtype : bool, default False
 |          Add the Series dtype.
 |      name : bool, default False
 |          Add the Series name if not None.
 |      max_rows : int, optional
 |          Maximum number of rows to show before truncating. If None, show
 |          all.
 |      min_rows : int, optional
 |          The number of rows to display in a truncated repr (when number
 |          of rows is above `max_rows`).
 |      
 |      Returns
 |      -------
 |      str or None
 |          String representation of Series if ``buf=None``, otherwise None.
 |  
 |  to_timestamp(self, freq=None, how: &quot;Literal[&#39;s&#39;, &#39;e&#39;, &#39;start&#39;, &#39;end&#39;]&quot; = &#39;start&#39;, copy: &#39;bool | None&#39; = None) -&gt; &#39;Series&#39;
 |      Cast to DatetimeIndex of Timestamps, at *beginning* of period.
 |      
 |      Parameters
 |      ----------
 |      freq : str, default frequency of PeriodIndex
 |          Desired frequency.
 |      how : {&#39;s&#39;, &#39;e&#39;, &#39;start&#39;, &#39;end&#39;}
 |          Convention for converting period to timestamp; start of period
 |          vs. end.
 |      copy : bool, default True
 |          Whether or not to return a copy.
 |      
 |      Returns
 |      -------
 |      Series with DatetimeIndex
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.PeriodIndex([&#39;2023&#39;, &#39;2024&#39;, &#39;2025&#39;], freq=&#39;Y&#39;)
 |      &gt;&gt;&gt; s1 = pd.Series([1, 2, 3], index=idx)
 |      &gt;&gt;&gt; s1
 |      2023    1
 |      2024    2
 |      2025    3
 |      Freq: A-DEC, dtype: int64
 |      
 |      The resulting frequency of the Timestamps is `YearBegin`
 |      
 |      &gt;&gt;&gt; s1 = s1.to_timestamp()
 |      &gt;&gt;&gt; s1
 |      2023-01-01    1
 |      2024-01-01    2
 |      2025-01-01    3
 |      Freq: AS-JAN, dtype: int64
 |      
 |      Using `freq` which is the offset that the Timestamps will have
 |      
 |      &gt;&gt;&gt; s2 = pd.Series([1, 2, 3], index=idx)
 |      &gt;&gt;&gt; s2 = s2.to_timestamp(freq=&#39;M&#39;)
 |      &gt;&gt;&gt; s2
 |      2023-01-31    1
 |      2024-01-31    2
 |      2025-01-31    3
 |      Freq: A-JAN, dtype: int64
 |  
 |  transform(self, func: &#39;AggFuncType&#39;, axis: &#39;Axis&#39; = 0, *args, **kwargs) -&gt; &#39;DataFrame | Series&#39;
 |      Call ``func`` on self producing a Series with the same axis shape as self.
 |      
 |      Parameters
 |      ----------
 |      func : function, str, list-like or dict-like
 |          Function to use for transforming the data. If a function, must either
 |          work when passed a Series or when passed to Series.apply. If func
 |          is both list-like and dict-like, dict-like behavior takes precedence.
 |      
 |          Accepted combinations are:
 |      
 |          - function
 |          - string function name
 |          - list-like of functions and/or function names, e.g. ``[np.exp, &#39;sqrt&#39;]``
 |          - dict-like of axis labels -&gt; functions, function names or list-like of such.
 |      axis : {0 or &#39;index&#39;}
 |              Unused. Parameter needed for compatibility with DataFrame.
 |      *args
 |          Positional arguments to pass to `func`.
 |      **kwargs
 |          Keyword arguments to pass to `func`.
 |      
 |      Returns
 |      -------
 |      Series
 |          A Series that must have the same length as self.
 |      
 |      Raises
 |      ------
 |      ValueError : If the returned Series has a different length than self.
 |      
 |      See Also
 |      --------
 |      Series.agg : Only perform aggregating type operations.
 |      Series.apply : Invoke function on a Series.
 |      
 |      Notes
 |      -----
 |      Functions that mutate the passed object can produce unexpected
 |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
 |      for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: range(3), &#39;B&#39;: range(1, 4)})
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  0  1
 |      1  1  2
 |      2  2  3
 |      &gt;&gt;&gt; df.transform(lambda x: x + 1)
 |         A  B
 |      0  1  2
 |      1  2  3
 |      2  3  4
 |      
 |      Even though the resulting Series must have the same length as the
 |      input Series, it is possible to provide several input functions:
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(3))
 |      &gt;&gt;&gt; s
 |      0    0
 |      1    1
 |      2    2
 |      dtype: int64
 |      &gt;&gt;&gt; s.transform([np.sqrt, np.exp])
 |             sqrt        exp
 |      0  0.000000   1.000000
 |      1  1.000000   2.718282
 |      2  1.414214   7.389056
 |      
 |      You can call transform on a GroupBy object:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &quot;Date&quot;: [
 |      ...         &quot;2015-05-08&quot;, &quot;2015-05-07&quot;, &quot;2015-05-06&quot;, &quot;2015-05-05&quot;,
 |      ...         &quot;2015-05-08&quot;, &quot;2015-05-07&quot;, &quot;2015-05-06&quot;, &quot;2015-05-05&quot;],
 |      ...     &quot;Data&quot;: [5, 8, 6, 1, 50, 100, 60, 120],
 |      ... })
 |      &gt;&gt;&gt; df
 |               Date  Data
 |      0  2015-05-08     5
 |      1  2015-05-07     8
 |      2  2015-05-06     6
 |      3  2015-05-05     1
 |      4  2015-05-08    50
 |      5  2015-05-07   100
 |      6  2015-05-06    60
 |      7  2015-05-05   120
 |      &gt;&gt;&gt; df.groupby(&#39;Date&#39;)[&#39;Data&#39;].transform(&#39;sum&#39;)
 |      0     55
 |      1    108
 |      2     66
 |      3    121
 |      4     55
 |      5    108
 |      6     66
 |      7    121
 |      Name: Data, dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &quot;c&quot;: [1, 1, 1, 2, 2, 2, 2],
 |      ...     &quot;type&quot;: [&quot;m&quot;, &quot;n&quot;, &quot;o&quot;, &quot;m&quot;, &quot;m&quot;, &quot;n&quot;, &quot;n&quot;]
 |      ... })
 |      &gt;&gt;&gt; df
 |         c type
 |      0  1    m
 |      1  1    n
 |      2  1    o
 |      3  2    m
 |      4  2    m
 |      5  2    n
 |      6  2    n
 |      &gt;&gt;&gt; df[&#39;size&#39;] = df.groupby(&#39;c&#39;)[&#39;type&#39;].transform(len)
 |      &gt;&gt;&gt; df
 |         c type size
 |      0  1    m    3
 |      1  1    n    3
 |      2  1    o    3
 |      3  2    m    4
 |      4  2    m    4
 |      5  2    n    4
 |      6  2    n    4
 |  
 |  truediv(self, other, level=None, fill_value=None, axis: &#39;Axis&#39; = 0)
 |      Return Floating division of series and other, element-wise (binary operator `truediv`).
 |      
 |      Equivalent to ``series / other``, but with support to substitute a fill_value for
 |      missing data in either one of the inputs.
 |      
 |      Parameters
 |      ----------
 |      other : Series or scalar value
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : None or float value, default None (NaN)
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful Series alignment, with this value before computation.
 |          If data in both corresponding Series locations is missing
 |          the result of filling (at that location) will be missing.
 |      axis : {0 or &#39;index&#39;}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      
 |      Returns
 |      -------
 |      Series
 |          The result of the operation.
 |      
 |      See Also
 |      --------
 |      Series.rtruediv : Reverse of the Floating division operator, see
 |          `Python documentation
 |          &lt;https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types&gt;`_
 |          for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; a = pd.Series([1, 1, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; a
 |      a    1.0
 |      b    1.0
 |      c    1.0
 |      d    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; b = pd.Series([1, np.nan, 1, np.nan], index=[&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; b
 |      a    1.0
 |      b    NaN
 |      d    1.0
 |      e    NaN
 |      dtype: float64
 |      &gt;&gt;&gt; a.divide(b, fill_value=0)
 |      a    1.0
 |      b    inf
 |      c    inf
 |      d    0.0
 |      e    NaN
 |      dtype: float64
 |  
 |  unique(self) -&gt; &#39;ArrayLike&#39;
 |      Return unique values of Series object.
 |      
 |      Uniques are returned in order of appearance. Hash table-based unique,
 |      therefore does NOT sort.
 |      
 |      Returns
 |      -------
 |      ndarray or ExtensionArray
 |          The unique values returned as a NumPy array. See Notes.
 |      
 |      See Also
 |      --------
 |      Series.drop_duplicates : Return Series with duplicate values removed.
 |      unique : Top-level unique method for any 1-d array-like object.
 |      Index.unique : Return Index with unique values from an Index object.
 |      
 |      Notes
 |      -----
 |      Returns the unique values as a NumPy array. In case of an
 |      extension-array backed Series, a new
 |      :class:`~api.extensions.ExtensionArray` of that type with just
 |      the unique values is returned. This includes
 |      
 |          * Categorical
 |          * Period
 |          * Datetime with Timezone
 |          * Datetime without Timezone
 |          * Timedelta
 |          * Interval
 |          * Sparse
 |          * IntegerNA
 |      
 |      See Examples section.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; pd.Series([2, 1, 3, 3], name=&#39;A&#39;).unique()
 |      array([2, 1, 3])
 |      
 |      &gt;&gt;&gt; pd.Series([pd.Timestamp(&#39;2016-01-01&#39;) for _ in range(3)]).unique()
 |      &lt;DatetimeArray&gt;
 |      [&#39;2016-01-01 00:00:00&#39;]
 |      Length: 1, dtype: datetime64[ns]
 |      
 |      &gt;&gt;&gt; pd.Series([pd.Timestamp(&#39;2016-01-01&#39;, tz=&#39;US/Eastern&#39;)
 |      ...            for _ in range(3)]).unique()
 |      &lt;DatetimeArray&gt;
 |      [&#39;2016-01-01 00:00:00-05:00&#39;]
 |      Length: 1, dtype: datetime64[ns, US/Eastern]
 |      
 |      An Categorical will return categories in the order of
 |      appearance and with the same dtype.
 |      
 |      &gt;&gt;&gt; pd.Series(pd.Categorical(list(&#39;baabc&#39;))).unique()
 |      [&#39;b&#39;, &#39;a&#39;, &#39;c&#39;]
 |      Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      &gt;&gt;&gt; pd.Series(pd.Categorical(list(&#39;baabc&#39;), categories=list(&#39;abc&#39;),
 |      ...                          ordered=True)).unique()
 |      [&#39;b&#39;, &#39;a&#39;, &#39;c&#39;]
 |      Categories (3, object): [&#39;a&#39; &lt; &#39;b&#39; &lt; &#39;c&#39;]
 |  
 |  unstack(self, level: &#39;IndexLabel&#39; = -1, fill_value: &#39;Hashable&#39; = None) -&gt; &#39;DataFrame&#39;
 |      Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.
 |      
 |      Parameters
 |      ----------
 |      level : int, str, or list of these, default last level
 |          Level(s) to unstack, can pass level name.
 |      fill_value : scalar value, default None
 |          Value to use when replacing NaN values.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Unstacked Series.
 |      
 |      Notes
 |      -----
 |      Reference :ref:`the user guide &lt;reshaping.stacking&gt;` for more examples.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4],
 |      ...               index=pd.MultiIndex.from_product([[&#39;one&#39;, &#39;two&#39;],
 |      ...                                                 [&#39;a&#39;, &#39;b&#39;]]))
 |      &gt;&gt;&gt; s
 |      one  a    1
 |           b    2
 |      two  a    3
 |           b    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.unstack(level=-1)
 |           a  b
 |      one  1  2
 |      two  3  4
 |      
 |      &gt;&gt;&gt; s.unstack(level=0)
 |         one  two
 |      a    1    3
 |      b    2    4
 |  
 |  update(self, other: &#39;Series | Sequence | Mapping&#39;) -&gt; &#39;None&#39;
 |      Modify Series in place using values from passed Series.
 |      
 |      Uses non-NA values from passed Series to make updates. Aligns
 |      on index.
 |      
 |      Parameters
 |      ----------
 |      other : Series, or object coercible into Series
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.update(pd.Series([4, 5, 6]))
 |      &gt;&gt;&gt; s
 |      0    4
 |      1    5
 |      2    6
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; s.update(pd.Series([&#39;d&#39;, &#39;e&#39;], index=[0, 2]))
 |      &gt;&gt;&gt; s
 |      0    d
 |      1    b
 |      2    e
 |      dtype: object
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.update(pd.Series([4, 5, 6, 7, 8]))
 |      &gt;&gt;&gt; s
 |      0    4
 |      1    5
 |      2    6
 |      dtype: int64
 |      
 |      If ``other`` contains NaNs the corresponding values are not updated
 |      in the original Series.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.update(pd.Series([4, np.nan, 6]))
 |      &gt;&gt;&gt; s
 |      0    4
 |      1    2
 |      2    6
 |      dtype: int64
 |      
 |      ``other`` can also be a non-Series object type
 |      that is coercible into a Series
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.update([4, np.nan, 6])
 |      &gt;&gt;&gt; s
 |      0    4
 |      1    2
 |      2    6
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.update({1: 9})
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    9
 |      2    3
 |      dtype: int64
 |  
 |  var(self, axis: &#39;Axis | None&#39; = None, skipna: &#39;bool_t&#39; = True, ddof: &#39;int&#39; = 1, numeric_only: &#39;bool_t&#39; = False, **kwargs)
 |      Return unbiased variance over requested axis.
 |      
 |      Normalized by N-1 by default. This can be changed using the ddof argument.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0)}
 |          For `Series` this parameter is unused and defaults to 0.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      ddof : int, default 1
 |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
 |          where N represents the number of elements.
 |      numeric_only : bool, default False
 |          Include only float, int, boolean columns. Not implemented for Series.
 |      
 |      Returns
 |      -------
 |      scalar or Series (if level specified) 
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;person_id&#39;: [0, 1, 2, 3],
 |      ...                   &#39;age&#39;: [21, 25, 62, 43],
 |      ...                   &#39;height&#39;: [1.61, 1.87, 1.49, 2.01]}
 |      ...                  ).set_index(&#39;person_id&#39;)
 |      &gt;&gt;&gt; df
 |                 age  height
 |      person_id
 |      0           21    1.61
 |      1           25    1.87
 |      2           62    1.49
 |      3           43    2.01
 |      
 |      &gt;&gt;&gt; df.var()
 |      age       352.916667
 |      height      0.056367
 |      dtype: float64
 |      
 |      Alternatively, ``ddof=0`` can be set to normalize by N instead of N-1:
 |      
 |      &gt;&gt;&gt; df.var(ddof=0)
 |      age       264.687500
 |      height      0.042275
 |      dtype: float64
 |  
 |  view(self, dtype: &#39;Dtype | None&#39; = None) -&gt; &#39;Series&#39;
 |      Create a new view of the Series.
 |      
 |      This function will return a new Series with a view of the same
 |      underlying values in memory, optionally reinterpreted with a new data
 |      type. The new data type must preserve the same size in bytes as to not
 |      cause index misalignment.
 |      
 |      Parameters
 |      ----------
 |      dtype : data type
 |          Data type object or one of their string representations.
 |      
 |      Returns
 |      -------
 |      Series
 |          A new Series object as a view of the same data in memory.
 |      
 |      See Also
 |      --------
 |      numpy.ndarray.view : Equivalent numpy function to create a new view of
 |          the same data in memory.
 |      
 |      Notes
 |      -----
 |      Series are instantiated with ``dtype=float64`` by default. While
 |      ``numpy.ndarray.view()`` will return a view with the same data type as
 |      the original array, ``Series.view()`` (without specified dtype)
 |      will try using ``float64`` and may fail if the original data type size
 |      in bytes is not the same.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([-2, -1, 0, 1, 2], dtype=&#39;int8&#39;)
 |      &gt;&gt;&gt; s
 |      0   -2
 |      1   -1
 |      2    0
 |      3    1
 |      4    2
 |      dtype: int8
 |      
 |      The 8 bit signed integer representation of `-1` is `0b11111111`, but
 |      the same bytes represent 255 if read as an 8 bit unsigned integer:
 |      
 |      &gt;&gt;&gt; us = s.view(&#39;uint8&#39;)
 |      &gt;&gt;&gt; us
 |      0    254
 |      1    255
 |      2      0
 |      3      1
 |      4      2
 |      dtype: uint8
 |      
 |      The views share the same underlying values:
 |      
 |      &gt;&gt;&gt; us[0] = 128
 |      &gt;&gt;&gt; s
 |      0   -128
 |      1     -1
 |      2      0
 |      3      1
 |      4      2
 |      dtype: int8
 |  
 |  where(self, cond, other=&lt;no_default&gt;, *, inplace: &#39;bool&#39; = False, axis: &#39;Axis | None&#39; = None, level: &#39;Level&#39; = None) -&gt; &#39;Series | None&#39;
 |      Replace values where the condition is False.
 |      
 |      Parameters
 |      ----------
 |      cond : bool Series/DataFrame, array-like, or callable
 |          Where `cond` is True, keep the original value. Where
 |          False, replace with corresponding value from `other`.
 |          If `cond` is callable, it is computed on the Series/DataFrame and
 |          should return boolean Series/DataFrame or array. The callable must
 |          not change input Series/DataFrame (though pandas doesn&#39;t check it).
 |      other : scalar, Series/DataFrame, or callable
 |          Entries where `cond` is False are replaced with
 |          corresponding value from `other`.
 |          If other is callable, it is computed on the Series/DataFrame and
 |          should return scalar or Series/DataFrame. The callable must not
 |          change input Series/DataFrame (though pandas doesn&#39;t check it).
 |          If not specified, entries will be filled with the corresponding
 |          NULL value (``np.nan`` for numpy dtypes, ``pd.NA`` for extension
 |          dtypes).
 |      inplace : bool, default False
 |          Whether to perform the operation in place on the data.
 |      axis : int, default None
 |          Alignment axis if needed. For `Series` this parameter is
 |          unused and defaults to 0.
 |      level : int, default None
 |          Alignment level if needed.
 |      
 |      Returns
 |      -------
 |      Same type as caller or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      :func:`DataFrame.mask` : Return an object of same shape as
 |          self.
 |      
 |      Notes
 |      -----
 |      The where method is an application of the if-then idiom. For each
 |      element in the calling DataFrame, if ``cond`` is ``True`` the
 |      element is used; otherwise the corresponding element from the DataFrame
 |      ``other`` is used. If the axis of ``other`` does not align with axis of
 |      ``cond`` Series/DataFrame, the misaligned index positions will be filled with
 |      False.
 |      
 |      The signature for :func:`DataFrame.where` differs from
 |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to
 |      ``np.where(m, df1, df2)``.
 |      
 |      For further details and examples see the ``where`` documentation in
 |      :ref:`indexing &lt;indexing.where_mask&gt;`.
 |      
 |      The dtype of the object takes precedence. The fill value is casted to
 |      the object&#39;s dtype, if this can be done losslessly.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(range(5))
 |      &gt;&gt;&gt; s.where(s &gt; 0)
 |      0    NaN
 |      1    1.0
 |      2    2.0
 |      3    3.0
 |      4    4.0
 |      dtype: float64
 |      &gt;&gt;&gt; s.mask(s &gt; 0)
 |      0    0.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(5))
 |      &gt;&gt;&gt; t = pd.Series([True, False])
 |      &gt;&gt;&gt; s.where(t, 99)
 |      0     0
 |      1    99
 |      2    99
 |      3    99
 |      4    99
 |      dtype: int64
 |      &gt;&gt;&gt; s.mask(t, 99)
 |      0    99
 |      1     1
 |      2    99
 |      3    99
 |      4    99
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.where(s &gt; 1, 10)
 |      0    10
 |      1    10
 |      2    2
 |      3    3
 |      4    4
 |      dtype: int64
 |      &gt;&gt;&gt; s.mask(s &gt; 1, 10)
 |      0     0
 |      1     1
 |      2    10
 |      3    10
 |      4    10
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=[&#39;A&#39;, &#39;B&#39;])
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  0  1
 |      1  2  3
 |      2  4  5
 |      3  6  7
 |      4  8  9
 |      &gt;&gt;&gt; m = df % 3 == 0
 |      &gt;&gt;&gt; df.where(m, -df)
 |         A  B
 |      0  0 -1
 |      1 -2  3
 |      2 -4 -5
 |      3  6 -7
 |      4 -8  9
 |      &gt;&gt;&gt; df.where(m, -df) == np.where(m, df, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |      &gt;&gt;&gt; df.where(m, -df) == df.mask(~m, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |  
 |  array
 |      The ExtensionArray of the data backing this Series or Index.
 |      
 |      Returns
 |      -------
 |      ExtensionArray
 |          An ExtensionArray of the values stored within. For extension
 |          types, this is the actual array. For NumPy native types, this
 |          is a thin (no copy) wrapper around :class:`numpy.ndarray`.
 |      
 |          ``.array`` differs ``.values`` which may require converting the
 |          data to a different form.
 |      
 |      See Also
 |      --------
 |      Index.to_numpy : Similar method that always returns a NumPy array.
 |      Series.to_numpy : Similar method that always returns a NumPy array.
 |      
 |      Notes
 |      -----
 |      This table lays out the different array types for each extension
 |      dtype within pandas.
 |      
 |      ================== =============================
 |      dtype              array type
 |      ================== =============================
 |      category           Categorical
 |      period             PeriodArray
 |      interval           IntervalArray
 |      IntegerNA          IntegerArray
 |      string             StringArray
 |      boolean            BooleanArray
 |      datetime64[ns, tz] DatetimeArray
 |      ================== =============================
 |      
 |      For any 3rd-party extension types, the array type will be an
 |      ExtensionArray.
 |      
 |      For all remaining dtypes ``.array`` will be a
 |      :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray
 |      stored within. If you absolutely need a NumPy array (possibly with
 |      copying / coercing data), then use :meth:`Series.to_numpy` instead.
 |      
 |      Examples
 |      --------
 |      For regular NumPy types like int, and float, a PandasArray
 |      is returned.
 |      
 |      &gt;&gt;&gt; pd.Series([1, 2, 3]).array
 |      &lt;PandasArray&gt;
 |      [1, 2, 3]
 |      Length: 3, dtype: int64
 |      
 |      For extension types, like Categorical, the actual ExtensionArray
 |      is returned
 |      
 |      &gt;&gt;&gt; ser = pd.Series(pd.Categorical([&#39;a&#39;, &#39;b&#39;, &#39;a&#39;]))
 |      &gt;&gt;&gt; ser.array
 |      [&#39;a&#39;, &#39;b&#39;, &#39;a&#39;]
 |      Categories (2, object): [&#39;a&#39;, &#39;b&#39;]
 |  
 |  axes
 |      Return a list of the row axis labels.
 |  
 |  dtype
 |      Return the dtype object of the underlying data.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.dtype
 |      dtype(&#39;int64&#39;)
 |  
 |  dtypes
 |      Return the dtype object of the underlying data.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.dtypes
 |      dtype(&#39;int64&#39;)
 |  
 |  hasnans
 |      Return True if there are any NaNs.
 |      
 |      Enables various performance speedups.
 |      
 |      Returns
 |      -------
 |      bool
 |  
 |  values
 |      Return Series as ndarray or ndarray-like depending on the dtype.
 |      
 |      .. warning::
 |      
 |         We recommend using :attr:`Series.array` or
 |         :meth:`Series.to_numpy`, depending on whether you need
 |         a reference to the underlying data or a NumPy array.
 |      
 |      Returns
 |      -------
 |      numpy.ndarray or ndarray-like
 |      
 |      See Also
 |      --------
 |      Series.array : Reference to the underlying data.
 |      Series.to_numpy : A NumPy array representing the underlying data.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; pd.Series([1, 2, 3]).values
 |      array([1, 2, 3])
 |      
 |      &gt;&gt;&gt; pd.Series(list(&#39;aabc&#39;)).values
 |      array([&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;], dtype=object)
 |      
 |      &gt;&gt;&gt; pd.Series(list(&#39;aabc&#39;)).astype(&#39;category&#39;).values
 |      [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      
 |      Timezone aware datetime data is converted to UTC:
 |      
 |      &gt;&gt;&gt; pd.Series(pd.date_range(&#39;20130101&#39;, periods=3,
 |      ...                         tz=&#39;US/Eastern&#39;)).values
 |      array([&#39;2013-01-01T05:00:00.000000000&#39;,
 |             &#39;2013-01-02T05:00:00.000000000&#39;,
 |             &#39;2013-01-03T05:00:00.000000000&#39;], dtype=&#39;datetime64[ns]&#39;)
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  index
 |      The index (axis labels) of the Series.
 |  
 |  name
 |      Return the name of the Series.
 |      
 |      The name of a Series becomes its index or column name if it is used
 |      to form a DataFrame. It is also used whenever displaying the Series
 |      using the interpreter.
 |      
 |      Returns
 |      -------
 |      label (hashable object)
 |          The name of the Series, also the column name if part of a DataFrame.
 |      
 |      See Also
 |      --------
 |      Series.rename : Sets the Series name when given a scalar input.
 |      Index.name : Corresponding Index property.
 |      
 |      Examples
 |      --------
 |      The Series name can be set initially when calling the constructor.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3], dtype=np.int64, name=&#39;Numbers&#39;)
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      Name: Numbers, dtype: int64
 |      &gt;&gt;&gt; s.name = &quot;Integers&quot;
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      Name: Integers, dtype: int64
 |      
 |      The name of a Series within a DataFrame is its column name.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],
 |      ...                   columns=[&quot;Odd Numbers&quot;, &quot;Even Numbers&quot;])
 |      &gt;&gt;&gt; df
 |         Odd Numbers  Even Numbers
 |      0            1             2
 |      1            3             4
 |      2            5             6
 |      &gt;&gt;&gt; df[&quot;Even Numbers&quot;].name
 |      &#39;Even Numbers&#39;
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __annotations__ = {&#39;_AXIS_ORDERS&#39;: &quot;list[Literal[&#39;index&#39;, &#39;columns&#39;]]&quot;...
 |  
 |  cat = &lt;class &#39;pandas.core.arrays.categorical.CategoricalAccessor&#39;&gt;
 |      Accessor object for categorical properties of the Series values.
 |      
 |      Parameters
 |      ----------
 |      data : Series or CategoricalIndex
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(list(&quot;abbccc&quot;)).astype(&quot;category&quot;)
 |      &gt;&gt;&gt; s
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.categories
 |      Index([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], dtype=&#39;object&#39;)
 |      
 |      &gt;&gt;&gt; s.cat.rename_categories(list(&quot;cba&quot;))
 |      0    c
 |      1    b
 |      2    b
 |      3    a
 |      4    a
 |      5    a
 |      dtype: category
 |      Categories (3, object): [&#39;c&#39;, &#39;b&#39;, &#39;a&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.reorder_categories(list(&quot;cba&quot;))
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (3, object): [&#39;c&#39;, &#39;b&#39;, &#39;a&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.add_categories([&quot;d&quot;, &quot;e&quot;])
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (5, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.remove_categories([&quot;a&quot;, &quot;c&quot;])
 |      0    NaN
 |      1      b
 |      2      b
 |      3    NaN
 |      4    NaN
 |      5    NaN
 |      dtype: category
 |      Categories (1, object): [&#39;b&#39;]
 |      
 |      &gt;&gt;&gt; s1 = s.cat.add_categories([&quot;d&quot;, &quot;e&quot;])
 |      &gt;&gt;&gt; s1.cat.remove_unused_categories()
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.set_categories(list(&quot;abcde&quot;))
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (5, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.as_ordered()
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (3, object): [&#39;a&#39; &lt; &#39;b&#39; &lt; &#39;c&#39;]
 |      
 |      &gt;&gt;&gt; s.cat.as_unordered()
 |      0    a
 |      1    b
 |      2    b
 |      3    c
 |      4    c
 |      5    c
 |      dtype: category
 |      Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |  
 |  
 |  dt = &lt;class &#39;pandas.core.indexes.accessors.CombinedDatetimelikePropert...
 |  
 |  plot = &lt;class &#39;pandas.plotting._core.PlotAccessor&#39;&gt;
 |      Make plots of Series or DataFrame.
 |      
 |      Uses the backend specified by the
 |      option ``plotting.backend``. By default, matplotlib is used.
 |      
 |      Parameters
 |      ----------
 |      data : Series or DataFrame
 |          The object for which the method is called.
 |      x : label or position, default None
 |          Only used if data is a DataFrame.
 |      y : label, position or list of label, positions, default None
 |          Allows plotting of one column versus another. Only used if data is a
 |          DataFrame.
 |      kind : str
 |          The kind of plot to produce:
 |      
 |          - &#39;line&#39; : line plot (default)
 |          - &#39;bar&#39; : vertical bar plot
 |          - &#39;barh&#39; : horizontal bar plot
 |          - &#39;hist&#39; : histogram
 |          - &#39;box&#39; : boxplot
 |          - &#39;kde&#39; : Kernel Density Estimation plot
 |          - &#39;density&#39; : same as &#39;kde&#39;
 |          - &#39;area&#39; : area plot
 |          - &#39;pie&#39; : pie plot
 |          - &#39;scatter&#39; : scatter plot (DataFrame only)
 |          - &#39;hexbin&#39; : hexbin plot (DataFrame only)
 |      ax : matplotlib axes object, default None
 |          An axes of the current figure.
 |      subplots : bool or sequence of iterables, default False
 |          Whether to group columns into subplots:
 |      
 |          - ``False`` : No subplots will be used
 |          - ``True`` : Make separate subplots for each column.
 |          - sequence of iterables of column labels: Create a subplot for each
 |            group of columns. For example `[(&#39;a&#39;, &#39;c&#39;), (&#39;b&#39;, &#39;d&#39;)]` will
 |            create 2 subplots: one with columns &#39;a&#39; and &#39;c&#39;, and one
 |            with columns &#39;b&#39; and &#39;d&#39;. Remaining columns that aren&#39;t specified
 |            will be plotted in additional subplots (one per column).
 |      
 |            .. versionadded:: 1.5.0
 |      
 |      sharex : bool, default True if ax is None else False
 |          In case ``subplots=True``, share x axis and set some x axis labels
 |          to invisible; defaults to True if ax is None otherwise False if
 |          an ax is passed in; Be aware, that passing in both an ax and
 |          ``sharex=True`` will alter all x axis labels for all axis in a figure.
 |      sharey : bool, default False
 |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.
 |      layout : tuple, optional
 |          (rows, columns) for the layout of subplots.
 |      figsize : a tuple (width, height) in inches
 |          Size of a figure object.
 |      use_index : bool, default True
 |          Use index as ticks for x axis.
 |      title : str or list
 |          Title to use for the plot. If a string is passed, print the string
 |          at the top of the figure. If a list is passed and `subplots` is
 |          True, print each item in the list above the corresponding subplot.
 |      grid : bool, default None (matlab style default)
 |          Axis grid lines.
 |      legend : bool or {&#39;reverse&#39;}
 |          Place legend on axis subplots.
 |      style : list or dict
 |          The matplotlib line style per column.
 |      logx : bool or &#39;sym&#39;, default False
 |          Use log scaling or symlog scaling on x axis.
 |      
 |      logy : bool or &#39;sym&#39; default False
 |          Use log scaling or symlog scaling on y axis.
 |      
 |      loglog : bool or &#39;sym&#39;, default False
 |          Use log scaling or symlog scaling on both x and y axes.
 |      
 |      xticks : sequence
 |          Values to use for the xticks.
 |      yticks : sequence
 |          Values to use for the yticks.
 |      xlim : 2-tuple/list
 |          Set the x limits of the current axes.
 |      ylim : 2-tuple/list
 |          Set the y limits of the current axes.
 |      xlabel : label, optional
 |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the
 |          x-column name for planar plots.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |             Now applicable to planar plots (`scatter`, `hexbin`).
 |      
 |          .. versionchanged:: 2.0.0
 |      
 |              Now applicable to histograms.
 |      
 |      ylabel : label, optional
 |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the
 |          y-column name for planar plots.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |             Now applicable to planar plots (`scatter`, `hexbin`).
 |      
 |          .. versionchanged:: 2.0.0
 |      
 |              Now applicable to histograms.
 |      
 |      rot : float, default None
 |          Rotation for ticks (xticks for vertical, yticks for horizontal
 |          plots).
 |      fontsize : float, default None
 |          Font size for xticks and yticks.
 |      colormap : str or matplotlib colormap object, default None
 |          Colormap to select colors from. If string, load colormap with that
 |          name from matplotlib.
 |      colorbar : bool, optional
 |          If True, plot colorbar (only relevant for &#39;scatter&#39; and &#39;hexbin&#39;
 |          plots).
 |      position : float
 |          Specify relative alignments for bar plot layout.
 |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
 |          (center).
 |      table : bool, Series or DataFrame, default False
 |          If True, draw a table using the data in the DataFrame and the data
 |          will be transposed to meet matplotlib&#39;s default layout.
 |          If a Series or DataFrame is passed, use passed data to draw a
 |          table.
 |      yerr : DataFrame, Series, array-like, dict and str
 |          See :ref:`Plotting with Error Bars &lt;visualization.errorbars&gt;` for
 |          detail.
 |      xerr : DataFrame, Series, array-like, dict and str
 |          Equivalent to yerr.
 |      stacked : bool, default False in line and bar plots, and True in area plot
 |          If True, create stacked plot.
 |      secondary_y : bool or sequence, default False
 |          Whether to plot on the secondary y-axis if a list/tuple, which
 |          columns to plot on secondary y-axis.
 |      mark_right : bool, default True
 |          When using a secondary_y axis, automatically mark the column
 |          labels with &quot;(right)&quot; in the legend.
 |      include_bool : bool, default is False
 |          If True, boolean values can be plotted.
 |      backend : str, default None
 |          Backend to use instead of the backend specified in the option
 |          ``plotting.backend``. For instance, &#39;matplotlib&#39;. Alternatively, to
 |          specify the ``plotting.backend`` for the whole session, set
 |          ``pd.options.plotting.backend``.
 |      **kwargs
 |          Options to pass to matplotlib plotting method.
 |      
 |      Returns
 |      -------
 |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them
 |          If the backend is not the default matplotlib one, the return value
 |          will be the object returned by the backend.
 |      
 |      Notes
 |      -----
 |      - See matplotlib documentation online for more on this subject
 |      - If `kind` = &#39;bar&#39; or &#39;barh&#39;, you can specify relative alignments
 |        for bar plot layout by `position` keyword.
 |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
 |        (center)
 |  
 |  
 |  sparse = &lt;class &#39;pandas.core.arrays.sparse.accessor.SparseAccessor&#39;&gt;
 |      Accessor for SparseSparse from other sparse matrix data types.
 |  
 |  
 |  str = &lt;class &#39;pandas.core.strings.accessor.StringMethods&#39;&gt;
 |      Vectorized string functions for Series and Index.
 |      
 |      NAs stay NA unless handled otherwise by a particular method.
 |      Patterned after Python&#39;s string methods, with some inspiration from
 |      R&#39;s stringr package.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&quot;A_Str_Series&quot;])
 |      &gt;&gt;&gt; s
 |      0    A_Str_Series
 |      dtype: object
 |      
 |      &gt;&gt;&gt; s.str.split(&quot;_&quot;)
 |      0    [A, Str, Series]
 |      dtype: object
 |      
 |      &gt;&gt;&gt; s.str.replace(&quot;_&quot;, &quot;&quot;)
 |      0    AStrSeries
 |      dtype: object
 |  
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.base.IndexOpsMixin:
 |  
 |  __iter__(self) -&gt; &#39;Iterator&#39;
 |      Return an iterator of the values.
 |      
 |      These are each a scalar type, which is a Python scalar
 |      (for str, int, float) or a pandas scalar
 |      (for Timestamp/Timedelta/Interval/Period)
 |      
 |      Returns
 |      -------
 |      iterator
 |  
 |  argmax(self, axis: &#39;AxisInt | None&#39; = None, skipna: &#39;bool&#39; = True, *args, **kwargs) -&gt; &#39;int&#39;
 |      Return int position of the largest value in the Series.
 |      
 |      If the maximum is achieved in multiple locations,
 |      the first row position is returned.
 |      
 |      Parameters
 |      ----------
 |      axis : {None}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      skipna : bool, default True
 |          Exclude NA/null values when showing the result.
 |      *args, **kwargs
 |          Additional arguments and keywords for compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      int
 |          Row position of the maximum value.
 |      
 |      See Also
 |      --------
 |      Series.argmax : Return position of the maximum value.
 |      Series.argmin : Return position of the minimum value.
 |      numpy.ndarray.argmax : Equivalent method for numpy arrays.
 |      Series.idxmax : Return index label of the maximum values.
 |      Series.idxmin : Return index label of the minimum values.
 |      
 |      Examples
 |      --------
 |      Consider dataset containing cereal calories
 |      
 |      &gt;&gt;&gt; s = pd.Series({&#39;Corn Flakes&#39;: 100.0, &#39;Almond Delight&#39;: 110.0,
 |      ...                &#39;Cinnamon Toast Crunch&#39;: 120.0, &#39;Cocoa Puff&#39;: 110.0})
 |      &gt;&gt;&gt; s
 |      Corn Flakes              100.0
 |      Almond Delight           110.0
 |      Cinnamon Toast Crunch    120.0
 |      Cocoa Puff               110.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.argmax()
 |      2
 |      &gt;&gt;&gt; s.argmin()
 |      0
 |      
 |      The maximum cereal calories is the third element and
 |      the minimum cereal calories is the first element,
 |      since series is zero-indexed.
 |  
 |  argmin(self, axis: &#39;AxisInt | None&#39; = None, skipna: &#39;bool&#39; = True, *args, **kwargs) -&gt; &#39;int&#39;
 |      Return int position of the smallest value in the Series.
 |      
 |      If the minimum is achieved in multiple locations,
 |      the first row position is returned.
 |      
 |      Parameters
 |      ----------
 |      axis : {None}
 |          Unused. Parameter needed for compatibility with DataFrame.
 |      skipna : bool, default True
 |          Exclude NA/null values when showing the result.
 |      *args, **kwargs
 |          Additional arguments and keywords for compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      int
 |          Row position of the minimum value.
 |      
 |      See Also
 |      --------
 |      Series.argmin : Return position of the minimum value.
 |      Series.argmax : Return position of the maximum value.
 |      numpy.ndarray.argmin : Equivalent method for numpy arrays.
 |      Series.idxmax : Return index label of the maximum values.
 |      Series.idxmin : Return index label of the minimum values.
 |      
 |      Examples
 |      --------
 |      Consider dataset containing cereal calories
 |      
 |      &gt;&gt;&gt; s = pd.Series({&#39;Corn Flakes&#39;: 100.0, &#39;Almond Delight&#39;: 110.0,
 |      ...                &#39;Cinnamon Toast Crunch&#39;: 120.0, &#39;Cocoa Puff&#39;: 110.0})
 |      &gt;&gt;&gt; s
 |      Corn Flakes              100.0
 |      Almond Delight           110.0
 |      Cinnamon Toast Crunch    120.0
 |      Cocoa Puff               110.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.argmax()
 |      2
 |      &gt;&gt;&gt; s.argmin()
 |      0
 |      
 |      The maximum cereal calories is the third element and
 |      the minimum cereal calories is the first element,
 |      since series is zero-indexed.
 |  
 |  factorize(self, sort: &#39;bool&#39; = False, use_na_sentinel: &#39;bool&#39; = True) -&gt; &#39;tuple[npt.NDArray[np.intp], Index]&#39;
 |      Encode the object as an enumerated type or categorical variable.
 |      
 |      This method is useful for obtaining a numeric representation of an
 |      array when all that matters is identifying distinct values. `factorize`
 |      is available as both a top-level function :func:`pandas.factorize`,
 |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.
 |      
 |      Parameters
 |      ----------
 |      sort : bool, default False
 |          Sort `uniques` and shuffle `codes` to maintain the
 |          relationship.
 |      
 |      use_na_sentinel : bool, default True
 |          If True, the sentinel -1 will be used for NaN values. If False,
 |          NaN values will be encoded as non-negative integers and will not drop the
 |          NaN from the uniques of the values.
 |      
 |          .. versionadded:: 1.5.0
 |      
 |      Returns
 |      -------
 |      codes : ndarray
 |          An integer ndarray that&#39;s an indexer into `uniques`.
 |          ``uniques.take(codes)`` will have the same values as `values`.
 |      uniques : ndarray, Index, or Categorical
 |          The unique valid values. When `values` is Categorical, `uniques`
 |          is a Categorical. When `values` is some other pandas object, an
 |          `Index` is returned. Otherwise, a 1-D ndarray is returned.
 |      
 |          .. note::
 |      
 |             Even if there&#39;s a missing value in `values`, `uniques` will
 |             *not* contain an entry for it.
 |      
 |      See Also
 |      --------
 |      cut : Discretize continuous-valued array.
 |      unique : Find the unique value in an array.
 |      
 |      Notes
 |      -----
 |      Reference :ref:`the user guide &lt;reshaping.factorize&gt;` for more examples.
 |      
 |      Examples
 |      --------
 |      These examples all show factorize as a top-level method like
 |      ``pd.factorize(values)``. The results are identical for methods like
 |      :meth:`Series.factorize`.
 |      
 |      &gt;&gt;&gt; codes, uniques = pd.factorize([&#39;b&#39;, &#39;b&#39;, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;])
 |      &gt;&gt;&gt; codes
 |      array([0, 0, 1, 2, 0])
 |      &gt;&gt;&gt; uniques
 |      array([&#39;b&#39;, &#39;a&#39;, &#39;c&#39;], dtype=object)
 |      
 |      With ``sort=True``, the `uniques` will be sorted, and `codes` will be
 |      shuffled so that the relationship is the maintained.
 |      
 |      &gt;&gt;&gt; codes, uniques = pd.factorize([&#39;b&#39;, &#39;b&#39;, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;], sort=True)
 |      &gt;&gt;&gt; codes
 |      array([1, 1, 0, 2, 1])
 |      &gt;&gt;&gt; uniques
 |      array([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], dtype=object)
 |      
 |      When ``use_na_sentinel=True`` (the default), missing values are indicated in
 |      the `codes` with the sentinel value ``-1`` and missing values are not
 |      included in `uniques`.
 |      
 |      &gt;&gt;&gt; codes, uniques = pd.factorize([&#39;b&#39;, None, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;])
 |      &gt;&gt;&gt; codes
 |      array([ 0, -1,  1,  2,  0])
 |      &gt;&gt;&gt; uniques
 |      array([&#39;b&#39;, &#39;a&#39;, &#39;c&#39;], dtype=object)
 |      
 |      Thus far, we&#39;ve only factorized lists (which are internally coerced to
 |      NumPy arrays). When factorizing pandas objects, the type of `uniques`
 |      will differ. For Categoricals, a `Categorical` is returned.
 |      
 |      &gt;&gt;&gt; cat = pd.Categorical([&#39;a&#39;, &#39;a&#39;, &#39;c&#39;], categories=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; codes, uniques = pd.factorize(cat)
 |      &gt;&gt;&gt; codes
 |      array([0, 0, 1])
 |      &gt;&gt;&gt; uniques
 |      [&#39;a&#39;, &#39;c&#39;]
 |      Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      
 |      Notice that ``&#39;b&#39;`` is in ``uniques.categories``, despite not being
 |      present in ``cat.values``.
 |      
 |      For all other pandas objects, an Index of the appropriate type is
 |      returned.
 |      
 |      &gt;&gt;&gt; cat = pd.Series([&#39;a&#39;, &#39;a&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; codes, uniques = pd.factorize(cat)
 |      &gt;&gt;&gt; codes
 |      array([0, 0, 1])
 |      &gt;&gt;&gt; uniques
 |      Index([&#39;a&#39;, &#39;c&#39;], dtype=&#39;object&#39;)
 |      
 |      If NaN is in the values, and we want to include NaN in the uniques of the
 |      values, it can be achieved by setting ``use_na_sentinel=False``.
 |      
 |      &gt;&gt;&gt; values = np.array([1, 2, 1, np.nan])
 |      &gt;&gt;&gt; codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True
 |      &gt;&gt;&gt; codes
 |      array([ 0,  1,  0, -1])
 |      &gt;&gt;&gt; uniques
 |      array([1., 2.])
 |      
 |      &gt;&gt;&gt; codes, uniques = pd.factorize(values, use_na_sentinel=False)
 |      &gt;&gt;&gt; codes
 |      array([0, 1, 0, 2])
 |      &gt;&gt;&gt; uniques
 |      array([ 1.,  2., nan])
 |  
 |  item(self)
 |      Return the first element of the underlying data as a Python scalar.
 |      
 |      Returns
 |      -------
 |      scalar
 |          The first element of %(klass)s.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          If the data is not length-1.
 |  
 |  nunique(self, dropna: &#39;bool&#39; = True) -&gt; &#39;int&#39;
 |      Return number of unique elements in the object.
 |      
 |      Excludes NA values by default.
 |      
 |      Parameters
 |      ----------
 |      dropna : bool, default True
 |          Don&#39;t include NaN in the count.
 |      
 |      Returns
 |      -------
 |      int
 |      
 |      See Also
 |      --------
 |      DataFrame.nunique: Method nunique for DataFrame.
 |      Series.count: Count non-NA/null observations in the Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 3, 5, 7, 7])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    3
 |      2    5
 |      3    7
 |      4    7
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.nunique()
 |      4
 |  
 |  to_list = tolist(self)
 |  
 |  to_numpy(self, dtype: &#39;npt.DTypeLike | None&#39; = None, copy: &#39;bool&#39; = False, na_value: &#39;object&#39; = &lt;no_default&gt;, **kwargs) -&gt; &#39;np.ndarray&#39;
 |      A NumPy ndarray representing the values in this Series or Index.
 |      
 |      Parameters
 |      ----------
 |      dtype : str or numpy.dtype, optional
 |          The dtype to pass to :meth:`numpy.asarray`.
 |      copy : bool, default False
 |          Whether to ensure that the returned value is not a view on
 |          another array. Note that ``copy=False`` does not *ensure* that
 |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that
 |          a copy is made, even if not strictly necessary.
 |      na_value : Any, optional
 |          The value to use for missing values. The default value depends
 |          on `dtype` and the type of the array.
 |      **kwargs
 |          Additional keywords passed through to the ``to_numpy`` method
 |          of the underlying array (for extension arrays).
 |      
 |      Returns
 |      -------
 |      numpy.ndarray
 |      
 |      See Also
 |      --------
 |      Series.array : Get the actual data stored within.
 |      Index.array : Get the actual data stored within.
 |      DataFrame.to_numpy : Similar method for DataFrame.
 |      
 |      Notes
 |      -----
 |      The returned array will be the same up to equality (values equal
 |      in `self` will be equal in the returned array; likewise for values
 |      that are not equal). When `self` contains an ExtensionArray, the
 |      dtype may be different. For example, for a category-dtype Series,
 |      ``to_numpy()`` will return a NumPy array and the categorical dtype
 |      will be lost.
 |      
 |      For NumPy dtypes, this will be a reference to the actual data stored
 |      in this Series or Index (assuming ``copy=False``). Modifying the result
 |      in place will modify the data stored in the Series or Index (not that
 |      we recommend doing that).
 |      
 |      For extension types, ``to_numpy()`` *may* require copying data and
 |      coercing the result to a NumPy type (possibly object), which may be
 |      expensive. When you need a no-copy reference to the underlying data,
 |      :attr:`Series.array` should be used instead.
 |      
 |      This table lays out the different dtypes and default return types of
 |      ``to_numpy()`` for various dtypes within pandas.
 |      
 |      ================== ================================
 |      dtype              array type
 |      ================== ================================
 |      category[T]        ndarray[T] (same dtype as input)
 |      period             ndarray[object] (Periods)
 |      interval           ndarray[object] (Intervals)
 |      IntegerNA          ndarray[object]
 |      datetime64[ns]     datetime64[ns]
 |      datetime64[ns, tz] ndarray[object] (Timestamps)
 |      ================== ================================
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; ser = pd.Series(pd.Categorical([&#39;a&#39;, &#39;b&#39;, &#39;a&#39;]))
 |      &gt;&gt;&gt; ser.to_numpy()
 |      array([&#39;a&#39;, &#39;b&#39;, &#39;a&#39;], dtype=object)
 |      
 |      Specify the `dtype` to control how datetime-aware data is represented.
 |      Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`
 |      objects, each with the correct ``tz``.
 |      
 |      &gt;&gt;&gt; ser = pd.Series(pd.date_range(&#39;2000&#39;, periods=2, tz=&quot;CET&quot;))
 |      &gt;&gt;&gt; ser.to_numpy(dtype=object)
 |      array([Timestamp(&#39;2000-01-01 00:00:00+0100&#39;, tz=&#39;CET&#39;),
 |             Timestamp(&#39;2000-01-02 00:00:00+0100&#39;, tz=&#39;CET&#39;)],
 |            dtype=object)
 |      
 |      Or ``dtype=&#39;datetime64[ns]&#39;`` to return an ndarray of native
 |      datetime64 values. The values are converted to UTC and the timezone
 |      info is dropped.
 |      
 |      &gt;&gt;&gt; ser.to_numpy(dtype=&quot;datetime64[ns]&quot;)
 |      ... # doctest: +ELLIPSIS
 |      array([&#39;1999-12-31T23:00:00.000000000&#39;, &#39;2000-01-01T23:00:00...&#39;],
 |            dtype=&#39;datetime64[ns]&#39;)
 |  
 |  tolist(self)
 |      Return a list of the values.
 |      
 |      These are each a scalar type, which is a Python scalar
 |      (for str, int, float) or a pandas scalar
 |      (for Timestamp/Timedelta/Interval/Period)
 |      
 |      Returns
 |      -------
 |      list
 |      
 |      See Also
 |      --------
 |      numpy.ndarray.tolist : Return the array as an a.ndim-levels deep
 |          nested list of Python scalars.
 |  
 |  transpose(self: &#39;_T&#39;, *args, **kwargs) -&gt; &#39;_T&#39;
 |      Return the transpose, which is by definition self.
 |      
 |      Returns
 |      -------
 |      %(klass)s
 |  
 |  value_counts(self, normalize: &#39;bool&#39; = False, sort: &#39;bool&#39; = True, ascending: &#39;bool&#39; = False, bins=None, dropna: &#39;bool&#39; = True) -&gt; &#39;Series&#39;
 |      Return a Series containing counts of unique values.
 |      
 |      The resulting object will be in descending order so that the
 |      first element is the most frequently-occurring element.
 |      Excludes NA values by default.
 |      
 |      Parameters
 |      ----------
 |      normalize : bool, default False
 |          If True then the object returned will contain the relative
 |          frequencies of the unique values.
 |      sort : bool, default True
 |          Sort by frequencies.
 |      ascending : bool, default False
 |          Sort in ascending order.
 |      bins : int, optional
 |          Rather than count values, group them into half-open bins,
 |          a convenience for ``pd.cut``, only works with numeric data.
 |      dropna : bool, default True
 |          Don&#39;t include counts of NaN.
 |      
 |      Returns
 |      -------
 |      Series
 |      
 |      See Also
 |      --------
 |      Series.count: Number of non-NA elements in a Series.
 |      DataFrame.count: Number of non-NA elements in a DataFrame.
 |      DataFrame.value_counts: Equivalent method on DataFrames.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; index = pd.Index([3, 1, 2, 3, 4, np.nan])
 |      &gt;&gt;&gt; index.value_counts()
 |      3.0    2
 |      1.0    1
 |      2.0    1
 |      4.0    1
 |      Name: count, dtype: int64
 |      
 |      With `normalize` set to `True`, returns the relative frequency by
 |      dividing all values by the sum of values.
 |      
 |      &gt;&gt;&gt; s = pd.Series([3, 1, 2, 3, 4, np.nan])
 |      &gt;&gt;&gt; s.value_counts(normalize=True)
 |      3.0    0.4
 |      1.0    0.2
 |      2.0    0.2
 |      4.0    0.2
 |      Name: proportion, dtype: float64
 |      
 |      **bins**
 |      
 |      Bins can be useful for going from a continuous variable to a
 |      categorical variable; instead of counting unique
 |      apparitions of values, divide the index in the specified
 |      number of half-open bins.
 |      
 |      &gt;&gt;&gt; s.value_counts(bins=3)
 |      (0.996, 2.0]    2
 |      (2.0, 3.0]      2
 |      (3.0, 4.0]      1
 |      Name: count, dtype: int64
 |      
 |      **dropna**
 |      
 |      With `dropna` set to `False` we can also see NaN index values.
 |      
 |      &gt;&gt;&gt; s.value_counts(dropna=False)
 |      3.0    2
 |      1.0    1
 |      2.0    1
 |      4.0    1
 |      NaN    1
 |      Name: count, dtype: int64
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pandas.core.base.IndexOpsMixin:
 |  
 |  T
 |      Return the transpose, which is by definition self.
 |  
 |  empty
 |  
 |  is_monotonic_decreasing
 |      Return boolean if values in the object are monotonically decreasing.
 |      
 |      Returns
 |      -------
 |      bool
 |  
 |  is_monotonic_increasing
 |      Return boolean if values in the object are monotonically increasing.
 |      
 |      Returns
 |      -------
 |      bool
 |  
 |  is_unique
 |      Return boolean if values in the object are unique.
 |      
 |      Returns
 |      -------
 |      bool
 |  
 |  nbytes
 |      Return the number of bytes in the underlying data.
 |  
 |  ndim
 |      Number of dimensions of the underlying data, by definition 1.
 |  
 |  shape
 |      Return a tuple of the shape of the underlying data.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.shape
 |      (3,)
 |  
 |  size
 |      Return the number of elements in the underlying data.
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:
 |  
 |  __array_priority__ = 1000
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.arraylike.OpsMixin:
 |  
 |  __add__(self, other)
 |      Get Addition of DataFrame and other, column-wise.
 |      
 |      Equivalent to ``DataFrame.add(other)``.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, dict or DataFrame
 |          Object to be added to the DataFrame.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The result of adding ``other`` to DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add a DataFrame and another object, with option for index-
 |          or column-oriented addition.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;height&#39;: [1.5, 2.6], &#39;weight&#39;: [500, 800]},
 |      ...                   index=[&#39;elk&#39;, &#39;moose&#39;])
 |      &gt;&gt;&gt; df
 |             height  weight
 |      elk       1.5     500
 |      moose     2.6     800
 |      
 |      Adding a scalar affects all rows and columns.
 |      
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]] + 1.5
 |             height  weight
 |      elk       3.0   501.5
 |      moose     4.1   801.5
 |      
 |      Each element of a list is added to a column of the DataFrame, in order.
 |      
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]] + [0.5, 1.5]
 |             height  weight
 |      elk       2.0   501.5
 |      moose     3.1   801.5
 |      
 |      Keys of a dictionary are aligned to the DataFrame, based on column names;
 |      each value in the dictionary is added to the corresponding column.
 |      
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]] + {&#39;height&#39;: 0.5, &#39;weight&#39;: 1.5}
 |             height  weight
 |      elk       2.0   501.5
 |      moose     3.1   801.5
 |      
 |      When `other` is a :class:`Series`, the index of `other` is aligned with the
 |      columns of the DataFrame.
 |      
 |      &gt;&gt;&gt; s1 = pd.Series([0.5, 1.5], index=[&#39;weight&#39;, &#39;height&#39;])
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]] + s1
 |             height  weight
 |      elk       3.0   500.5
 |      moose     4.1   800.5
 |      
 |      Even when the index of `other` is the same as the index of the DataFrame,
 |      the :class:`Series` will not be reoriented. If index-wise alignment is desired,
 |      :meth:`DataFrame.add` should be used with `axis=&#39;index&#39;`.
 |      
 |      &gt;&gt;&gt; s2 = pd.Series([0.5, 1.5], index=[&#39;elk&#39;, &#39;moose&#39;])
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]] + s2
 |             elk  height  moose  weight
 |      elk    NaN     NaN    NaN     NaN
 |      moose  NaN     NaN    NaN     NaN
 |      
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]].add(s2, axis=&#39;index&#39;)
 |             height  weight
 |      elk       2.0   500.5
 |      moose     4.1   801.5
 |      
 |      When `other` is a :class:`DataFrame`, both columns names and the
 |      index are aligned.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;height&#39;: [0.2, 0.4, 0.6]},
 |      ...                      index=[&#39;elk&#39;, &#39;moose&#39;, &#39;deer&#39;])
 |      &gt;&gt;&gt; df[[&#39;height&#39;, &#39;weight&#39;]] + other
 |             height  weight
 |      deer      NaN     NaN
 |      elk       1.7     NaN
 |      moose     3.0     NaN
 |  
 |  __and__(self, other)
 |  
 |  __divmod__(self, other)
 |  
 |  __eq__(self, other)
 |      Return self==value.
 |  
 |  __floordiv__(self, other)
 |  
 |  __ge__(self, other)
 |      Return self&gt;=value.
 |  
 |  __gt__(self, other)
 |      Return self&gt;value.
 |  
 |  __le__(self, other)
 |      Return self&lt;=value.
 |  
 |  __lt__(self, other)
 |      Return self&lt;value.
 |  
 |  __mod__(self, other)
 |  
 |  __mul__(self, other)
 |  
 |  __ne__(self, other)
 |      Return self!=value.
 |  
 |  __or__(self, other)
 |  
 |  __pow__(self, other)
 |  
 |  __radd__(self, other)
 |  
 |  __rand__(self, other)
 |  
 |  __rdivmod__(self, other)
 |  
 |  __rfloordiv__(self, other)
 |  
 |  __rmod__(self, other)
 |  
 |  __rmul__(self, other)
 |  
 |  __ror__(self, other)
 |  
 |  __rpow__(self, other)
 |  
 |  __rsub__(self, other)
 |  
 |  __rtruediv__(self, other)
 |  
 |  __rxor__(self, other)
 |  
 |  __sub__(self, other)
 |  
 |  __truediv__(self, other)
 |  
 |  __xor__(self, other)
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pandas.core.arraylike.OpsMixin:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:
 |  
 |  __hash__ = None
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.generic.NDFrame:
 |  
 |  __abs__(self: &#39;NDFrameT&#39;) -&gt; &#39;NDFrameT&#39;
 |  
 |  __array_ufunc__(self, ufunc: &#39;np.ufunc&#39;, method: &#39;str&#39;, *inputs: &#39;Any&#39;, **kwargs: &#39;Any&#39;)
 |  
 |  __bool__ = __nonzero__(self) -&gt; &#39;NoReturn&#39;
 |  
 |  __contains__(self, key) -&gt; &#39;bool_t&#39;
 |      True if the key is in the info axis
 |  
 |  __copy__(self: &#39;NDFrameT&#39;, deep: &#39;bool_t&#39; = True) -&gt; &#39;NDFrameT&#39;
 |  
 |  __deepcopy__(self: &#39;NDFrameT&#39;, memo=None) -&gt; &#39;NDFrameT&#39;
 |      Parameters
 |      ----------
 |      memo, default None
 |          Standard signature. Unused
 |  
 |  __delitem__(self, key) -&gt; &#39;None&#39;
 |      Delete item
 |  
 |  __finalize__(self: &#39;NDFrameT&#39;, other, method: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;NDFrameT&#39;
 |      Propagate metadata from other to self.
 |      
 |      Parameters
 |      ----------
 |      other : the object from which to get the attributes that we are going
 |          to propagate
 |      method : str, optional
 |          A passed method name providing context on where ``__finalize__``
 |          was called.
 |      
 |          .. warning::
 |      
 |             The value passed as `method` are not currently considered
 |             stable across pandas releases.
 |  
 |  __getattr__(self, name: &#39;str&#39;)
 |      After regular attribute access, try looking up the name
 |      This allows simpler access to columns for interactive use.
 |  
 |  __getstate__(self) -&gt; &#39;dict[str, Any]&#39;
 |  
 |  __iadd__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __iand__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __ifloordiv__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __imod__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __imul__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __invert__(self: &#39;NDFrameT&#39;) -&gt; &#39;NDFrameT&#39;
 |  
 |  __ior__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __ipow__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __isub__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __itruediv__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __ixor__(self: &#39;NDFrameT&#39;, other) -&gt; &#39;NDFrameT&#39;
 |  
 |  __neg__(self: &#39;NDFrameT&#39;) -&gt; &#39;NDFrameT&#39;
 |  
 |  __nonzero__(self) -&gt; &#39;NoReturn&#39;
 |  
 |  __pos__(self: &#39;NDFrameT&#39;) -&gt; &#39;NDFrameT&#39;
 |  
 |  __round__(self: &#39;NDFrameT&#39;, decimals: &#39;int&#39; = 0) -&gt; &#39;NDFrameT&#39;
 |  
 |  __setattr__(self, name: &#39;str&#39;, value) -&gt; &#39;None&#39;
 |      After regular attribute access, try setting the name
 |      This allows simpler access to columns for interactive use.
 |  
 |  __setstate__(self, state) -&gt; &#39;None&#39;
 |  
 |  abs(self: &#39;NDFrameT&#39;) -&gt; &#39;NDFrameT&#39;
 |      Return a Series/DataFrame with absolute numeric value of each element.
 |      
 |      This function only applies to elements that are all numeric.
 |      
 |      Returns
 |      -------
 |      abs
 |          Series/DataFrame containing the absolute value of each element.
 |      
 |      See Also
 |      --------
 |      numpy.absolute : Calculate the absolute value element-wise.
 |      
 |      Notes
 |      -----
 |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is
 |      :math:`\sqrt{ a^2 + b^2 }`.
 |      
 |      Examples
 |      --------
 |      Absolute numeric values in a Series.
 |      
 |      &gt;&gt;&gt; s = pd.Series([-1.10, 2, -3.33, 4])
 |      &gt;&gt;&gt; s.abs()
 |      0    1.10
 |      1    2.00
 |      2    3.33
 |      3    4.00
 |      dtype: float64
 |      
 |      Absolute numeric values in a Series with complex numbers.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1.2 + 1j])
 |      &gt;&gt;&gt; s.abs()
 |      0    1.56205
 |      dtype: float64
 |      
 |      Absolute numeric values in a Series with a Timedelta element.
 |      
 |      &gt;&gt;&gt; s = pd.Series([pd.Timedelta(&#39;1 days&#39;)])
 |      &gt;&gt;&gt; s.abs()
 |      0   1 days
 |      dtype: timedelta64[ns]
 |      
 |      Select rows with data closest to certain value using argsort (from
 |      `StackOverflow &lt;https://stackoverflow.com/a/17758115&gt;`__).
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;a&#39;: [4, 5, 6, 7],
 |      ...     &#39;b&#39;: [10, 20, 30, 40],
 |      ...     &#39;c&#39;: [100, 50, -30, -50]
 |      ... })
 |      &gt;&gt;&gt; df
 |           a    b    c
 |      0    4   10  100
 |      1    5   20   50
 |      2    6   30  -30
 |      3    7   40  -50
 |      &gt;&gt;&gt; df.loc[(df.c - 43).abs().argsort()]
 |           a    b    c
 |      1    5   20   50
 |      0    4   10  100
 |      2    6   30  -30
 |      3    7   40  -50
 |  
 |  add_prefix(self: &#39;NDFrameT&#39;, prefix: &#39;str&#39;, axis: &#39;Axis | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Prefix labels with string `prefix`.
 |      
 |      For Series, the row labels are prefixed.
 |      For DataFrame, the column labels are prefixed.
 |      
 |      Parameters
 |      ----------
 |      prefix : str
 |          The string to add before each label.
 |      axis : {{0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}}, default None
 |          Axis to add prefix on
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          New Series or DataFrame with updated labels.
 |      
 |      See Also
 |      --------
 |      Series.add_suffix: Suffix row labels with string `suffix`.
 |      DataFrame.add_suffix: Suffix column labels with string `suffix`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.add_prefix(&#39;item_&#39;)
 |      item_0    1
 |      item_1    2
 |      item_2    3
 |      item_3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4], &#39;B&#39;: [3, 4, 5, 6]})
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  1  3
 |      1  2  4
 |      2  3  5
 |      3  4  6
 |      
 |      &gt;&gt;&gt; df.add_prefix(&#39;col_&#39;)
 |           col_A  col_B
 |      0       1       3
 |      1       2       4
 |      2       3       5
 |      3       4       6
 |  
 |  add_suffix(self: &#39;NDFrameT&#39;, suffix: &#39;str&#39;, axis: &#39;Axis | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Suffix labels with string `suffix`.
 |      
 |      For Series, the row labels are suffixed.
 |      For DataFrame, the column labels are suffixed.
 |      
 |      Parameters
 |      ----------
 |      suffix : str
 |          The string to add after each label.
 |      axis : {{0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}}, default None
 |          Axis to add suffix on
 |      
 |          .. versionadded:: 2.0.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          New Series or DataFrame with updated labels.
 |      
 |      See Also
 |      --------
 |      Series.add_prefix: Prefix row labels with string `prefix`.
 |      DataFrame.add_prefix: Prefix column labels with string `prefix`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.add_suffix(&#39;_item&#39;)
 |      0_item    1
 |      1_item    2
 |      2_item    3
 |      3_item    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4], &#39;B&#39;: [3, 4, 5, 6]})
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  1  3
 |      1  2  4
 |      2  3  5
 |      3  4  6
 |      
 |      &gt;&gt;&gt; df.add_suffix(&#39;_col&#39;)
 |           A_col  B_col
 |      0       1       3
 |      1       2       4
 |      2       3       5
 |      3       4       6
 |  
 |  asof(self, where, subset=None)
 |      Return the last row(s) without any NaNs before `where`.
 |      
 |      The last row (for each element in `where`, if list) without any
 |      NaN is taken.
 |      In case of a :class:`~pandas.DataFrame`, the last row without NaN
 |      considering only the subset of columns (if not `None`)
 |      
 |      If there is no good value, NaN is returned for a Series or
 |      a Series of NaN values for a DataFrame
 |      
 |      Parameters
 |      ----------
 |      where : date or array-like of dates
 |          Date(s) before which the last row(s) are returned.
 |      subset : str or array-like of str, default `None`
 |          For DataFrame, if not `None`, only use these columns to
 |          check for NaNs.
 |      
 |      Returns
 |      -------
 |      scalar, Series, or DataFrame
 |      
 |          The return can be:
 |      
 |          * scalar : when `self` is a Series and `where` is a scalar
 |          * Series: when `self` is a Series and `where` is an array-like,
 |            or when `self` is a DataFrame and `where` is a scalar
 |          * DataFrame : when `self` is a DataFrame and `where` is an
 |            array-like
 |      
 |          Return scalar, Series, or DataFrame.
 |      
 |      See Also
 |      --------
 |      merge_asof : Perform an asof merge. Similar to left join.
 |      
 |      Notes
 |      -----
 |      Dates are assumed to be sorted. Raises if this is not the case.
 |      
 |      Examples
 |      --------
 |      A Series and a scalar `where`.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])
 |      &gt;&gt;&gt; s
 |      10    1.0
 |      20    2.0
 |      30    NaN
 |      40    4.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.asof(20)
 |      2.0
 |      
 |      For a sequence `where`, a Series is returned. The first value is
 |      NaN, because the first element of `where` is before the first
 |      index value.
 |      
 |      &gt;&gt;&gt; s.asof([5, 20])
 |      5     NaN
 |      20    2.0
 |      dtype: float64
 |      
 |      Missing values are not considered. The following is ``2.0``, not
 |      NaN, even though NaN is at the index location for ``30``.
 |      
 |      &gt;&gt;&gt; s.asof(30)
 |      2.0
 |      
 |      Take all columns into consideration
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;a&#39;: [10, 20, 30, 40, 50],
 |      ...                    &#39;b&#39;: [None, None, None, None, 500]},
 |      ...                   index=pd.DatetimeIndex([&#39;2018-02-27 09:01:00&#39;,
 |      ...                                           &#39;2018-02-27 09:02:00&#39;,
 |      ...                                           &#39;2018-02-27 09:03:00&#39;,
 |      ...                                           &#39;2018-02-27 09:04:00&#39;,
 |      ...                                           &#39;2018-02-27 09:05:00&#39;]))
 |      &gt;&gt;&gt; df.asof(pd.DatetimeIndex([&#39;2018-02-27 09:03:30&#39;,
 |      ...                           &#39;2018-02-27 09:04:30&#39;]))
 |                            a   b
 |      2018-02-27 09:03:30 NaN NaN
 |      2018-02-27 09:04:30 NaN NaN
 |      
 |      Take a single column into consideration
 |      
 |      &gt;&gt;&gt; df.asof(pd.DatetimeIndex([&#39;2018-02-27 09:03:30&#39;,
 |      ...                           &#39;2018-02-27 09:04:30&#39;]),
 |      ...         subset=[&#39;a&#39;])
 |                            a   b
 |      2018-02-27 09:03:30  30 NaN
 |      2018-02-27 09:04:30  40 NaN
 |  
 |  astype(self: &#39;NDFrameT&#39;, dtype, copy: &#39;bool_t | None&#39; = None, errors: &#39;IgnoreRaise&#39; = &#39;raise&#39;) -&gt; &#39;NDFrameT&#39;
 |      Cast a pandas object to a specified dtype ``dtype``.
 |      
 |      Parameters
 |      ----------
 |      dtype : str, data type, Series or Mapping of column name -&gt; data type
 |          Use a str, numpy.dtype, pandas.ExtensionDtype or Python type to
 |          cast entire pandas object to the same type. Alternatively, use a
 |          mapping, e.g. {col: dtype, ...}, where col is a column label and dtype is
 |          a numpy.dtype or Python type to cast one or more of the DataFrame&#39;s
 |          columns to column-specific types.
 |      copy : bool, default True
 |          Return a copy when ``copy=True`` (be very careful setting
 |          ``copy=False`` as changes to values then may propagate to other
 |          pandas objects).
 |      errors : {&#39;raise&#39;, &#39;ignore&#39;}, default &#39;raise&#39;
 |          Control raising of exceptions on invalid data for provided dtype.
 |      
 |          - ``raise`` : allow exceptions to be raised
 |          - ``ignore`` : suppress exceptions. On error return original object.
 |      
 |      Returns
 |      -------
 |      same type as caller
 |      
 |      See Also
 |      --------
 |      to_datetime : Convert argument to datetime.
 |      to_timedelta : Convert argument to timedelta.
 |      to_numeric : Convert argument to a numeric type.
 |      numpy.ndarray.astype : Cast a numpy array to a specified type.
 |      
 |      Notes
 |      -----
 |      .. versionchanged:: 2.0.0
 |      
 |          Using ``astype`` to convert from timezone-naive dtype to
 |          timezone-aware dtype will raise an exception.
 |          Use :meth:`Series.dt.tz_localize` instead.
 |      
 |      Examples
 |      --------
 |      Create a DataFrame:
 |      
 |      &gt;&gt;&gt; d = {&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]}
 |      &gt;&gt;&gt; df = pd.DataFrame(data=d)
 |      &gt;&gt;&gt; df.dtypes
 |      col1    int64
 |      col2    int64
 |      dtype: object
 |      
 |      Cast all columns to int32:
 |      
 |      &gt;&gt;&gt; df.astype(&#39;int32&#39;).dtypes
 |      col1    int32
 |      col2    int32
 |      dtype: object
 |      
 |      Cast col1 to int32 using a dictionary:
 |      
 |      &gt;&gt;&gt; df.astype({&#39;col1&#39;: &#39;int32&#39;}).dtypes
 |      col1    int32
 |      col2    int64
 |      dtype: object
 |      
 |      Create a series:
 |      
 |      &gt;&gt;&gt; ser = pd.Series([1, 2], dtype=&#39;int32&#39;)
 |      &gt;&gt;&gt; ser
 |      0    1
 |      1    2
 |      dtype: int32
 |      &gt;&gt;&gt; ser.astype(&#39;int64&#39;)
 |      0    1
 |      1    2
 |      dtype: int64
 |      
 |      Convert to categorical type:
 |      
 |      &gt;&gt;&gt; ser.astype(&#39;category&#39;)
 |      0    1
 |      1    2
 |      dtype: category
 |      Categories (2, int32): [1, 2]
 |      
 |      Convert to ordered categorical type with custom ordering:
 |      
 |      &gt;&gt;&gt; from pandas.api.types import CategoricalDtype
 |      &gt;&gt;&gt; cat_dtype = CategoricalDtype(
 |      ...     categories=[2, 1], ordered=True)
 |      &gt;&gt;&gt; ser.astype(cat_dtype)
 |      0    1
 |      1    2
 |      dtype: category
 |      Categories (2, int64): [2 &lt; 1]
 |      
 |      Create a series of dates:
 |      
 |      &gt;&gt;&gt; ser_date = pd.Series(pd.date_range(&#39;20200101&#39;, periods=3))
 |      &gt;&gt;&gt; ser_date
 |      0   2020-01-01
 |      1   2020-01-02
 |      2   2020-01-03
 |      dtype: datetime64[ns]
 |  
 |  at_time(self: &#39;NDFrameT&#39;, time, asof: &#39;bool_t&#39; = False, axis: &#39;Axis | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Select values at particular time of day (e.g., 9:30AM).
 |      
 |      Parameters
 |      ----------
 |      time : datetime.time or str
 |          The values to select.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      between_time : Select values between particular times of the day.
 |      first : Select initial periods of time series based on a date offset.
 |      last : Select final periods of time series based on a date offset.
 |      DatetimeIndex.indexer_at_time : Get just the index locations for
 |          values at particular time of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;12H&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                           A
 |      2018-04-09 00:00:00  1
 |      2018-04-09 12:00:00  2
 |      2018-04-10 00:00:00  3
 |      2018-04-10 12:00:00  4
 |      
 |      &gt;&gt;&gt; ts.at_time(&#39;12:00&#39;)
 |                           A
 |      2018-04-09 12:00:00  2
 |      2018-04-10 12:00:00  4
 |  
 |  backfill(self: &#39;NDFrameT&#39;, *, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool_t&#39; = False, limit: &#39;None | int&#39; = None, downcast: &#39;dict | None&#39; = None) -&gt; &#39;NDFrameT | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;bfill&#39;``.
 |      
 |      .. deprecated:: 2.0
 |      
 |          Series/DataFrame.backfill is deprecated. Use Series/DataFrame.bfill instead.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  between_time(self: &#39;NDFrameT&#39;, start_time, end_time, inclusive: &#39;IntervalClosedType&#39; = &#39;both&#39;, axis: &#39;Axis | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Select values between particular times of the day (e.g., 9:00-9:30 AM).
 |      
 |      By setting ``start_time`` to be later than ``end_time``,
 |      you can get the times that are *not* between the two times.
 |      
 |      Parameters
 |      ----------
 |      start_time : datetime.time or str
 |          Initial time as a time filter limit.
 |      end_time : datetime.time or str
 |          End time as a time filter limit.
 |      inclusive : {&quot;both&quot;, &quot;neither&quot;, &quot;left&quot;, &quot;right&quot;}, default &quot;both&quot;
 |          Include boundaries; whether to set each bound as closed or open.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Determine range time on index or columns value.
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Data from the original object filtered to the specified dates range.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      at_time : Select values at a particular time of the day.
 |      first : Select initial periods of time series based on a date offset.
 |      last : Select final periods of time series based on a date offset.
 |      DatetimeIndex.indexer_between_time : Get just the index locations for
 |          values between particular times of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;1D20min&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                           A
 |      2018-04-09 00:00:00  1
 |      2018-04-10 00:20:00  2
 |      2018-04-11 00:40:00  3
 |      2018-04-12 01:00:00  4
 |      
 |      &gt;&gt;&gt; ts.between_time(&#39;0:15&#39;, &#39;0:45&#39;)
 |                           A
 |      2018-04-10 00:20:00  2
 |      2018-04-11 00:40:00  3
 |      
 |      You get the times that are *not* between two times by setting
 |      ``start_time`` later than ``end_time``:
 |      
 |      &gt;&gt;&gt; ts.between_time(&#39;0:45&#39;, &#39;0:15&#39;)
 |                           A
 |      2018-04-09 00:00:00  1
 |      2018-04-12 01:00:00  4
 |  
 |  bool(self) -&gt; &#39;bool_t&#39;
 |      Return the bool of a single element Series or DataFrame.
 |      
 |      This must be a boolean scalar value, either True or False. It will raise a
 |      ValueError if the Series or DataFrame does not have exactly 1 element, or that
 |      element is not boolean (integer values 0 and 1 will also raise an exception).
 |      
 |      Returns
 |      -------
 |      bool
 |          The value in the Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      Series.astype : Change the data type of a Series, including to boolean.
 |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.
 |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.
 |      
 |      Examples
 |      --------
 |      The method will only work for single element objects with a boolean value:
 |      
 |      &gt;&gt;&gt; pd.Series([True]).bool()
 |      True
 |      &gt;&gt;&gt; pd.Series([False]).bool()
 |      False
 |      
 |      &gt;&gt;&gt; pd.DataFrame({&#39;col&#39;: [True]}).bool()
 |      True
 |      &gt;&gt;&gt; pd.DataFrame({&#39;col&#39;: [False]}).bool()
 |      False
 |  
 |  convert_dtypes(self: &#39;NDFrameT&#39;, infer_objects: &#39;bool_t&#39; = True, convert_string: &#39;bool_t&#39; = True, convert_integer: &#39;bool_t&#39; = True, convert_boolean: &#39;bool_t&#39; = True, convert_floating: &#39;bool_t&#39; = True, dtype_backend: &#39;DtypeBackend&#39; = &#39;numpy_nullable&#39;) -&gt; &#39;NDFrameT&#39;
 |      Convert columns to the best possible dtypes using dtypes supporting ``pd.NA``.
 |      
 |      Parameters
 |      ----------
 |      infer_objects : bool, default True
 |          Whether object dtypes should be converted to the best possible types.
 |      convert_string : bool, default True
 |          Whether object dtypes should be converted to ``StringDtype()``.
 |      convert_integer : bool, default True
 |          Whether, if possible, conversion can be done to integer extension types.
 |      convert_boolean : bool, defaults True
 |          Whether object dtypes should be converted to ``BooleanDtypes()``.
 |      convert_floating : bool, defaults True
 |          Whether, if possible, conversion can be done to floating extension types.
 |          If `convert_integer` is also True, preference will be give to integer
 |          dtypes if the floats can be faithfully casted to integers.
 |      
 |          .. versionadded:: 1.2.0
 |      dtype_backend : {&quot;numpy_nullable&quot;, &quot;pyarrow&quot;}, default &quot;numpy_nullable&quot;
 |          Which dtype_backend to use, e.g. whether a DataFrame should use nullable
 |          dtypes for all dtypes that have a nullable
 |          implementation when &quot;numpy_nullable&quot; is set, pyarrow is used for all
 |          dtypes if &quot;pyarrow&quot; is set.
 |      
 |          The dtype_backends are still experimential.
 |      
 |          .. versionadded:: 2.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Copy of input object with new dtype.
 |      
 |      See Also
 |      --------
 |      infer_objects : Infer dtypes of objects.
 |      to_datetime : Convert argument to datetime.
 |      to_timedelta : Convert argument to timedelta.
 |      to_numeric : Convert argument to a numeric type.
 |      
 |      Notes
 |      -----
 |      By default, ``convert_dtypes`` will attempt to convert a Series (or each
 |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options
 |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and
 |      ``convert_floating``, it is possible to turn off individual conversions
 |      to ``StringDtype``, the integer extension types, ``BooleanDtype``
 |      or floating extension types, respectively.
 |      
 |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference
 |      rules as during normal Series/DataFrame construction.  Then, if possible,
 |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer
 |      or floating extension type, otherwise leave as ``object``.
 |      
 |      If the dtype is integer, convert to an appropriate integer extension type.
 |      
 |      If the dtype is numeric, and consists of all integers, convert to an
 |      appropriate integer extension type. Otherwise, convert to an
 |      appropriate floating extension type.
 |      
 |      .. versionchanged:: 1.2
 |          Starting with pandas 1.2, this method also converts float columns
 |          to the nullable floating extension type.
 |      
 |      In the future, as new dtypes are added that support ``pd.NA``, the results
 |      of this method will change to support those new dtypes.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     {
 |      ...         &quot;a&quot;: pd.Series([1, 2, 3], dtype=np.dtype(&quot;int32&quot;)),
 |      ...         &quot;b&quot;: pd.Series([&quot;x&quot;, &quot;y&quot;, &quot;z&quot;], dtype=np.dtype(&quot;O&quot;)),
 |      ...         &quot;c&quot;: pd.Series([True, False, np.nan], dtype=np.dtype(&quot;O&quot;)),
 |      ...         &quot;d&quot;: pd.Series([&quot;h&quot;, &quot;i&quot;, np.nan], dtype=np.dtype(&quot;O&quot;)),
 |      ...         &quot;e&quot;: pd.Series([10, np.nan, 20], dtype=np.dtype(&quot;float&quot;)),
 |      ...         &quot;f&quot;: pd.Series([np.nan, 100.5, 200], dtype=np.dtype(&quot;float&quot;)),
 |      ...     }
 |      ... )
 |      
 |      Start with a DataFrame with default dtypes.
 |      
 |      &gt;&gt;&gt; df
 |         a  b      c    d     e      f
 |      0  1  x   True    h  10.0    NaN
 |      1  2  y  False    i   NaN  100.5
 |      2  3  z    NaN  NaN  20.0  200.0
 |      
 |      &gt;&gt;&gt; df.dtypes
 |      a      int32
 |      b     object
 |      c     object
 |      d     object
 |      e    float64
 |      f    float64
 |      dtype: object
 |      
 |      Convert the DataFrame to use best possible dtypes.
 |      
 |      &gt;&gt;&gt; dfn = df.convert_dtypes()
 |      &gt;&gt;&gt; dfn
 |         a  b      c     d     e      f
 |      0  1  x   True     h    10   &lt;NA&gt;
 |      1  2  y  False     i  &lt;NA&gt;  100.5
 |      2  3  z   &lt;NA&gt;  &lt;NA&gt;    20  200.0
 |      
 |      &gt;&gt;&gt; dfn.dtypes
 |      a             Int32
 |      b    string[python]
 |      c           boolean
 |      d    string[python]
 |      e             Int64
 |      f           Float64
 |      dtype: object
 |      
 |      Start with a Series of strings and missing data represented by ``np.nan``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([&quot;a&quot;, &quot;b&quot;, np.nan])
 |      &gt;&gt;&gt; s
 |      0      a
 |      1      b
 |      2    NaN
 |      dtype: object
 |      
 |      Obtain a Series with dtype ``StringDtype``.
 |      
 |      &gt;&gt;&gt; s.convert_dtypes()
 |      0       a
 |      1       b
 |      2    &lt;NA&gt;
 |      dtype: string
 |  
 |  copy(self: &#39;NDFrameT&#39;, deep: &#39;bool_t | None&#39; = True) -&gt; &#39;NDFrameT&#39;
 |      Make a copy of this object&#39;s indices and data.
 |      
 |      When ``deep=True`` (default), a new object will be created with a
 |      copy of the calling object&#39;s data and indices. Modifications to
 |      the data or indices of the copy will not be reflected in the
 |      original object (see notes below).
 |      
 |      When ``deep=False``, a new object will be created without copying
 |      the calling object&#39;s data or index (only references to the data
 |      and index are copied). Any changes to the data of the original
 |      will be reflected in the shallow copy (and vice versa).
 |      
 |      Parameters
 |      ----------
 |      deep : bool, default True
 |          Make a deep copy, including a copy of the data and the indices.
 |          With ``deep=False`` neither the indices nor the data are copied.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Object type matches caller.
 |      
 |      Notes
 |      -----
 |      When ``deep=True``, data is copied but actual Python objects
 |      will not be copied recursively, only the reference to the object.
 |      This is in contrast to `copy.deepcopy` in the Standard Library,
 |      which recursively copies object data (see examples below).
 |      
 |      While ``Index`` objects are copied when ``deep=True``, the underlying
 |      numpy array is not copied for performance reasons. Since ``Index`` is
 |      immutable, the underlying data can be safely shared and a copy
 |      is not needed.
 |      
 |      Since pandas is not thread safe, see the
 |      :ref:`gotchas &lt;gotchas.thread-safety&gt;` when copying in a threading
 |      environment.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2], index=[&quot;a&quot;, &quot;b&quot;])
 |      &gt;&gt;&gt; s
 |      a    1
 |      b    2
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s_copy = s.copy()
 |      &gt;&gt;&gt; s_copy
 |      a    1
 |      b    2
 |      dtype: int64
 |      
 |      **Shallow copy versus default (deep) copy:**
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2], index=[&quot;a&quot;, &quot;b&quot;])
 |      &gt;&gt;&gt; deep = s.copy()
 |      &gt;&gt;&gt; shallow = s.copy(deep=False)
 |      
 |      Shallow copy shares data and index with original.
 |      
 |      &gt;&gt;&gt; s is shallow
 |      False
 |      &gt;&gt;&gt; s.values is shallow.values and s.index is shallow.index
 |      True
 |      
 |      Deep copy has own copy of data and index.
 |      
 |      &gt;&gt;&gt; s is deep
 |      False
 |      &gt;&gt;&gt; s.values is deep.values or s.index is deep.index
 |      False
 |      
 |      Updates to the data shared by shallow copy and original is reflected
 |      in both; deep copy remains unchanged.
 |      
 |      &gt;&gt;&gt; s[0] = 3
 |      &gt;&gt;&gt; shallow[1] = 4
 |      &gt;&gt;&gt; s
 |      a    3
 |      b    4
 |      dtype: int64
 |      &gt;&gt;&gt; shallow
 |      a    3
 |      b    4
 |      dtype: int64
 |      &gt;&gt;&gt; deep
 |      a    1
 |      b    2
 |      dtype: int64
 |      
 |      Note that when copying an object containing Python objects, a deep copy
 |      will copy the data, but will not do so recursively. Updating a nested
 |      data object will be reflected in the deep copy.
 |      
 |      &gt;&gt;&gt; s = pd.Series([[1, 2], [3, 4]])
 |      &gt;&gt;&gt; deep = s.copy()
 |      &gt;&gt;&gt; s[0][0] = 10
 |      &gt;&gt;&gt; s
 |      0    [10, 2]
 |      1     [3, 4]
 |      dtype: object
 |      &gt;&gt;&gt; deep
 |      0    [10, 2]
 |      1     [3, 4]
 |      dtype: object
 |  
 |  describe(self: &#39;NDFrameT&#39;, percentiles=None, include=None, exclude=None) -&gt; &#39;NDFrameT&#39;
 |      Generate descriptive statistics.
 |      
 |      Descriptive statistics include those that summarize the central
 |      tendency, dispersion and shape of a
 |      dataset&#39;s distribution, excluding ``NaN`` values.
 |      
 |      Analyzes both numeric and object series, as well
 |      as ``DataFrame`` column sets of mixed data types. The output
 |      will vary depending on what is provided. Refer to the notes
 |      below for more detail.
 |      
 |      Parameters
 |      ----------
 |      percentiles : list-like of numbers, optional
 |          The percentiles to include in the output. All should
 |          fall between 0 and 1. The default is
 |          ``[.25, .5, .75]``, which returns the 25th, 50th, and
 |          75th percentiles.
 |      include : &#39;all&#39;, list-like of dtypes or None (default), optional
 |          A white list of data types to include in the result. Ignored
 |          for ``Series``. Here are the options:
 |      
 |          - &#39;all&#39; : All columns of the input will be included in the output.
 |          - A list-like of dtypes : Limits the results to the
 |            provided data types.
 |            To limit the result to numeric types submit
 |            ``numpy.number``. To limit it instead to object columns submit
 |            the ``numpy.object`` data type. Strings
 |            can also be used in the style of
 |            ``select_dtypes`` (e.g. ``df.describe(include=[&#39;O&#39;])``). To
 |            select pandas categorical columns, use ``&#39;category&#39;``
 |          - None (default) : The result will include all numeric columns.
 |      exclude : list-like of dtypes or None (default), optional,
 |          A black list of data types to omit from the result. Ignored
 |          for ``Series``. Here are the options:
 |      
 |          - A list-like of dtypes : Excludes the provided data types
 |            from the result. To exclude numeric types submit
 |            ``numpy.number``. To exclude object columns submit the data
 |            type ``numpy.object``. Strings can also be used in the style of
 |            ``select_dtypes`` (e.g. ``df.describe(exclude=[&#39;O&#39;])``). To
 |            exclude pandas categorical columns, use ``&#39;category&#39;``
 |          - None (default) : The result will exclude nothing.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Summary statistics of the Series or Dataframe provided.
 |      
 |      See Also
 |      --------
 |      DataFrame.count: Count number of non-NA/null observations.
 |      DataFrame.max: Maximum of the values in the object.
 |      DataFrame.min: Minimum of the values in the object.
 |      DataFrame.mean: Mean of the values.
 |      DataFrame.std: Standard deviation of the observations.
 |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding
 |          columns based on their dtype.
 |      
 |      Notes
 |      -----
 |      For numeric data, the result&#39;s index will include ``count``,
 |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and
 |      upper percentiles. By default the lower percentile is ``25`` and the
 |      upper percentile is ``75``. The ``50`` percentile is the
 |      same as the median.
 |      
 |      For object data (e.g. strings or timestamps), the result&#39;s index
 |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``
 |      is the most common value. The ``freq`` is the most common value&#39;s
 |      frequency. Timestamps also include the ``first`` and ``last`` items.
 |      
 |      If multiple object values have the highest count, then the
 |      ``count`` and ``top`` results will be arbitrarily chosen from
 |      among those with the highest count.
 |      
 |      For mixed data types provided via a ``DataFrame``, the default is to
 |      return only an analysis of numeric columns. If the dataframe consists
 |      only of object and categorical data without any numeric columns, the
 |      default is to return an analysis of both the object and categorical
 |      columns. If ``include=&#39;all&#39;`` is provided as an option, the result
 |      will include a union of attributes of each type.
 |      
 |      The `include` and `exclude` parameters can be used to limit
 |      which columns in a ``DataFrame`` are analyzed for the output.
 |      The parameters are ignored when analyzing a ``Series``.
 |      
 |      Examples
 |      --------
 |      Describing a numeric ``Series``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.describe()
 |      count    3.0
 |      mean     2.0
 |      std      1.0
 |      min      1.0
 |      25%      1.5
 |      50%      2.0
 |      75%      2.5
 |      max      3.0
 |      dtype: float64
 |      
 |      Describing a categorical ``Series``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; s.describe()
 |      count     4
 |      unique    3
 |      top       a
 |      freq      2
 |      dtype: object
 |      
 |      Describing a timestamp ``Series``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([
 |      ...     np.datetime64(&quot;2000-01-01&quot;),
 |      ...     np.datetime64(&quot;2010-01-01&quot;),
 |      ...     np.datetime64(&quot;2010-01-01&quot;)
 |      ... ])
 |      &gt;&gt;&gt; s.describe()
 |      count                      3
 |      mean     2006-09-01 08:00:00
 |      min      2000-01-01 00:00:00
 |      25%      2004-12-31 12:00:00
 |      50%      2010-01-01 00:00:00
 |      75%      2010-01-01 00:00:00
 |      max      2010-01-01 00:00:00
 |      dtype: object
 |      
 |      Describing a ``DataFrame``. By default only numeric fields
 |      are returned.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;categorical&#39;: pd.Categorical([&#39;d&#39;,&#39;e&#39;,&#39;f&#39;]),
 |      ...                    &#39;numeric&#39;: [1, 2, 3],
 |      ...                    &#39;object&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      ...                   })
 |      &gt;&gt;&gt; df.describe()
 |             numeric
 |      count      3.0
 |      mean       2.0
 |      std        1.0
 |      min        1.0
 |      25%        1.5
 |      50%        2.0
 |      75%        2.5
 |      max        3.0
 |      
 |      Describing all columns of a ``DataFrame`` regardless of data type.
 |      
 |      &gt;&gt;&gt; df.describe(include=&#39;all&#39;)  # doctest: +SKIP
 |             categorical  numeric object
 |      count            3      3.0      3
 |      unique           3      NaN      3
 |      top              f      NaN      a
 |      freq             1      NaN      1
 |      mean           NaN      2.0    NaN
 |      std            NaN      1.0    NaN
 |      min            NaN      1.0    NaN
 |      25%            NaN      1.5    NaN
 |      50%            NaN      2.0    NaN
 |      75%            NaN      2.5    NaN
 |      max            NaN      3.0    NaN
 |      
 |      Describing a column from a ``DataFrame`` by accessing it as
 |      an attribute.
 |      
 |      &gt;&gt;&gt; df.numeric.describe()
 |      count    3.0
 |      mean     2.0
 |      std      1.0
 |      min      1.0
 |      25%      1.5
 |      50%      2.0
 |      75%      2.5
 |      max      3.0
 |      Name: numeric, dtype: float64
 |      
 |      Including only numeric columns in a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(include=[np.number])
 |             numeric
 |      count      3.0
 |      mean       2.0
 |      std        1.0
 |      min        1.0
 |      25%        1.5
 |      50%        2.0
 |      75%        2.5
 |      max        3.0
 |      
 |      Including only string columns in a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP
 |             object
 |      count       3
 |      unique      3
 |      top         a
 |      freq        1
 |      
 |      Including only categorical columns from a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(include=[&#39;category&#39;])
 |             categorical
 |      count            3
 |      unique           3
 |      top              d
 |      freq             1
 |      
 |      Excluding numeric columns from a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP
 |             categorical object
 |      count            3      3
 |      unique           3      3
 |      top              f      a
 |      freq             1      1
 |      
 |      Excluding object columns from a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP
 |             categorical  numeric
 |      count            3      3.0
 |      unique           3      NaN
 |      top              f      NaN
 |      freq             1      NaN
 |      mean           NaN      2.0
 |      std            NaN      1.0
 |      min            NaN      1.0
 |      25%            NaN      1.5
 |      50%            NaN      2.0
 |      75%            NaN      2.5
 |      max            NaN      3.0
 |  
 |  droplevel(self: &#39;NDFrameT&#39;, level: &#39;IndexLabel&#39;, axis: &#39;Axis&#39; = 0) -&gt; &#39;NDFrameT&#39;
 |      Return Series/DataFrame with requested index / column level(s) removed.
 |      
 |      Parameters
 |      ----------
 |      level : int, str, or list-like
 |          If a string is given, must be the name of a level
 |          If list-like, elements must be names or positional indexes
 |          of levels.
 |      
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Axis along which the level(s) is removed:
 |      
 |          * 0 or &#39;index&#39;: remove level(s) in column.
 |          * 1 or &#39;columns&#39;: remove level(s) in row.
 |      
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame
 |          Series/DataFrame with requested index / column level(s) removed.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([
 |      ...     [1, 2, 3, 4],
 |      ...     [5, 6, 7, 8],
 |      ...     [9, 10, 11, 12]
 |      ... ]).set_index([0, 1]).rename_axis([&#39;a&#39;, &#39;b&#39;])
 |      
 |      &gt;&gt;&gt; df.columns = pd.MultiIndex.from_tuples([
 |      ...     (&#39;c&#39;, &#39;e&#39;), (&#39;d&#39;, &#39;f&#39;)
 |      ... ], names=[&#39;level_1&#39;, &#39;level_2&#39;])
 |      
 |      &gt;&gt;&gt; df
 |      level_1   c   d
 |      level_2   e   f
 |      a b
 |      1 2      3   4
 |      5 6      7   8
 |      9 10    11  12
 |      
 |      &gt;&gt;&gt; df.droplevel(&#39;a&#39;)
 |      level_1   c   d
 |      level_2   e   f
 |      b
 |      2        3   4
 |      6        7   8
 |      10      11  12
 |      
 |      &gt;&gt;&gt; df.droplevel(&#39;level_2&#39;, axis=1)
 |      level_1   c   d
 |      a b
 |      1 2      3   4
 |      5 6      7   8
 |      9 10    11  12
 |  
 |  equals(self, other: &#39;object&#39;) -&gt; &#39;bool_t&#39;
 |      Test whether two objects contain the same elements.
 |      
 |      This function allows two Series or DataFrames to be compared against
 |      each other to see if they have the same shape and elements. NaNs in
 |      the same location are considered equal.
 |      
 |      The row/column index do not need to have the same type, as long
 |      as the values are considered equal. Corresponding columns must be of
 |      the same dtype.
 |      
 |      Parameters
 |      ----------
 |      other : Series or DataFrame
 |          The other Series or DataFrame to be compared with the first.
 |      
 |      Returns
 |      -------
 |      bool
 |          True if all elements are the same in both objects, False
 |          otherwise.
 |      
 |      See Also
 |      --------
 |      Series.eq : Compare two Series objects of the same length
 |          and return a Series where each element is True if the element
 |          in each Series is equal, False otherwise.
 |      DataFrame.eq : Compare two DataFrame objects of the same shape and
 |          return a DataFrame where each element is True if the respective
 |          element in each DataFrame is equal, False otherwise.
 |      testing.assert_series_equal : Raises an AssertionError if left and
 |          right are not equal. Provides an easy interface to ignore
 |          inequality in dtypes, indexes and precision among others.
 |      testing.assert_frame_equal : Like assert_series_equal, but targets
 |          DataFrames.
 |      numpy.array_equal : Return True if two arrays have the same shape
 |          and elements, False otherwise.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({1: [10], 2: [20]})
 |      &gt;&gt;&gt; df
 |          1   2
 |      0  10  20
 |      
 |      DataFrames df and exactly_equal have the same types and values for
 |      their elements and column labels, which will return True.
 |      
 |      &gt;&gt;&gt; exactly_equal = pd.DataFrame({1: [10], 2: [20]})
 |      &gt;&gt;&gt; exactly_equal
 |          1   2
 |      0  10  20
 |      &gt;&gt;&gt; df.equals(exactly_equal)
 |      True
 |      
 |      DataFrames df and different_column_type have the same element
 |      types and values, but have different types for the column labels,
 |      which will still return True.
 |      
 |      &gt;&gt;&gt; different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
 |      &gt;&gt;&gt; different_column_type
 |         1.0  2.0
 |      0   10   20
 |      &gt;&gt;&gt; df.equals(different_column_type)
 |      True
 |      
 |      DataFrames df and different_data_type have different types for the
 |      same values for their elements, and will return False even though
 |      their column labels are the same values and types.
 |      
 |      &gt;&gt;&gt; different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
 |      &gt;&gt;&gt; different_data_type
 |            1     2
 |      0  10.0  20.0
 |      &gt;&gt;&gt; df.equals(different_data_type)
 |      False
 |  
 |  ewm(self, com: &#39;float | None&#39; = None, span: &#39;float | None&#39; = None, halflife: &#39;float | TimedeltaConvertibleTypes | None&#39; = None, alpha: &#39;float | None&#39; = None, min_periods: &#39;int | None&#39; = 0, adjust: &#39;bool_t&#39; = True, ignore_na: &#39;bool_t&#39; = False, axis: &#39;Axis&#39; = 0, times: &#39;np.ndarray | DataFrame | Series | None&#39; = None, method: &#39;str&#39; = &#39;single&#39;) -&gt; &#39;ExponentialMovingWindow&#39;
 |      Provide exponentially weighted (EW) calculations.
 |      
 |      Exactly one of ``com``, ``span``, ``halflife``, or ``alpha`` must be
 |      provided if ``times`` is not provided. If ``times`` is provided,
 |      ``halflife`` and one of ``com``, ``span`` or ``alpha`` may be provided.
 |      
 |      Parameters
 |      ----------
 |      com : float, optional
 |          Specify decay in terms of center of mass
 |      
 |          :math:`\alpha = 1 / (1 + com)`, for :math:`com \geq 0`.
 |      
 |      span : float, optional
 |          Specify decay in terms of span
 |      
 |          :math:`\alpha = 2 / (span + 1)`, for :math:`span \geq 1`.
 |      
 |      halflife : float, str, timedelta, optional
 |          Specify decay in terms of half-life
 |      
 |          :math:`\alpha = 1 - \exp\left(-\ln(2) / halflife\right)`, for
 |          :math:`halflife &gt; 0`.
 |      
 |          If ``times`` is specified, a timedelta convertible unit over which an
 |          observation decays to half its value. Only applicable to ``mean()``,
 |          and halflife value will not apply to the other functions.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      alpha : float, optional
 |          Specify smoothing factor :math:`\alpha` directly
 |      
 |          :math:`0 &lt; \alpha \leq 1`.
 |      
 |      min_periods : int, default 0
 |          Minimum number of observations in window required to have a value;
 |          otherwise, result is ``np.nan``.
 |      
 |      adjust : bool, default True
 |          Divide by decaying adjustment factor in beginning periods to account
 |          for imbalance in relative weightings (viewing EWMA as a moving average).
 |      
 |          - When ``adjust=True`` (default), the EW function is calculated using weights
 |            :math:`w_i = (1 - \alpha)^i`. For example, the EW moving average of the series
 |            [:math:`x_0, x_1, ..., x_t`] would be:
 |      
 |          .. math::
 |              y_t = \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ... + (1 -
 |              \alpha)^t x_0}{1 + (1 - \alpha) + (1 - \alpha)^2 + ... + (1 - \alpha)^t}
 |      
 |          - When ``adjust=False``, the exponentially weighted function is calculated
 |            recursively:
 |      
 |          .. math::
 |              \begin{split}
 |                  y_0 &amp;= x_0\\
 |                  y_t &amp;= (1 - \alpha) y_{t-1} + \alpha x_t,
 |              \end{split}
 |      ignore_na : bool, default False
 |          Ignore missing values when calculating weights.
 |      
 |          - When ``ignore_na=False`` (default), weights are based on absolute positions.
 |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating
 |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are
 |            :math:`(1-\alpha)^2` and :math:`1` if ``adjust=True``, and
 |            :math:`(1-\alpha)^2` and :math:`\alpha` if ``adjust=False``.
 |      
 |          - When ``ignore_na=True``, weights are based
 |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`
 |            used in calculating the final weighted average of
 |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\alpha` and :math:`1` if
 |            ``adjust=True``, and :math:`1-\alpha` and :math:`\alpha` if ``adjust=False``.
 |      
 |      axis : {0, 1}, default 0
 |          If ``0`` or ``&#39;index&#39;``, calculate across the rows.
 |      
 |          If ``1`` or ``&#39;columns&#39;``, calculate across the columns.
 |      
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |      times : np.ndarray, Series, default None
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          Only applicable to ``mean()``.
 |      
 |          Times corresponding to the observations. Must be monotonically increasing and
 |          ``datetime64[ns]`` dtype.
 |      
 |          If 1-D array like, a sequence with the same shape as the observations.
 |      
 |      method : str {&#39;single&#39;, &#39;table&#39;}, default &#39;single&#39;
 |          .. versionadded:: 1.4.0
 |      
 |          Execute the rolling operation per single column or row (``&#39;single&#39;``)
 |          or over the entire object (``&#39;table&#39;``).
 |      
 |          This argument is only implemented when specifying ``engine=&#39;numba&#39;``
 |          in the method call.
 |      
 |          Only applicable to ``mean()``
 |      
 |      Returns
 |      -------
 |      ``ExponentialMovingWindow`` subclass
 |      
 |      See Also
 |      --------
 |      rolling : Provides rolling window calculations.
 |      expanding : Provides expanding transformations.
 |      
 |      Notes
 |      -----
 |      See :ref:`Windowing Operations &lt;window.exponentially_weighted&gt;`
 |      for further usage details and examples.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4]})
 |      &gt;&gt;&gt; df
 |           B
 |      0  0.0
 |      1  1.0
 |      2  2.0
 |      3  NaN
 |      4  4.0
 |      
 |      &gt;&gt;&gt; df.ewm(com=0.5).mean()
 |                B
 |      0  0.000000
 |      1  0.750000
 |      2  1.615385
 |      3  1.615385
 |      4  3.670213
 |      &gt;&gt;&gt; df.ewm(alpha=2 / 3).mean()
 |                B
 |      0  0.000000
 |      1  0.750000
 |      2  1.615385
 |      3  1.615385
 |      4  3.670213
 |      
 |      **adjust**
 |      
 |      &gt;&gt;&gt; df.ewm(com=0.5, adjust=True).mean()
 |                B
 |      0  0.000000
 |      1  0.750000
 |      2  1.615385
 |      3  1.615385
 |      4  3.670213
 |      &gt;&gt;&gt; df.ewm(com=0.5, adjust=False).mean()
 |                B
 |      0  0.000000
 |      1  0.666667
 |      2  1.555556
 |      3  1.555556
 |      4  3.650794
 |      
 |      **ignore_na**
 |      
 |      &gt;&gt;&gt; df.ewm(com=0.5, ignore_na=True).mean()
 |                B
 |      0  0.000000
 |      1  0.750000
 |      2  1.615385
 |      3  1.615385
 |      4  3.225000
 |      &gt;&gt;&gt; df.ewm(com=0.5, ignore_na=False).mean()
 |                B
 |      0  0.000000
 |      1  0.750000
 |      2  1.615385
 |      3  1.615385
 |      4  3.670213
 |      
 |      **times**
 |      
 |      Exponentially weighted mean with weights calculated with a timedelta ``halflife``
 |      relative to ``times``.
 |      
 |      &gt;&gt;&gt; times = [&#39;2020-01-01&#39;, &#39;2020-01-03&#39;, &#39;2020-01-10&#39;, &#39;2020-01-15&#39;, &#39;2020-01-17&#39;]
 |      &gt;&gt;&gt; df.ewm(halflife=&#39;4 days&#39;, times=pd.DatetimeIndex(times)).mean()
 |                B
 |      0  0.000000
 |      1  0.585786
 |      2  1.523889
 |      3  1.523889
 |      4  3.233686
 |  
 |  expanding(self, min_periods: &#39;int&#39; = 1, axis: &#39;Axis&#39; = 0, method: &#39;str&#39; = &#39;single&#39;) -&gt; &#39;Expanding&#39;
 |      Provide expanding window calculations.
 |      
 |      Parameters
 |      ----------
 |      min_periods : int, default 1
 |          Minimum number of observations in window required to have a value;
 |          otherwise, result is ``np.nan``.
 |      
 |      axis : int or str, default 0
 |          If ``0`` or ``&#39;index&#39;``, roll across the rows.
 |      
 |          If ``1`` or ``&#39;columns&#39;``, roll across the columns.
 |      
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |      method : str {&#39;single&#39;, &#39;table&#39;}, default &#39;single&#39;
 |          Execute the rolling operation per single column or row (``&#39;single&#39;``)
 |          or over the entire object (``&#39;table&#39;``).
 |      
 |          This argument is only implemented when specifying ``engine=&#39;numba&#39;``
 |          in the method call.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      ``Expanding`` subclass
 |      
 |      See Also
 |      --------
 |      rolling : Provides rolling window calculations.
 |      ewm : Provides exponential weighted functions.
 |      
 |      Notes
 |      -----
 |      See :ref:`Windowing Operations &lt;window.expanding&gt;` for further usage details
 |      and examples.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;B&quot;: [0, 1, 2, np.nan, 4]})
 |      &gt;&gt;&gt; df
 |           B
 |      0  0.0
 |      1  1.0
 |      2  2.0
 |      3  NaN
 |      4  4.0
 |      
 |      **min_periods**
 |      
 |      Expanding sum with 1 vs 3 observations needed to calculate a value.
 |      
 |      &gt;&gt;&gt; df.expanding(1).sum()
 |           B
 |      0  0.0
 |      1  1.0
 |      2  3.0
 |      3  3.0
 |      4  7.0
 |      &gt;&gt;&gt; df.expanding(3).sum()
 |           B
 |      0  NaN
 |      1  NaN
 |      2  3.0
 |      3  3.0
 |      4  7.0
 |  
 |  filter(self: &#39;NDFrameT&#39;, items=None, like: &#39;str | None&#39; = None, regex: &#39;str | None&#39; = None, axis: &#39;Axis | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Subset the dataframe rows or columns according to the specified index labels.
 |      
 |      Note that this routine does not filter a dataframe on its
 |      contents. The filter is applied to the labels of the index.
 |      
 |      Parameters
 |      ----------
 |      items : list-like
 |          Keep labels from axis which are in items.
 |      like : str
 |          Keep labels from axis for which &quot;like in label == True&quot;.
 |      regex : str (regular expression)
 |          Keep labels from axis for which re.search(regex, label) == True.
 |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None
 |          The axis to filter on, expressed either as an index (int)
 |          or axis name (str). By default this is the info axis, &#39;columns&#39; for
 |          DataFrame. For `Series` this parameter is unused and defaults to `None`.
 |      
 |      Returns
 |      -------
 |      same type as input object
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Access a group of rows and columns
 |          by label(s) or a boolean array.
 |      
 |      Notes
 |      -----
 |      The ``items``, ``like``, and ``regex`` parameters are
 |      enforced to be mutually exclusive.
 |      
 |      ``axis`` defaults to the info axis that is used when indexing
 |      with ``[]``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),
 |      ...                   index=[&#39;mouse&#39;, &#39;rabbit&#39;],
 |      ...                   columns=[&#39;one&#39;, &#39;two&#39;, &#39;three&#39;])
 |      &gt;&gt;&gt; df
 |              one  two  three
 |      mouse     1    2      3
 |      rabbit    4    5      6
 |      
 |      &gt;&gt;&gt; # select columns by name
 |      &gt;&gt;&gt; df.filter(items=[&#39;one&#39;, &#39;three&#39;])
 |               one  three
 |      mouse     1      3
 |      rabbit    4      6
 |      
 |      &gt;&gt;&gt; # select columns by regular expression
 |      &gt;&gt;&gt; df.filter(regex=&#39;e$&#39;, axis=1)
 |               one  three
 |      mouse     1      3
 |      rabbit    4      6
 |      
 |      &gt;&gt;&gt; # select rows containing &#39;bbi&#39;
 |      &gt;&gt;&gt; df.filter(like=&#39;bbi&#39;, axis=0)
 |               one  two  three
 |      rabbit    4    5      6
 |  
 |  first(self: &#39;NDFrameT&#39;, offset) -&gt; &#39;NDFrameT&#39;
 |      Select initial periods of time series data based on a date offset.
 |      
 |      For a DataFrame with a sorted DatetimeIndex, this function can
 |      select the first few rows based on a date offset.
 |      
 |      Parameters
 |      ----------
 |      offset : str, DateOffset or dateutil.relativedelta
 |          The offset length of the data that will be selected. For instance,
 |          &#39;1M&#39; will display all the rows having their index within the first month.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          A subset of the caller.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      last : Select final periods of time series based on a date offset.
 |      at_time : Select values at a particular time of the day.
 |      between_time : Select values between particular times of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;2D&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                  A
 |      2018-04-09  1
 |      2018-04-11  2
 |      2018-04-13  3
 |      2018-04-15  4
 |      
 |      Get the rows for the first 3 days:
 |      
 |      &gt;&gt;&gt; ts.first(&#39;3D&#39;)
 |                  A
 |      2018-04-09  1
 |      2018-04-11  2
 |      
 |      Notice the data for 3 first calendar days were returned, not the first
 |      3 days observed in the dataset, and therefore data for 2018-04-13 was
 |      not returned.
 |  
 |  first_valid_index(self) -&gt; &#39;Hashable | None&#39;
 |      Return index for first non-NA value or None, if no non-NA value is found.
 |      
 |      Returns
 |      -------
 |      type of index
 |      
 |      Notes
 |      -----
 |      If all elements are non-NA/null, returns None.
 |      Also returns None for empty Series/DataFrame.
 |  
 |  get(self, key, default=None)
 |      Get item from object for given key (ex: DataFrame column).
 |      
 |      Returns default value if not found.
 |      
 |      Parameters
 |      ----------
 |      key : object
 |      
 |      Returns
 |      -------
 |      same type as items contained in object
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     [
 |      ...         [24.3, 75.7, &quot;high&quot;],
 |      ...         [31, 87.8, &quot;high&quot;],
 |      ...         [22, 71.6, &quot;medium&quot;],
 |      ...         [35, 95, &quot;medium&quot;],
 |      ...     ],
 |      ...     columns=[&quot;temp_celsius&quot;, &quot;temp_fahrenheit&quot;, &quot;windspeed&quot;],
 |      ...     index=pd.date_range(start=&quot;2014-02-12&quot;, end=&quot;2014-02-15&quot;, freq=&quot;D&quot;),
 |      ... )
 |      
 |      &gt;&gt;&gt; df
 |                  temp_celsius  temp_fahrenheit windspeed
 |      2014-02-12          24.3             75.7      high
 |      2014-02-13          31.0             87.8      high
 |      2014-02-14          22.0             71.6    medium
 |      2014-02-15          35.0             95.0    medium
 |      
 |      &gt;&gt;&gt; df.get([&quot;temp_celsius&quot;, &quot;windspeed&quot;])
 |                  temp_celsius windspeed
 |      2014-02-12          24.3      high
 |      2014-02-13          31.0      high
 |      2014-02-14          22.0    medium
 |      2014-02-15          35.0    medium
 |      
 |      &gt;&gt;&gt; ser = df[&#39;windspeed&#39;]
 |      &gt;&gt;&gt; ser.get(&#39;2014-02-13&#39;)
 |      &#39;high&#39;
 |      
 |      If the key isn&#39;t found, the default value will be used.
 |      
 |      &gt;&gt;&gt; df.get([&quot;temp_celsius&quot;, &quot;temp_kelvin&quot;], default=&quot;default_value&quot;)
 |      &#39;default_value&#39;
 |      
 |      &gt;&gt;&gt; ser.get(&#39;2014-02-10&#39;, &#39;[unknown]&#39;)
 |      &#39;[unknown]&#39;
 |  
 |  head(self: &#39;NDFrameT&#39;, n: &#39;int&#39; = 5) -&gt; &#39;NDFrameT&#39;
 |      Return the first `n` rows.
 |      
 |      This function returns the first `n` rows for the object based
 |      on position. It is useful for quickly testing if your object
 |      has the right type of data in it.
 |      
 |      For negative values of `n`, this function returns all rows except
 |      the last `|n|` rows, equivalent to ``df[:n]``.
 |      
 |      If n is larger than the number of rows, this function returns all rows.
 |      
 |      Parameters
 |      ----------
 |      n : int, default 5
 |          Number of rows to select.
 |      
 |      Returns
 |      -------
 |      same type as caller
 |          The first `n` rows of the caller object.
 |      
 |      See Also
 |      --------
 |      DataFrame.tail: Returns the last `n` rows.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;animal&#39;: [&#39;alligator&#39;, &#39;bee&#39;, &#39;falcon&#39;, &#39;lion&#39;,
 |      ...                    &#39;monkey&#39;, &#39;parrot&#39;, &#39;shark&#39;, &#39;whale&#39;, &#39;zebra&#39;]})
 |      &gt;&gt;&gt; df
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      5     parrot
 |      6      shark
 |      7      whale
 |      8      zebra
 |      
 |      Viewing the first 5 lines
 |      
 |      &gt;&gt;&gt; df.head()
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      
 |      Viewing the first `n` lines (three in this case)
 |      
 |      &gt;&gt;&gt; df.head(3)
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      
 |      For negative values of `n`
 |      
 |      &gt;&gt;&gt; df.head(-3)
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      5     parrot
 |  
 |  infer_objects(self: &#39;NDFrameT&#39;, copy: &#39;bool_t | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Attempt to infer better dtypes for object columns.
 |      
 |      Attempts soft conversion of object-dtyped
 |      columns, leaving non-object and unconvertible
 |      columns unchanged. The inference rules are the
 |      same as during normal Series/DataFrame construction.
 |      
 |      Parameters
 |      ----------
 |      copy : bool, default True
 |          Whether to make a copy for non-object or non-inferrable columns
 |          or Series.
 |      
 |      Returns
 |      -------
 |      same type as input object
 |      
 |      See Also
 |      --------
 |      to_datetime : Convert argument to datetime.
 |      to_timedelta : Convert argument to timedelta.
 |      to_numeric : Convert argument to numeric type.
 |      convert_dtypes : Convert argument to best possible dtype.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [&quot;a&quot;, 1, 2, 3]})
 |      &gt;&gt;&gt; df = df.iloc[1:]
 |      &gt;&gt;&gt; df
 |         A
 |      1  1
 |      2  2
 |      3  3
 |      
 |      &gt;&gt;&gt; df.dtypes
 |      A    object
 |      dtype: object
 |      
 |      &gt;&gt;&gt; df.infer_objects().dtypes
 |      A    int64
 |      dtype: object
 |  
 |  last(self: &#39;NDFrameT&#39;, offset) -&gt; &#39;NDFrameT&#39;
 |      Select final periods of time series data based on a date offset.
 |      
 |      For a DataFrame with a sorted DatetimeIndex, this function
 |      selects the last few rows based on a date offset.
 |      
 |      Parameters
 |      ----------
 |      offset : str, DateOffset, dateutil.relativedelta
 |          The offset length of the data that will be selected. For instance,
 |          &#39;3D&#39; will display all the rows having their index within the last 3 days.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          A subset of the caller.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      first : Select initial periods of time series based on a date offset.
 |      at_time : Select values at a particular time of the day.
 |      between_time : Select values between particular times of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;2D&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                  A
 |      2018-04-09  1
 |      2018-04-11  2
 |      2018-04-13  3
 |      2018-04-15  4
 |      
 |      Get the rows for the last 3 days:
 |      
 |      &gt;&gt;&gt; ts.last(&#39;3D&#39;)
 |                  A
 |      2018-04-13  3
 |      2018-04-15  4
 |      
 |      Notice the data for 3 last calendar days were returned, not the last
 |      3 observed days in the dataset, and therefore data for 2018-04-11 was
 |      not returned.
 |  
 |  last_valid_index(self) -&gt; &#39;Hashable | None&#39;
 |      Return index for last non-NA value or None, if no non-NA value is found.
 |      
 |      Returns
 |      -------
 |      type of index
 |      
 |      Notes
 |      -----
 |      If all elements are non-NA/null, returns None.
 |      Also returns None for empty Series/DataFrame.
 |  
 |  pad(self: &#39;NDFrameT&#39;, *, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool_t&#39; = False, limit: &#39;None | int&#39; = None, downcast: &#39;dict | None&#39; = None) -&gt; &#39;NDFrameT | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;ffill&#39;``.
 |      
 |      .. deprecated:: 2.0
 |      
 |          Series/DataFrame.pad is deprecated. Use Series/DataFrame.ffill instead.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  pct_change(self: &#39;NDFrameT&#39;, periods: &#39;int&#39; = 1, fill_method: &quot;Literal[&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;] | None&quot; = &#39;pad&#39;, limit=None, freq=None, **kwargs) -&gt; &#39;NDFrameT&#39;
 |      Percentage change between the current and a prior element.
 |      
 |      Computes the percentage change from the immediately previous row by
 |      default. This is useful in comparing the percentage of change in a time
 |      series of elements.
 |      
 |      Parameters
 |      ----------
 |      periods : int, default 1
 |          Periods to shift for forming percent change.
 |      fill_method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default &#39;pad&#39;
 |          How to handle NAs **before** computing percent changes.
 |      limit : int, default None
 |          The number of consecutive NAs to fill before stopping.
 |      freq : DateOffset, timedelta, or str, optional
 |          Increment to use from time series API (e.g. &#39;M&#39; or BDay()).
 |      **kwargs
 |          Additional keyword arguments are passed into
 |          `DataFrame.shift` or `Series.shift`.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          The same type as the calling object.
 |      
 |      See Also
 |      --------
 |      Series.diff : Compute the difference of two elements in a Series.
 |      DataFrame.diff : Compute the difference of two elements in a DataFrame.
 |      Series.shift : Shift the index by some number of periods.
 |      DataFrame.shift : Shift the index by some number of periods.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([90, 91, 85])
 |      &gt;&gt;&gt; s
 |      0    90
 |      1    91
 |      2    85
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.pct_change()
 |      0         NaN
 |      1    0.011111
 |      2   -0.065934
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.pct_change(periods=2)
 |      0         NaN
 |      1         NaN
 |      2   -0.055556
 |      dtype: float64
 |      
 |      See the percentage change in a Series where filling NAs with last
 |      valid observation forward to next valid.
 |      
 |      &gt;&gt;&gt; s = pd.Series([90, 91, None, 85])
 |      &gt;&gt;&gt; s
 |      0    90.0
 |      1    91.0
 |      2     NaN
 |      3    85.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.pct_change(fill_method=&#39;ffill&#39;)
 |      0         NaN
 |      1    0.011111
 |      2    0.000000
 |      3   -0.065934
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      Percentage change in French franc, Deutsche Mark, and Italian lira from
 |      1980-01-01 to 1980-03-01.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;FR&#39;: [4.0405, 4.0963, 4.3149],
 |      ...     &#39;GR&#39;: [1.7246, 1.7482, 1.8519],
 |      ...     &#39;IT&#39;: [804.74, 810.01, 860.13]},
 |      ...     index=[&#39;1980-01-01&#39;, &#39;1980-02-01&#39;, &#39;1980-03-01&#39;])
 |      &gt;&gt;&gt; df
 |                      FR      GR      IT
 |      1980-01-01  4.0405  1.7246  804.74
 |      1980-02-01  4.0963  1.7482  810.01
 |      1980-03-01  4.3149  1.8519  860.13
 |      
 |      &gt;&gt;&gt; df.pct_change()
 |                        FR        GR        IT
 |      1980-01-01       NaN       NaN       NaN
 |      1980-02-01  0.013810  0.013684  0.006549
 |      1980-03-01  0.053365  0.059318  0.061876
 |      
 |      Percentage of change in GOOG and APPL stock volume. Shows computing
 |      the percentage change between columns.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;2016&#39;: [1769950, 30586265],
 |      ...     &#39;2015&#39;: [1500923, 40912316],
 |      ...     &#39;2014&#39;: [1371819, 41403351]},
 |      ...     index=[&#39;GOOG&#39;, &#39;APPL&#39;])
 |      &gt;&gt;&gt; df
 |                2016      2015      2014
 |      GOOG   1769950   1500923   1371819
 |      APPL  30586265  40912316  41403351
 |      
 |      &gt;&gt;&gt; df.pct_change(axis=&#39;columns&#39;, periods=-1)
 |                2016      2015  2014
 |      GOOG  0.179241  0.094112   NaN
 |      APPL -0.252395 -0.011860   NaN
 |  
 |  pipe(self, func: &#39;Callable[..., T] | tuple[Callable[..., T], str]&#39;, *args, **kwargs) -&gt; &#39;T&#39;
 |      Apply chainable functions that expect Series or DataFrames.
 |      
 |      Parameters
 |      ----------
 |      func : function
 |          Function to apply to the Series/DataFrame.
 |          ``args``, and ``kwargs`` are passed into ``func``.
 |          Alternatively a ``(callable, data_keyword)`` tuple where
 |          ``data_keyword`` is a string indicating the keyword of
 |          ``callable`` that expects the Series/DataFrame.
 |      args : iterable, optional
 |          Positional arguments passed into ``func``.
 |      kwargs : mapping, optional
 |          A dictionary of keyword arguments passed into ``func``.
 |      
 |      Returns
 |      -------
 |      the return type of ``func``.
 |      
 |      See Also
 |      --------
 |      DataFrame.apply : Apply a function along input axis of DataFrame.
 |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.
 |      Series.map : Apply a mapping correspondence on a
 |          :class:`~pandas.Series`.
 |      
 |      Notes
 |      -----
 |      Use ``.pipe`` when chaining together functions that expect
 |      Series, DataFrames or GroupBy objects. Instead of writing
 |      
 |      &gt;&gt;&gt; func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP
 |      
 |      You can write
 |      
 |      &gt;&gt;&gt; (df.pipe(h)
 |      ...    .pipe(g, arg1=a)
 |      ...    .pipe(func, arg2=b, arg3=c)
 |      ... )  # doctest: +SKIP
 |      
 |      If you have a function that takes the data as (say) the second
 |      argument, pass a tuple indicating which keyword expects the
 |      data. For example, suppose ``func`` takes its data as ``arg2``:
 |      
 |      &gt;&gt;&gt; (df.pipe(h)
 |      ...    .pipe(g, arg1=a)
 |      ...    .pipe((func, &#39;arg2&#39;), arg1=a, arg3=c)
 |      ...  )  # doctest: +SKIP
 |  
 |  rank(self: &#39;NDFrameT&#39;, axis: &#39;Axis&#39; = 0, method: &#39;str&#39; = &#39;average&#39;, numeric_only: &#39;bool_t&#39; = False, na_option: &#39;str&#39; = &#39;keep&#39;, ascending: &#39;bool_t&#39; = True, pct: &#39;bool_t&#39; = False) -&gt; &#39;NDFrameT&#39;
 |      Compute numerical data ranks (1 through n) along axis.
 |      
 |      By default, equal values are assigned a rank that is the average of the
 |      ranks of those values.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Index to direct ranking.
 |          For `Series` this parameter is unused and defaults to 0.
 |      method : {&#39;average&#39;, &#39;min&#39;, &#39;max&#39;, &#39;first&#39;, &#39;dense&#39;}, default &#39;average&#39;
 |          How to rank the group of records that have the same value (i.e. ties):
 |      
 |          * average: average rank of the group
 |          * min: lowest rank in the group
 |          * max: highest rank in the group
 |          * first: ranks assigned in order they appear in the array
 |          * dense: like &#39;min&#39;, but rank always increases by 1 between groups.
 |      
 |      numeric_only : bool, default False
 |          For DataFrame objects, rank only numeric columns if set to True.
 |      
 |          .. versionchanged:: 2.0.0
 |              The default value of ``numeric_only`` is now ``False``.
 |      
 |      na_option : {&#39;keep&#39;, &#39;top&#39;, &#39;bottom&#39;}, default &#39;keep&#39;
 |          How to rank NaN values:
 |      
 |          * keep: assign NaN rank to NaN values
 |          * top: assign lowest rank to NaN values
 |          * bottom: assign highest rank to NaN values
 |      
 |      ascending : bool, default True
 |          Whether or not the elements should be ranked in ascending order.
 |      pct : bool, default False
 |          Whether or not to display the returned rankings in percentile
 |          form.
 |      
 |      Returns
 |      -------
 |      same type as caller
 |          Return a Series or DataFrame with data ranks as values.
 |      
 |      See Also
 |      --------
 |      core.groupby.DataFrameGroupBy.rank : Rank of values within each group.
 |      core.groupby.SeriesGroupBy.rank : Rank of values within each group.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(data={&#39;Animal&#39;: [&#39;cat&#39;, &#39;penguin&#39;, &#39;dog&#39;,
 |      ...                                    &#39;spider&#39;, &#39;snake&#39;],
 |      ...                         &#39;Number_legs&#39;: [4, 2, 4, 8, np.nan]})
 |      &gt;&gt;&gt; df
 |          Animal  Number_legs
 |      0      cat          4.0
 |      1  penguin          2.0
 |      2      dog          4.0
 |      3   spider          8.0
 |      4    snake          NaN
 |      
 |      Ties are assigned the mean of the ranks (by default) for the group.
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(5), index=list(&quot;abcde&quot;))
 |      &gt;&gt;&gt; s[&quot;d&quot;] = s[&quot;b&quot;]
 |      &gt;&gt;&gt; s.rank()
 |      a    1.0
 |      b    2.5
 |      c    4.0
 |      d    2.5
 |      e    5.0
 |      dtype: float64
 |      
 |      The following example shows how the method behaves with the above
 |      parameters:
 |      
 |      * default_rank: this is the default behaviour obtained without using
 |        any parameter.
 |      * max_rank: setting ``method = &#39;max&#39;`` the records that have the
 |        same values are ranked using the highest rank (e.g.: since &#39;cat&#39;
 |        and &#39;dog&#39; are both in the 2nd and 3rd position, rank 3 is assigned.)
 |      * NA_bottom: choosing ``na_option = &#39;bottom&#39;``, if there are records
 |        with NaN values they are placed at the bottom of the ranking.
 |      * pct_rank: when setting ``pct = True``, the ranking is expressed as
 |        percentile rank.
 |      
 |      &gt;&gt;&gt; df[&#39;default_rank&#39;] = df[&#39;Number_legs&#39;].rank()
 |      &gt;&gt;&gt; df[&#39;max_rank&#39;] = df[&#39;Number_legs&#39;].rank(method=&#39;max&#39;)
 |      &gt;&gt;&gt; df[&#39;NA_bottom&#39;] = df[&#39;Number_legs&#39;].rank(na_option=&#39;bottom&#39;)
 |      &gt;&gt;&gt; df[&#39;pct_rank&#39;] = df[&#39;Number_legs&#39;].rank(pct=True)
 |      &gt;&gt;&gt; df
 |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank
 |      0      cat          4.0           2.5       3.0        2.5     0.625
 |      1  penguin          2.0           1.0       1.0        1.0     0.250
 |      2      dog          4.0           2.5       3.0        2.5     0.625
 |      3   spider          8.0           4.0       4.0        4.0     1.000
 |      4    snake          NaN           NaN       NaN        5.0       NaN
 |  
 |  reindex_like(self: &#39;NDFrameT&#39;, other, method: &quot;Literal[&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, &#39;nearest&#39;] | None&quot; = None, copy: &#39;bool_t | None&#39; = None, limit=None, tolerance=None) -&gt; &#39;NDFrameT&#39;
 |      Return an object with matching indices as other object.
 |      
 |      Conform the object to the same index on all axes. Optional
 |      filling logic, placing NaN in locations having no value
 |      in the previous index. A new object is produced unless the
 |      new index is equivalent to the current one and copy=False.
 |      
 |      Parameters
 |      ----------
 |      other : Object of the same data type
 |          Its row and column indices are used to define the new indices
 |          of this object.
 |      method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}
 |          Method to use for filling holes in reindexed DataFrame.
 |          Please note: this is only applicable to DataFrames/Series with a
 |          monotonically increasing/decreasing index.
 |      
 |          * None (default): don&#39;t fill gaps
 |          * pad / ffill: propagate last valid observation forward to next
 |            valid
 |          * backfill / bfill: use next valid observation to fill gap
 |          * nearest: use nearest valid observations to fill gap.
 |      
 |      copy : bool, default True
 |          Return a new object, even if the passed indexes are the same.
 |      limit : int, default None
 |          Maximum number of consecutive labels to fill for inexact matches.
 |      tolerance : optional
 |          Maximum distance between original and new labels for inexact
 |          matches. The values of the index at the matching locations must
 |          satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
 |      
 |          Tolerance may be a scalar value, which applies the same tolerance
 |          to all values, or list-like, which applies variable tolerance per
 |          element. List-like includes list, tuple, array, Series, and must be
 |          the same size as the index and its dtype must exactly match the
 |          index&#39;s type.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Same type as caller, but with changed indices on each axis.
 |      
 |      See Also
 |      --------
 |      DataFrame.set_index : Set row labels.
 |      DataFrame.reset_index : Remove row labels or move them to new columns.
 |      DataFrame.reindex : Change to new indices or expand indices.
 |      
 |      Notes
 |      -----
 |      Same as calling
 |      ``.reindex(index=other.index, columns=other.columns,...)``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df1 = pd.DataFrame([[24.3, 75.7, &#39;high&#39;],
 |      ...                     [31, 87.8, &#39;high&#39;],
 |      ...                     [22, 71.6, &#39;medium&#39;],
 |      ...                     [35, 95, &#39;medium&#39;]],
 |      ...                    columns=[&#39;temp_celsius&#39;, &#39;temp_fahrenheit&#39;,
 |      ...                             &#39;windspeed&#39;],
 |      ...                    index=pd.date_range(start=&#39;2014-02-12&#39;,
 |      ...                                        end=&#39;2014-02-15&#39;, freq=&#39;D&#39;))
 |      
 |      &gt;&gt;&gt; df1
 |                  temp_celsius  temp_fahrenheit windspeed
 |      2014-02-12          24.3             75.7      high
 |      2014-02-13          31.0             87.8      high
 |      2014-02-14          22.0             71.6    medium
 |      2014-02-15          35.0             95.0    medium
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame([[28, &#39;low&#39;],
 |      ...                     [30, &#39;low&#39;],
 |      ...                     [35.1, &#39;medium&#39;]],
 |      ...                    columns=[&#39;temp_celsius&#39;, &#39;windspeed&#39;],
 |      ...                    index=pd.DatetimeIndex([&#39;2014-02-12&#39;, &#39;2014-02-13&#39;,
 |      ...                                            &#39;2014-02-15&#39;]))
 |      
 |      &gt;&gt;&gt; df2
 |                  temp_celsius windspeed
 |      2014-02-12          28.0       low
 |      2014-02-13          30.0       low
 |      2014-02-15          35.1    medium
 |      
 |      &gt;&gt;&gt; df2.reindex_like(df1)
 |                  temp_celsius  temp_fahrenheit windspeed
 |      2014-02-12          28.0              NaN       low
 |      2014-02-13          30.0              NaN       low
 |      2014-02-14           NaN              NaN       NaN
 |      2014-02-15          35.1              NaN    medium
 |  
 |  rolling(self, window: &#39;int | dt.timedelta | str | BaseOffset | BaseIndexer&#39;, min_periods: &#39;int | None&#39; = None, center: &#39;bool_t&#39; = False, win_type: &#39;str | None&#39; = None, on: &#39;str | None&#39; = None, axis: &#39;Axis&#39; = 0, closed: &#39;str | None&#39; = None, step: &#39;int | None&#39; = None, method: &#39;str&#39; = &#39;single&#39;) -&gt; &#39;Window | Rolling&#39;
 |      Provide rolling window calculations.
 |      
 |      Parameters
 |      ----------
 |      window : int, timedelta, str, offset, or BaseIndexer subclass
 |          Size of the moving window.
 |      
 |          If an integer, the fixed number of observations used for
 |          each window.
 |      
 |          If a timedelta, str, or offset, the time period of each window. Each
 |          window will be a variable sized based on the observations included in
 |          the time-period. This is only valid for datetimelike indexes.
 |          To learn more about the offsets &amp; frequency strings, please see `this link
 |          &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases&gt;`__.
 |      
 |          If a BaseIndexer subclass, the window boundaries
 |          based on the defined ``get_window_bounds`` method. Additional rolling
 |          keyword arguments, namely ``min_periods``, ``center``, ``closed`` and
 |          ``step`` will be passed to ``get_window_bounds``.
 |      
 |      min_periods : int, default None
 |          Minimum number of observations in window required to have a value;
 |          otherwise, result is ``np.nan``.
 |      
 |          For a window that is specified by an offset, ``min_periods`` will default to 1.
 |      
 |          For a window that is specified by an integer, ``min_periods`` will default
 |          to the size of the window.
 |      
 |      center : bool, default False
 |          If False, set the window labels as the right edge of the window index.
 |      
 |          If True, set the window labels as the center of the window index.
 |      
 |      win_type : str, default None
 |          If ``None``, all points are evenly weighted.
 |      
 |          If a string, it must be a valid `scipy.signal window function
 |          &lt;https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows&gt;`__.
 |      
 |          Certain Scipy window types require additional parameters to be passed
 |          in the aggregation function. The additional parameters must match
 |          the keywords specified in the Scipy window type method signature.
 |      
 |      on : str, optional
 |          For a DataFrame, a column label or Index level on which
 |          to calculate the rolling window, rather than the DataFrame&#39;s index.
 |      
 |          Provided integer column is ignored and excluded from result since
 |          an integer index is not used to calculate the rolling window.
 |      
 |      axis : int or str, default 0
 |          If ``0`` or ``&#39;index&#39;``, roll across the rows.
 |      
 |          If ``1`` or ``&#39;columns&#39;``, roll across the columns.
 |      
 |          For `Series` this parameter is unused and defaults to 0.
 |      
 |      closed : str, default None
 |          If ``&#39;right&#39;``, the first point in the window is excluded from calculations.
 |      
 |          If ``&#39;left&#39;``, the last point in the window is excluded from calculations.
 |      
 |          If ``&#39;both&#39;``, the no points in the window are excluded from calculations.
 |      
 |          If ``&#39;neither&#39;``, the first and last points in the window are excluded
 |          from calculations.
 |      
 |          Default ``None`` (``&#39;right&#39;``).
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |              The closed parameter with fixed windows is now supported.
 |      
 |      step : int, default None
 |      
 |          .. versionadded:: 1.5.0
 |      
 |          Evaluate the window at every ``step`` result, equivalent to slicing as
 |          ``[::step]``. ``window`` must be an integer. Using a step argument other
 |          than None or 1 will produce a result with a different shape than the input.
 |      
 |      method : str {&#39;single&#39;, &#39;table&#39;}, default &#39;single&#39;
 |      
 |          .. versionadded:: 1.3.0
 |      
 |          Execute the rolling operation per single column or row (``&#39;single&#39;``)
 |          or over the entire object (``&#39;table&#39;``).
 |      
 |          This argument is only implemented when specifying ``engine=&#39;numba&#39;``
 |          in the method call.
 |      
 |      Returns
 |      -------
 |      ``Window`` subclass if a ``win_type`` is passed
 |      
 |      ``Rolling`` subclass if ``win_type`` is not passed
 |      
 |      See Also
 |      --------
 |      expanding : Provides expanding transformations.
 |      ewm : Provides exponential weighted functions.
 |      
 |      Notes
 |      -----
 |      See :ref:`Windowing Operations &lt;window.generic&gt;` for further usage details
 |      and examples.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4]})
 |      &gt;&gt;&gt; df
 |           B
 |      0  0.0
 |      1  1.0
 |      2  2.0
 |      3  NaN
 |      4  4.0
 |      
 |      **window**
 |      
 |      Rolling sum with a window length of 2 observations.
 |      
 |      &gt;&gt;&gt; df.rolling(2).sum()
 |           B
 |      0  NaN
 |      1  1.0
 |      2  3.0
 |      3  NaN
 |      4  NaN
 |      
 |      Rolling sum with a window span of 2 seconds.
 |      
 |      &gt;&gt;&gt; df_time = pd.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4]},
 |      ...                        index = [pd.Timestamp(&#39;20130101 09:00:00&#39;),
 |      ...                                 pd.Timestamp(&#39;20130101 09:00:02&#39;),
 |      ...                                 pd.Timestamp(&#39;20130101 09:00:03&#39;),
 |      ...                                 pd.Timestamp(&#39;20130101 09:00:05&#39;),
 |      ...                                 pd.Timestamp(&#39;20130101 09:00:06&#39;)])
 |      
 |      &gt;&gt;&gt; df_time
 |                             B
 |      2013-01-01 09:00:00  0.0
 |      2013-01-01 09:00:02  1.0
 |      2013-01-01 09:00:03  2.0
 |      2013-01-01 09:00:05  NaN
 |      2013-01-01 09:00:06  4.0
 |      
 |      &gt;&gt;&gt; df_time.rolling(&#39;2s&#39;).sum()
 |                             B
 |      2013-01-01 09:00:00  0.0
 |      2013-01-01 09:00:02  1.0
 |      2013-01-01 09:00:03  3.0
 |      2013-01-01 09:00:05  NaN
 |      2013-01-01 09:00:06  4.0
 |      
 |      Rolling sum with forward looking windows with 2 observations.
 |      
 |      &gt;&gt;&gt; indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
 |      &gt;&gt;&gt; df.rolling(window=indexer, min_periods=1).sum()
 |           B
 |      0  1.0
 |      1  3.0
 |      2  2.0
 |      3  4.0
 |      4  4.0
 |      
 |      **min_periods**
 |      
 |      Rolling sum with a window length of 2 observations, but only needs a minimum of 1
 |      observation to calculate a value.
 |      
 |      &gt;&gt;&gt; df.rolling(2, min_periods=1).sum()
 |           B
 |      0  0.0
 |      1  1.0
 |      2  3.0
 |      3  2.0
 |      4  4.0
 |      
 |      **center**
 |      
 |      Rolling sum with the result assigned to the center of the window index.
 |      
 |      &gt;&gt;&gt; df.rolling(3, min_periods=1, center=True).sum()
 |           B
 |      0  1.0
 |      1  3.0
 |      2  3.0
 |      3  6.0
 |      4  4.0
 |      
 |      &gt;&gt;&gt; df.rolling(3, min_periods=1, center=False).sum()
 |           B
 |      0  0.0
 |      1  1.0
 |      2  3.0
 |      3  3.0
 |      4  6.0
 |      
 |      **step**
 |      
 |      Rolling sum with a window length of 2 observations, minimum of 1 observation to
 |      calculate a value, and a step of 2.
 |      
 |      &gt;&gt;&gt; df.rolling(2, min_periods=1, step=2).sum()
 |           B
 |      0  0.0
 |      2  3.0
 |      4  4.0
 |      
 |      **win_type**
 |      
 |      Rolling sum with a window length of 2, using the Scipy ``&#39;gaussian&#39;``
 |      window type. ``std`` is required in the aggregation function.
 |      
 |      &gt;&gt;&gt; df.rolling(2, win_type=&#39;gaussian&#39;).sum(std=3)
 |                B
 |      0       NaN
 |      1  0.986207
 |      2  2.958621
 |      3       NaN
 |      4       NaN
 |      
 |      **on**
 |      
 |      Rolling sum with a window length of 2 days.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;A&#39;: [pd.to_datetime(&#39;2020-01-01&#39;),
 |      ...           pd.to_datetime(&#39;2020-01-01&#39;),
 |      ...           pd.to_datetime(&#39;2020-01-02&#39;),],
 |      ...     &#39;B&#39;: [1, 2, 3], },
 |      ...     index=pd.date_range(&#39;2020&#39;, periods=3))
 |      
 |      &gt;&gt;&gt; df
 |                          A  B
 |      2020-01-01 2020-01-01  1
 |      2020-01-02 2020-01-01  2
 |      2020-01-03 2020-01-02  3
 |      
 |      &gt;&gt;&gt; df.rolling(&#39;2D&#39;, on=&#39;A&#39;).sum()
 |                          A    B
 |      2020-01-01 2020-01-01  1.0
 |      2020-01-02 2020-01-01  3.0
 |      2020-01-03 2020-01-02  6.0
 |  
 |  sample(self: &#39;NDFrameT&#39;, n: &#39;int | None&#39; = None, frac: &#39;float | None&#39; = None, replace: &#39;bool_t&#39; = False, weights=None, random_state: &#39;RandomState | None&#39; = None, axis: &#39;Axis | None&#39; = None, ignore_index: &#39;bool_t&#39; = False) -&gt; &#39;NDFrameT&#39;
 |      Return a random sample of items from an axis of object.
 |      
 |      You can use `random_state` for reproducibility.
 |      
 |      Parameters
 |      ----------
 |      n : int, optional
 |          Number of items from axis to return. Cannot be used with `frac`.
 |          Default = 1 if `frac` = None.
 |      frac : float, optional
 |          Fraction of axis items to return. Cannot be used with `n`.
 |      replace : bool, default False
 |          Allow or disallow sampling of the same row more than once.
 |      weights : str or ndarray-like, optional
 |          Default &#39;None&#39; results in equal probability weighting.
 |          If passed a Series, will align with target object on index. Index
 |          values in weights not found in sampled object will be ignored and
 |          index values in sampled object not in weights will be assigned
 |          weights of zero.
 |          If called on a DataFrame, will accept the name of a column
 |          when axis = 0.
 |          Unless weights are a Series, weights must be same length as axis
 |          being sampled.
 |          If weights do not sum to 1, they will be normalized to sum to 1.
 |          Missing values in the weights column will be treated as zero.
 |          Infinite values not allowed.
 |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional
 |          If int, array-like, or BitGenerator, seed for random number generator.
 |          If np.random.RandomState or np.random.Generator, use as given.
 |      
 |          .. versionchanged:: 1.1.0
 |      
 |              array-like and BitGenerator object now passed to np.random.RandomState()
 |              as seed
 |      
 |          .. versionchanged:: 1.4.0
 |      
 |              np.random.Generator objects now accepted
 |      
 |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None
 |          Axis to sample. Accepts axis number or name. Default is stat axis
 |          for given data type. For `Series` this parameter is unused and defaults to `None`.
 |      ignore_index : bool, default False
 |          If True, the resulting index will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          A new object of same type as caller containing `n` items randomly
 |          sampled from the caller object.
 |      
 |      See Also
 |      --------
 |      DataFrameGroupBy.sample: Generates random samples from each group of a
 |          DataFrame object.
 |      SeriesGroupBy.sample: Generates random samples from each group of a
 |          Series object.
 |      numpy.random.choice: Generates a random sample from a given 1-D numpy
 |          array.
 |      
 |      Notes
 |      -----
 |      If `frac` &gt; 1, `replacement` should be set to `True`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;num_legs&#39;: [2, 4, 8, 0],
 |      ...                    &#39;num_wings&#39;: [2, 0, 0, 0],
 |      ...                    &#39;num_specimen_seen&#39;: [10, 2, 1, 8]},
 |      ...                   index=[&#39;falcon&#39;, &#39;dog&#39;, &#39;spider&#39;, &#39;fish&#39;])
 |      &gt;&gt;&gt; df
 |              num_legs  num_wings  num_specimen_seen
 |      falcon         2          2                 10
 |      dog            4          0                  2
 |      spider         8          0                  1
 |      fish           0          0                  8
 |      
 |      Extract 3 random elements from the ``Series`` ``df[&#39;num_legs&#39;]``:
 |      Note that we use `random_state` to ensure the reproducibility of
 |      the examples.
 |      
 |      &gt;&gt;&gt; df[&#39;num_legs&#39;].sample(n=3, random_state=1)
 |      fish      0
 |      spider    8
 |      falcon    2
 |      Name: num_legs, dtype: int64
 |      
 |      A random 50% sample of the ``DataFrame`` with replacement:
 |      
 |      &gt;&gt;&gt; df.sample(frac=0.5, replace=True, random_state=1)
 |            num_legs  num_wings  num_specimen_seen
 |      dog          4          0                  2
 |      fish         0          0                  8
 |      
 |      An upsample sample of the ``DataFrame`` with replacement:
 |      Note that `replace` parameter has to be `True` for `frac` parameter &gt; 1.
 |      
 |      &gt;&gt;&gt; df.sample(frac=2, replace=True, random_state=1)
 |              num_legs  num_wings  num_specimen_seen
 |      dog            4          0                  2
 |      fish           0          0                  8
 |      falcon         2          2                 10
 |      falcon         2          2                 10
 |      fish           0          0                  8
 |      dog            4          0                  2
 |      fish           0          0                  8
 |      dog            4          0                  2
 |      
 |      Using a DataFrame column as weights. Rows with larger value in the
 |      `num_specimen_seen` column are more likely to be sampled.
 |      
 |      &gt;&gt;&gt; df.sample(n=2, weights=&#39;num_specimen_seen&#39;, random_state=1)
 |              num_legs  num_wings  num_specimen_seen
 |      falcon         2          2                 10
 |      fish           0          0                  8
 |  
 |  set_flags(self: &#39;NDFrameT&#39;, *, copy: &#39;bool_t&#39; = False, allows_duplicate_labels: &#39;bool_t | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Return a new object with updated flags.
 |      
 |      Parameters
 |      ----------
 |      copy : bool, default False
 |          Specify if a copy of the object should be made.
 |      allows_duplicate_labels : bool, optional
 |          Whether the returned object allows duplicate labels.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          The same type as the caller.
 |      
 |      See Also
 |      --------
 |      DataFrame.attrs : Global metadata applying to this dataset.
 |      DataFrame.flags : Global flags applying to this object.
 |      
 |      Notes
 |      -----
 |      This method returns a new object that&#39;s a view on the same data
 |      as the input. Mutating the input or the output values will be reflected
 |      in the other.
 |      
 |      This method is intended to be used in method chains.
 |      
 |      &quot;Flags&quot; differ from &quot;metadata&quot;. Flags reflect properties of the
 |      pandas object (the Series or DataFrame). Metadata refer to properties
 |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2]})
 |      &gt;&gt;&gt; df.flags.allows_duplicate_labels
 |      True
 |      &gt;&gt;&gt; df2 = df.set_flags(allows_duplicate_labels=False)
 |      &gt;&gt;&gt; df2.flags.allows_duplicate_labels
 |      False
 |  
 |  squeeze(self, axis: &#39;Axis | None&#39; = None)
 |      Squeeze 1 dimensional axis objects into scalars.
 |      
 |      Series or DataFrames with a single element are squeezed to a scalar.
 |      DataFrames with a single column or a single row are squeezed to a
 |      Series. Otherwise the object is unchanged.
 |      
 |      This method is most useful when you don&#39;t know if your
 |      object is a Series or DataFrame, but you do know it has just a single
 |      column. In that case you can safely call `squeeze` to ensure you have a
 |      Series.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default None
 |          A specific axis to squeeze. By default, all length-1 axes are
 |          squeezed. For `Series` this parameter is unused and defaults to `None`.
 |      
 |      Returns
 |      -------
 |      DataFrame, Series, or scalar
 |          The projection after squeezing `axis` or all the axes.
 |      
 |      See Also
 |      --------
 |      Series.iloc : Integer-location based indexing for selecting scalars.
 |      DataFrame.iloc : Integer-location based indexing for selecting Series.
 |      Series.to_frame : Inverse of DataFrame.squeeze for a
 |          single-column DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; primes = pd.Series([2, 3, 5, 7])
 |      
 |      Slicing might produce a Series with a single value:
 |      
 |      &gt;&gt;&gt; even_primes = primes[primes % 2 == 0]
 |      &gt;&gt;&gt; even_primes
 |      0    2
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; even_primes.squeeze()
 |      2
 |      
 |      Squeezing objects with more than one value in every axis does nothing:
 |      
 |      &gt;&gt;&gt; odd_primes = primes[primes % 2 == 1]
 |      &gt;&gt;&gt; odd_primes
 |      1    3
 |      2    5
 |      3    7
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; odd_primes.squeeze()
 |      1    3
 |      2    5
 |      3    7
 |      dtype: int64
 |      
 |      Squeezing is even more effective when used with DataFrames.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], columns=[&#39;a&#39;, &#39;b&#39;])
 |      &gt;&gt;&gt; df
 |         a  b
 |      0  1  2
 |      1  3  4
 |      
 |      Slicing a single column will produce a DataFrame with the columns
 |      having only one value:
 |      
 |      &gt;&gt;&gt; df_a = df[[&#39;a&#39;]]
 |      &gt;&gt;&gt; df_a
 |         a
 |      0  1
 |      1  3
 |      
 |      So the columns can be squeezed down, resulting in a Series:
 |      
 |      &gt;&gt;&gt; df_a.squeeze(&#39;columns&#39;)
 |      0    1
 |      1    3
 |      Name: a, dtype: int64
 |      
 |      Slicing a single row from a single column will produce a single
 |      scalar DataFrame:
 |      
 |      &gt;&gt;&gt; df_0a = df.loc[df.index &lt; 1, [&#39;a&#39;]]
 |      &gt;&gt;&gt; df_0a
 |         a
 |      0  1
 |      
 |      Squeezing the rows produces a single scalar Series:
 |      
 |      &gt;&gt;&gt; df_0a.squeeze(&#39;rows&#39;)
 |      a    1
 |      Name: 0, dtype: int64
 |      
 |      Squeezing all axes will project directly into a scalar:
 |      
 |      &gt;&gt;&gt; df_0a.squeeze()
 |      1
 |  
 |  swapaxes(self: &#39;NDFrameT&#39;, axis1: &#39;Axis&#39;, axis2: &#39;Axis&#39;, copy: &#39;bool_t | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Interchange axes and swap values axes appropriately.
 |      
 |      Returns
 |      -------
 |      same as input
 |  
 |  tail(self: &#39;NDFrameT&#39;, n: &#39;int&#39; = 5) -&gt; &#39;NDFrameT&#39;
 |      Return the last `n` rows.
 |      
 |      This function returns last `n` rows from the object based on
 |      position. It is useful for quickly verifying data, for example,
 |      after sorting or appending rows.
 |      
 |      For negative values of `n`, this function returns all rows except
 |      the first `|n|` rows, equivalent to ``df[|n|:]``.
 |      
 |      If n is larger than the number of rows, this function returns all rows.
 |      
 |      Parameters
 |      ----------
 |      n : int, default 5
 |          Number of rows to select.
 |      
 |      Returns
 |      -------
 |      type of caller
 |          The last `n` rows of the caller object.
 |      
 |      See Also
 |      --------
 |      DataFrame.head : The first `n` rows of the caller object.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;animal&#39;: [&#39;alligator&#39;, &#39;bee&#39;, &#39;falcon&#39;, &#39;lion&#39;,
 |      ...                    &#39;monkey&#39;, &#39;parrot&#39;, &#39;shark&#39;, &#39;whale&#39;, &#39;zebra&#39;]})
 |      &gt;&gt;&gt; df
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      5     parrot
 |      6      shark
 |      7      whale
 |      8      zebra
 |      
 |      Viewing the last 5 lines
 |      
 |      &gt;&gt;&gt; df.tail()
 |         animal
 |      4  monkey
 |      5  parrot
 |      6   shark
 |      7   whale
 |      8   zebra
 |      
 |      Viewing the last `n` lines (three in this case)
 |      
 |      &gt;&gt;&gt; df.tail(3)
 |        animal
 |      6  shark
 |      7  whale
 |      8  zebra
 |      
 |      For negative values of `n`
 |      
 |      &gt;&gt;&gt; df.tail(-3)
 |         animal
 |      3    lion
 |      4  monkey
 |      5  parrot
 |      6   shark
 |      7   whale
 |      8   zebra
 |  
 |  to_clipboard(self, excel: &#39;bool_t&#39; = True, sep: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;None&#39;
 |      Copy object to the system clipboard.
 |      
 |      Write a text representation of object to the system clipboard.
 |      This can be pasted into Excel, for example.
 |      
 |      Parameters
 |      ----------
 |      excel : bool, default True
 |          Produce output in a csv format for easy pasting into excel.
 |      
 |          - True, use the provided separator for csv pasting.
 |          - False, write a string representation of the object to the clipboard.
 |      
 |      sep : str, default ``&#39;\t&#39;``
 |          Field delimiter.
 |      **kwargs
 |          These parameters will be passed to DataFrame.to_csv.
 |      
 |      See Also
 |      --------
 |      DataFrame.to_csv : Write a DataFrame to a comma-separated values
 |          (csv) file.
 |      read_clipboard : Read text from clipboard and pass to read_csv.
 |      
 |      Notes
 |      -----
 |      Requirements for your platform.
 |      
 |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)
 |        - Windows : none
 |        - macOS : none
 |      
 |      This method uses the processes developed for the package `pyperclip`. A
 |      solution to render any output string format is given in the examples.
 |      
 |      Examples
 |      --------
 |      Copy the contents of a DataFrame to the clipboard.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      
 |      &gt;&gt;&gt; df.to_clipboard(sep=&#39;,&#39;)  # doctest: +SKIP
 |      ... # Wrote the following to the system clipboard:
 |      ... # ,A,B,C
 |      ... # 0,1,2,3
 |      ... # 1,4,5,6
 |      
 |      We can omit the index by passing the keyword `index` and setting
 |      it to false.
 |      
 |      &gt;&gt;&gt; df.to_clipboard(sep=&#39;,&#39;, index=False)  # doctest: +SKIP
 |      ... # Wrote the following to the system clipboard:
 |      ... # A,B,C
 |      ... # 1,2,3
 |      ... # 4,5,6
 |      
 |      Using the original `pyperclip` package for any string output format.
 |      
 |      .. code-block:: python
 |      
 |         import pyperclip
 |         html = df.style.to_html()
 |         pyperclip.copy(html)
 |  
 |  to_csv(self, path_or_buf: &#39;FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None&#39; = None, sep: &#39;str&#39; = &#39;,&#39;, na_rep: &#39;str&#39; = &#39;&#39;, float_format: &#39;str | Callable | None&#39; = None, columns: &#39;Sequence[Hashable] | None&#39; = None, header: &#39;bool_t | list[str]&#39; = True, index: &#39;bool_t&#39; = True, index_label: &#39;IndexLabel | None&#39; = None, mode: &#39;str&#39; = &#39;w&#39;, encoding: &#39;str | None&#39; = None, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, quoting: &#39;int | None&#39; = None, quotechar: &#39;str&#39; = &#39;&quot;&#39;, lineterminator: &#39;str | None&#39; = None, chunksize: &#39;int | None&#39; = None, date_format: &#39;str | None&#39; = None, doublequote: &#39;bool_t&#39; = True, escapechar: &#39;str | None&#39; = None, decimal: &#39;str&#39; = &#39;.&#39;, errors: &#39;str&#39; = &#39;strict&#39;, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;str | None&#39;
 |      Write object to a comma-separated values (csv) file.
 |      
 |      Parameters
 |      ----------
 |      path_or_buf : str, path object, file-like object, or None, default None
 |          String, path object (implementing os.PathLike[str]), or file-like
 |          object implementing a write() function. If None, the result is
 |          returned as a string. If a non-binary file object is passed, it should
 |          be opened with `newline=&#39;&#39;`, disabling universal newlines. If a binary
 |          file object is passed, `mode` might need to contain a `&#39;b&#39;`.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |             Support for binary file objects was introduced.
 |      
 |      sep : str, default &#39;,&#39;
 |          String of length 1. Field delimiter for the output file.
 |      na_rep : str, default &#39;&#39;
 |          Missing data representation.
 |      float_format : str, Callable, default None
 |          Format string for floating point numbers. If a Callable is given, it takes
 |          precedence over other numeric formatting parameters, like decimal.
 |      columns : sequence, optional
 |          Columns to write.
 |      header : bool or list of str, default True
 |          Write out the column names. If a list of strings is given it is
 |          assumed to be aliases for the column names.
 |      index : bool, default True
 |          Write row names (index).
 |      index_label : str or sequence, or False, default None
 |          Column label for index column(s) if desired. If None is given, and
 |          `header` and `index` are True, then the index names are used. A
 |          sequence should be given if the object uses MultiIndex. If
 |          False do not print fields for index names. Use index_label=False
 |          for easier importing in R.
 |      mode : str, default &#39;w&#39;
 |          Python write mode. The available write modes are the same as
 |          :py:func:`open`.
 |      encoding : str, optional
 |          A string representing the encoding to use in the output file,
 |          defaults to &#39;utf-8&#39;. `encoding` is not supported if `path_or_buf`
 |          is a non-binary file object.
 |      compression : str or dict, default &#39;infer&#39;
 |          For on-the-fly compression of the output data. If &#39;infer&#39; and &#39;path_or_buf&#39; is
 |          path-like, then detect compression from the following extensions: &#39;.gz&#39;,
 |          &#39;.bz2&#39;, &#39;.zip&#39;, &#39;.xz&#39;, &#39;.zst&#39;, &#39;.tar&#39;, &#39;.tar.gz&#39;, &#39;.tar.xz&#39; or &#39;.tar.bz2&#39;
 |          (otherwise no compression).
 |          Set to ``None`` for no compression.
 |          Can also be a dict with key ``&#39;method&#39;`` set
 |          to one of {``&#39;zip&#39;``, ``&#39;gzip&#39;``, ``&#39;bz2&#39;``, ``&#39;zstd&#39;``, ``&#39;tar&#39;``} and other
 |          key-value pairs are forwarded to
 |          ``zipfile.ZipFile``, ``gzip.GzipFile``,
 |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or
 |          ``tarfile.TarFile``, respectively.
 |          As an example, the following could be passed for faster compression and to create
 |          a reproducible gzip archive:
 |          ``compression={&#39;method&#39;: &#39;gzip&#39;, &#39;compresslevel&#39;: 1, &#39;mtime&#39;: 1}``.
 |      
 |          .. versionadded:: 1.5.0
 |              Added support for `.tar` files.
 |      
 |          .. versionchanged:: 1.0.0
 |      
 |             May now be a dict with key &#39;method&#39; as compression mode
 |             and other entries as additional compression options if
 |             compression mode is &#39;zip&#39;.
 |      
 |          .. versionchanged:: 1.1.0
 |      
 |             Passing compression options as keys in dict is
 |             supported for compression modes &#39;gzip&#39;, &#39;bz2&#39;, &#39;zstd&#39;, and &#39;zip&#39;.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |              Compression is supported for binary file objects.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |              Previous versions forwarded dict entries for &#39;gzip&#39; to
 |              `gzip.open` instead of `gzip.GzipFile` which prevented
 |              setting `mtime`.
 |      
 |      quoting : optional constant from csv module
 |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`
 |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC
 |          will treat them as non-numeric.
 |      quotechar : str, default &#39;\&quot;&#39;
 |          String of length 1. Character used to quote fields.
 |      lineterminator : str, optional
 |          The newline character or character sequence to use in the output
 |          file. Defaults to `os.linesep`, which depends on the OS in which
 |          this method is called (&#39;\\n&#39; for linux, &#39;\\r\\n&#39; for Windows, i.e.).
 |      
 |          .. versionchanged:: 1.5.0
 |      
 |              Previously was line_terminator, changed for consistency with
 |              read_csv and the standard library &#39;csv&#39; module.
 |      
 |      chunksize : int or None
 |          Rows to write at a time.
 |      date_format : str, default None
 |          Format string for datetime objects.
 |      doublequote : bool, default True
 |          Control quoting of `quotechar` inside a field.
 |      escapechar : str, default None
 |          String of length 1. Character used to escape `sep` and `quotechar`
 |          when appropriate.
 |      decimal : str, default &#39;.&#39;
 |          Character recognized as decimal separator. E.g. use &#39;,&#39; for
 |          European data.
 |      errors : str, default &#39;strict&#39;
 |          Specifies how encoding and decoding errors are to be handled.
 |          See the errors argument for :func:`open` for a full list
 |          of options.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib.request.Request`` as header options. For other
 |          URLs (e.g. starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are
 |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more
 |          details, and for more examples on storage options refer `here
 |          &lt;https://pandas.pydata.org/docs/user_guide/io.html?
 |          highlight=storage_options#reading-writing-remote-files&gt;`_.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      Returns
 |      -------
 |      None or str
 |          If path_or_buf is None, returns the resulting csv format as a
 |          string. Otherwise returns None.
 |      
 |      See Also
 |      --------
 |      read_csv : Load a CSV file into a DataFrame.
 |      to_excel : Write DataFrame to an Excel file.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;name&#39;: [&#39;Raphael&#39;, &#39;Donatello&#39;],
 |      ...                    &#39;mask&#39;: [&#39;red&#39;, &#39;purple&#39;],
 |      ...                    &#39;weapon&#39;: [&#39;sai&#39;, &#39;bo staff&#39;]})
 |      &gt;&gt;&gt; df.to_csv(index=False)
 |      &#39;name,mask,weapon\nRaphael,red,sai\nDonatello,purple,bo staff\n&#39;
 |      
 |      Create &#39;out.zip&#39; containing &#39;out.csv&#39;
 |      
 |      &gt;&gt;&gt; compression_opts = dict(method=&#39;zip&#39;,
 |      ...                         archive_name=&#39;out.csv&#39;)  # doctest: +SKIP
 |      &gt;&gt;&gt; df.to_csv(&#39;out.zip&#39;, index=False,
 |      ...           compression=compression_opts)  # doctest: +SKIP
 |      
 |      To write a csv file to a new folder or nested folder you will first
 |      need to create it using either Pathlib or os:
 |      
 |      &gt;&gt;&gt; from pathlib import Path  # doctest: +SKIP
 |      &gt;&gt;&gt; filepath = Path(&#39;folder/subfolder/out.csv&#39;)  # doctest: +SKIP
 |      &gt;&gt;&gt; filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP
 |      &gt;&gt;&gt; df.to_csv(filepath)  # doctest: +SKIP
 |      
 |      &gt;&gt;&gt; import os  # doctest: +SKIP
 |      &gt;&gt;&gt; os.makedirs(&#39;folder/subfolder&#39;, exist_ok=True)  # doctest: +SKIP
 |      &gt;&gt;&gt; df.to_csv(&#39;folder/subfolder/out.csv&#39;)  # doctest: +SKIP
 |  
 |  to_excel(self, excel_writer, sheet_name: &#39;str&#39; = &#39;Sheet1&#39;, na_rep: &#39;str&#39; = &#39;&#39;, float_format: &#39;str | None&#39; = None, columns: &#39;Sequence[Hashable] | None&#39; = None, header: &#39;Sequence[Hashable] | bool_t&#39; = True, index: &#39;bool_t&#39; = True, index_label: &#39;IndexLabel&#39; = None, startrow: &#39;int&#39; = 0, startcol: &#39;int&#39; = 0, engine: &#39;str | None&#39; = None, merge_cells: &#39;bool_t&#39; = True, inf_rep: &#39;str&#39; = &#39;inf&#39;, freeze_panes: &#39;tuple[int, int] | None&#39; = None, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;None&#39;
 |      Write object to an Excel sheet.
 |      
 |      To write a single object to an Excel .xlsx file it is only necessary to
 |      specify a target file name. To write to multiple sheets it is necessary to
 |      create an `ExcelWriter` object with a target file name, and specify a sheet
 |      in the file to write to.
 |      
 |      Multiple sheets may be written to by specifying unique `sheet_name`.
 |      With all data written to the file it is necessary to save the changes.
 |      Note that creating an `ExcelWriter` object with a file name that already
 |      exists will result in the contents of the existing file being erased.
 |      
 |      Parameters
 |      ----------
 |      excel_writer : path-like, file-like, or ExcelWriter object
 |          File path or existing ExcelWriter.
 |      sheet_name : str, default &#39;Sheet1&#39;
 |          Name of sheet which will contain DataFrame.
 |      na_rep : str, default &#39;&#39;
 |          Missing data representation.
 |      float_format : str, optional
 |          Format string for floating point numbers. For example
 |          ``float_format=&quot;%.2f&quot;`` will format 0.1234 to 0.12.
 |      columns : sequence or list of str, optional
 |          Columns to write.
 |      header : bool or list of str, default True
 |          Write out the column names. If a list of string is given it is
 |          assumed to be aliases for the column names.
 |      index : bool, default True
 |          Write row names (index).
 |      index_label : str or sequence, optional
 |          Column label for index column(s) if desired. If not specified, and
 |          `header` and `index` are True, then the index names are used. A
 |          sequence should be given if the DataFrame uses MultiIndex.
 |      startrow : int, default 0
 |          Upper left cell row to dump data frame.
 |      startcol : int, default 0
 |          Upper left cell column to dump data frame.
 |      engine : str, optional
 |          Write engine to use, &#39;openpyxl&#39; or &#39;xlsxwriter&#39;. You can also set this
 |          via the options ``io.excel.xlsx.writer`` or
 |          ``io.excel.xlsm.writer``.
 |      
 |      merge_cells : bool, default True
 |          Write MultiIndex and Hierarchical Rows as merged cells.
 |      inf_rep : str, default &#39;inf&#39;
 |          Representation for infinity (there is no native representation for
 |          infinity in Excel).
 |      freeze_panes : tuple of int (length 2), optional
 |          Specifies the one-based bottommost row and rightmost column that
 |          is to be frozen.
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib.request.Request`` as header options. For other
 |          URLs (e.g. starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are
 |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more
 |          details, and for more examples on storage options refer `here
 |          &lt;https://pandas.pydata.org/docs/user_guide/io.html?
 |          highlight=storage_options#reading-writing-remote-files&gt;`_.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      See Also
 |      --------
 |      to_csv : Write DataFrame to a comma-separated values (csv) file.
 |      ExcelWriter : Class for writing DataFrame objects into excel sheets.
 |      read_excel : Read an Excel file into a pandas DataFrame.
 |      read_csv : Read a comma-separated values (csv) file into DataFrame.
 |      io.formats.style.Styler.to_excel : Add styles to Excel sheet.
 |      
 |      Notes
 |      -----
 |      For compatibility with :meth:`~DataFrame.to_csv`,
 |      to_excel serializes lists and dicts to strings before writing.
 |      
 |      Once a workbook has been saved it is not possible to write further
 |      data without rewriting the whole workbook.
 |      
 |      Examples
 |      --------
 |      
 |      Create, write to and save a workbook:
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame([[&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;]],
 |      ...                    index=[&#39;row 1&#39;, &#39;row 2&#39;],
 |      ...                    columns=[&#39;col 1&#39;, &#39;col 2&#39;])
 |      &gt;&gt;&gt; df1.to_excel(&quot;output.xlsx&quot;)  # doctest: +SKIP
 |      
 |      To specify the sheet name:
 |      
 |      &gt;&gt;&gt; df1.to_excel(&quot;output.xlsx&quot;,
 |      ...              sheet_name=&#39;Sheet_name_1&#39;)  # doctest: +SKIP
 |      
 |      If you wish to write to more than one sheet in the workbook, it is
 |      necessary to specify an ExcelWriter object:
 |      
 |      &gt;&gt;&gt; df2 = df1.copy()
 |      &gt;&gt;&gt; with pd.ExcelWriter(&#39;output.xlsx&#39;) as writer:  # doctest: +SKIP
 |      ...     df1.to_excel(writer, sheet_name=&#39;Sheet_name_1&#39;)
 |      ...     df2.to_excel(writer, sheet_name=&#39;Sheet_name_2&#39;)
 |      
 |      ExcelWriter can also be used to append to an existing Excel file:
 |      
 |      &gt;&gt;&gt; with pd.ExcelWriter(&#39;output.xlsx&#39;,
 |      ...                     mode=&#39;a&#39;) as writer:  # doctest: +SKIP
 |      ...     df.to_excel(writer, sheet_name=&#39;Sheet_name_3&#39;)
 |      
 |      To set the library that is used to write the Excel file,
 |      you can pass the `engine` keyword (the default engine is
 |      automatically chosen depending on the file extension):
 |      
 |      &gt;&gt;&gt; df1.to_excel(&#39;output1.xlsx&#39;, engine=&#39;xlsxwriter&#39;)  # doctest: +SKIP
 |  
 |  to_hdf(self, path_or_buf: &#39;FilePath | HDFStore&#39;, key: &#39;str&#39;, mode: &#39;str&#39; = &#39;a&#39;, complevel: &#39;int | None&#39; = None, complib: &#39;str | None&#39; = None, append: &#39;bool_t&#39; = False, format: &#39;str | None&#39; = None, index: &#39;bool_t&#39; = True, min_itemsize: &#39;int | dict[str, int] | None&#39; = None, nan_rep=None, dropna: &#39;bool_t | None&#39; = None, data_columns: &#39;Literal[True] | list[str] | None&#39; = None, errors: &#39;str&#39; = &#39;strict&#39;, encoding: &#39;str&#39; = &#39;UTF-8&#39;) -&gt; &#39;None&#39;
 |      Write the contained data to an HDF5 file using HDFStore.
 |      
 |      Hierarchical Data Format (HDF) is self-describing, allowing an
 |      application to interpret the structure and contents of a file with
 |      no outside information. One HDF file can hold a mix of related objects
 |      which can be accessed as a group or as individual objects.
 |      
 |      In order to add another DataFrame or Series to an existing HDF file
 |      please use append mode and a different a key.
 |      
 |      .. warning::
 |      
 |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,
 |         but the type of the subclass is lost upon storing.
 |      
 |      For more information see the :ref:`user guide &lt;io.hdf5&gt;`.
 |      
 |      Parameters
 |      ----------
 |      path_or_buf : str or pandas.HDFStore
 |          File path or HDFStore object.
 |      key : str
 |          Identifier for the group in the store.
 |      mode : {&#39;a&#39;, &#39;w&#39;, &#39;r+&#39;}, default &#39;a&#39;
 |          Mode to open file:
 |      
 |          - &#39;w&#39;: write, a new file is created (an existing file with
 |            the same name would be deleted).
 |          - &#39;a&#39;: append, an existing file is opened for reading and
 |            writing, and if the file does not exist it is created.
 |          - &#39;r+&#39;: similar to &#39;a&#39;, but the file must already exist.
 |      complevel : {0-9}, default None
 |          Specifies a compression level for data.
 |          A value of 0 or None disables compression.
 |      complib : {&#39;zlib&#39;, &#39;lzo&#39;, &#39;bzip2&#39;, &#39;blosc&#39;}, default &#39;zlib&#39;
 |          Specifies the compression library to be used.
 |          As of v0.20.2 these additional compressors for Blosc are supported
 |          (default if no compressor specified: &#39;blosc:blosclz&#39;):
 |          {&#39;blosc:blosclz&#39;, &#39;blosc:lz4&#39;, &#39;blosc:lz4hc&#39;, &#39;blosc:snappy&#39;,
 |          &#39;blosc:zlib&#39;, &#39;blosc:zstd&#39;}.
 |          Specifying a compression library which is not available issues
 |          a ValueError.
 |      append : bool, default False
 |          For Table formats, append the input data to the existing.
 |      format : {&#39;fixed&#39;, &#39;table&#39;, None}, default &#39;fixed&#39;
 |          Possible values:
 |      
 |          - &#39;fixed&#39;: Fixed format. Fast writing/reading. Not-appendable,
 |            nor searchable.
 |          - &#39;table&#39;: Table format. Write as a PyTables Table structure
 |            which may perform worse but allow more flexible operations
 |            like searching / selecting subsets of the data.
 |          - If None, pd.get_option(&#39;io.hdf.default_format&#39;) is checked,
 |            followed by fallback to &quot;fixed&quot;.
 |      index : bool, default True
 |          Write DataFrame index as a column.
 |      min_itemsize : dict or int, optional
 |          Map column names to minimum string sizes for columns.
 |      nan_rep : Any, optional
 |          How to represent null values as str.
 |          Not allowed with append=True.
 |      dropna : bool, default False, optional
 |          Remove missing values.
 |      data_columns : list of columns or True, optional
 |          List of columns to create as indexed data columns for on-disk
 |          queries, or True to use all columns. By default only the axes
 |          of the object are indexed. See
 |          :ref:`Query via data columns&lt;io.hdf5-query-data-columns&gt;`. for
 |          more information.
 |          Applicable only to format=&#39;table&#39;.
 |      errors : str, default &#39;strict&#39;
 |          Specifies how encoding and decoding errors are to be handled.
 |          See the errors argument for :func:`open` for a full list
 |          of options.
 |      encoding : str, default &quot;UTF-8&quot;
 |      
 |      See Also
 |      --------
 |      read_hdf : Read from HDF file.
 |      DataFrame.to_orc : Write a DataFrame to the binary orc format.
 |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.
 |      DataFrame.to_sql : Write to a SQL table.
 |      DataFrame.to_feather : Write out feather-format for DataFrames.
 |      DataFrame.to_csv : Write out to a csv file.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3], &#39;B&#39;: [4, 5, 6]},
 |      ...                   index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])  # doctest: +SKIP
 |      &gt;&gt;&gt; df.to_hdf(&#39;data.h5&#39;, key=&#39;df&#39;, mode=&#39;w&#39;)  # doctest: +SKIP
 |      
 |      We can add another object to the same file:
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])  # doctest: +SKIP
 |      &gt;&gt;&gt; s.to_hdf(&#39;data.h5&#39;, key=&#39;s&#39;)  # doctest: +SKIP
 |      
 |      Reading from HDF file:
 |      
 |      &gt;&gt;&gt; pd.read_hdf(&#39;data.h5&#39;, &#39;df&#39;)  # doctest: +SKIP
 |      A  B
 |      a  1  4
 |      b  2  5
 |      c  3  6
 |      &gt;&gt;&gt; pd.read_hdf(&#39;data.h5&#39;, &#39;s&#39;)  # doctest: +SKIP
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |  
 |  to_json(self, path_or_buf: &#39;FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None&#39; = None, orient: &#39;str | None&#39; = None, date_format: &#39;str | None&#39; = None, double_precision: &#39;int&#39; = 10, force_ascii: &#39;bool_t&#39; = True, date_unit: &#39;str&#39; = &#39;ms&#39;, default_handler: &#39;Callable[[Any], JSONSerializable] | None&#39; = None, lines: &#39;bool_t&#39; = False, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, index: &#39;bool_t&#39; = True, indent: &#39;int | None&#39; = None, storage_options: &#39;StorageOptions&#39; = None, mode: &quot;Literal[&#39;a&#39;, &#39;w&#39;]&quot; = &#39;w&#39;) -&gt; &#39;str | None&#39;
 |      Convert the object to a JSON string.
 |      
 |      Note NaN&#39;s and None will be converted to null and datetime objects
 |      will be converted to UNIX timestamps.
 |      
 |      Parameters
 |      ----------
 |      path_or_buf : str, path object, file-like object, or None, default None
 |          String, path object (implementing os.PathLike[str]), or file-like
 |          object implementing a write() function. If None, the result is
 |          returned as a string.
 |      orient : str
 |          Indication of expected JSON string format.
 |      
 |          * Series:
 |      
 |              - default is &#39;index&#39;
 |              - allowed values are: {&#39;split&#39;, &#39;records&#39;, &#39;index&#39;, &#39;table&#39;}.
 |      
 |          * DataFrame:
 |      
 |              - default is &#39;columns&#39;
 |              - allowed values are: {&#39;split&#39;, &#39;records&#39;, &#39;index&#39;, &#39;columns&#39;,
 |                &#39;values&#39;, &#39;table&#39;}.
 |      
 |          * The format of the JSON string:
 |      
 |              - &#39;split&#39; : dict like {&#39;index&#39; -&gt; [index], &#39;columns&#39; -&gt; [columns],
 |                &#39;data&#39; -&gt; [values]}
 |              - &#39;records&#39; : list like [{column -&gt; value}, ... , {column -&gt; value}]
 |              - &#39;index&#39; : dict like {index -&gt; {column -&gt; value}}
 |              - &#39;columns&#39; : dict like {column -&gt; {index -&gt; value}}
 |              - &#39;values&#39; : just the values array
 |              - &#39;table&#39; : dict like {&#39;schema&#39;: {schema}, &#39;data&#39;: {data}}
 |      
 |              Describing the data, where data component is like ``orient=&#39;records&#39;``.
 |      
 |      date_format : {None, &#39;epoch&#39;, &#39;iso&#39;}
 |          Type of date conversion. &#39;epoch&#39; = epoch milliseconds,
 |          &#39;iso&#39; = ISO8601. The default depends on the `orient`. For
 |          ``orient=&#39;table&#39;``, the default is &#39;iso&#39;. For all other orients,
 |          the default is &#39;epoch&#39;.
 |      double_precision : int, default 10
 |          The number of decimal places to use when encoding
 |          floating point values.
 |      force_ascii : bool, default True
 |          Force encoded string to be ASCII.
 |      date_unit : str, default &#39;ms&#39; (milliseconds)
 |          The time unit to encode to, governs timestamp and ISO8601
 |          precision.  One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
 |          microsecond, and nanosecond respectively.
 |      default_handler : callable, default None
 |          Handler to call if object cannot otherwise be converted to a
 |          suitable format for JSON. Should receive a single argument which is
 |          the object to convert and return a serialisable object.
 |      lines : bool, default False
 |          If &#39;orient&#39; is &#39;records&#39; write out line-delimited json format. Will
 |          throw ValueError if incorrect &#39;orient&#39; since others are not
 |          list-like.
 |      compression : str or dict, default &#39;infer&#39;
 |          For on-the-fly compression of the output data. If &#39;infer&#39; and &#39;path_or_buf&#39; is
 |          path-like, then detect compression from the following extensions: &#39;.gz&#39;,
 |          &#39;.bz2&#39;, &#39;.zip&#39;, &#39;.xz&#39;, &#39;.zst&#39;, &#39;.tar&#39;, &#39;.tar.gz&#39;, &#39;.tar.xz&#39; or &#39;.tar.bz2&#39;
 |          (otherwise no compression).
 |          Set to ``None`` for no compression.
 |          Can also be a dict with key ``&#39;method&#39;`` set
 |          to one of {``&#39;zip&#39;``, ``&#39;gzip&#39;``, ``&#39;bz2&#39;``, ``&#39;zstd&#39;``, ``&#39;tar&#39;``} and other
 |          key-value pairs are forwarded to
 |          ``zipfile.ZipFile``, ``gzip.GzipFile``,
 |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or
 |          ``tarfile.TarFile``, respectively.
 |          As an example, the following could be passed for faster compression and to create
 |          a reproducible gzip archive:
 |          ``compression={&#39;method&#39;: &#39;gzip&#39;, &#39;compresslevel&#39;: 1, &#39;mtime&#39;: 1}``.
 |      
 |          .. versionadded:: 1.5.0
 |              Added support for `.tar` files.
 |      
 |          .. versionchanged:: 1.4.0 Zstandard support.
 |      
 |      index : bool, default True
 |          Whether to include the index values in the JSON string. Not
 |          including the index (``index=False``) is only supported when
 |          orient is &#39;split&#39; or &#39;table&#39;.
 |      indent : int, optional
 |         Length of whitespace used to indent each record.
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib.request.Request`` as header options. For other
 |          URLs (e.g. starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are
 |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more
 |          details, and for more examples on storage options refer `here
 |          &lt;https://pandas.pydata.org/docs/user_guide/io.html?
 |          highlight=storage_options#reading-writing-remote-files&gt;`_.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      mode : str, default &#39;w&#39; (writing)
 |          Specify the IO mode for output when supplying a path_or_buf.
 |          Accepted args are &#39;w&#39; (writing) and &#39;a&#39; (append) only.
 |          mode=&#39;a&#39; is only supported when lines is True and orient is &#39;records&#39;.
 |      
 |      Returns
 |      -------
 |      None or str
 |          If path_or_buf is None, returns the resulting json format as a
 |          string. Otherwise returns None.
 |      
 |      See Also
 |      --------
 |      read_json : Convert a JSON string to pandas object.
 |      
 |      Notes
 |      -----
 |      The behavior of ``indent=0`` varies from the stdlib, which does not
 |      indent the output but does insert newlines. Currently, ``indent=0``
 |      and the default ``indent=None`` are equivalent in pandas, though this
 |      may change in a future release.
 |      
 |      ``orient=&#39;table&#39;`` contains a &#39;pandas_version&#39; field under &#39;schema&#39;.
 |      This stores the version of `pandas` used in the latest revision of the
 |      schema.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; from json import loads, dumps
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     [[&quot;a&quot;, &quot;b&quot;], [&quot;c&quot;, &quot;d&quot;]],
 |      ...     index=[&quot;row 1&quot;, &quot;row 2&quot;],
 |      ...     columns=[&quot;col 1&quot;, &quot;col 2&quot;],
 |      ... )
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;split&quot;)
 |      &gt;&gt;&gt; parsed = loads(result)
 |      &gt;&gt;&gt; dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;columns&quot;: [
 |              &quot;col 1&quot;,
 |              &quot;col 2&quot;
 |          ],
 |          &quot;index&quot;: [
 |              &quot;row 1&quot;,
 |              &quot;row 2&quot;
 |          ],
 |          &quot;data&quot;: [
 |              [
 |                  &quot;a&quot;,
 |                  &quot;b&quot;
 |              ],
 |              [
 |                  &quot;c&quot;,
 |                  &quot;d&quot;
 |              ]
 |          ]
 |      }
 |      
 |      Encoding/decoding a Dataframe using ``&#39;records&#39;`` formatted JSON.
 |      Note that index labels are not preserved with this encoding.
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;records&quot;)
 |      &gt;&gt;&gt; parsed = loads(result)
 |      &gt;&gt;&gt; dumps(parsed, indent=4)  # doctest: +SKIP
 |      [
 |          {
 |              &quot;col 1&quot;: &quot;a&quot;,
 |              &quot;col 2&quot;: &quot;b&quot;
 |          },
 |          {
 |              &quot;col 1&quot;: &quot;c&quot;,
 |              &quot;col 2&quot;: &quot;d&quot;
 |          }
 |      ]
 |      
 |      Encoding/decoding a Dataframe using ``&#39;index&#39;`` formatted JSON:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;index&quot;)
 |      &gt;&gt;&gt; parsed = loads(result)
 |      &gt;&gt;&gt; dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;row 1&quot;: {
 |              &quot;col 1&quot;: &quot;a&quot;,
 |              &quot;col 2&quot;: &quot;b&quot;
 |          },
 |          &quot;row 2&quot;: {
 |              &quot;col 1&quot;: &quot;c&quot;,
 |              &quot;col 2&quot;: &quot;d&quot;
 |          }
 |      }
 |      
 |      Encoding/decoding a Dataframe using ``&#39;columns&#39;`` formatted JSON:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;columns&quot;)
 |      &gt;&gt;&gt; parsed = loads(result)
 |      &gt;&gt;&gt; dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;col 1&quot;: {
 |              &quot;row 1&quot;: &quot;a&quot;,
 |              &quot;row 2&quot;: &quot;c&quot;
 |          },
 |          &quot;col 2&quot;: {
 |              &quot;row 1&quot;: &quot;b&quot;,
 |              &quot;row 2&quot;: &quot;d&quot;
 |          }
 |      }
 |      
 |      Encoding/decoding a Dataframe using ``&#39;values&#39;`` formatted JSON:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;values&quot;)
 |      &gt;&gt;&gt; parsed = loads(result)
 |      &gt;&gt;&gt; dumps(parsed, indent=4)  # doctest: +SKIP
 |      [
 |          [
 |              &quot;a&quot;,
 |              &quot;b&quot;
 |          ],
 |          [
 |              &quot;c&quot;,
 |              &quot;d&quot;
 |          ]
 |      ]
 |      
 |      Encoding with Table Schema:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;table&quot;)
 |      &gt;&gt;&gt; parsed = loads(result)
 |      &gt;&gt;&gt; dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;schema&quot;: {
 |              &quot;fields&quot;: [
 |                  {
 |                      &quot;name&quot;: &quot;index&quot;,
 |                      &quot;type&quot;: &quot;string&quot;
 |                  },
 |                  {
 |                      &quot;name&quot;: &quot;col 1&quot;,
 |                      &quot;type&quot;: &quot;string&quot;
 |                  },
 |                  {
 |                      &quot;name&quot;: &quot;col 2&quot;,
 |                      &quot;type&quot;: &quot;string&quot;
 |                  }
 |              ],
 |              &quot;primaryKey&quot;: [
 |                  &quot;index&quot;
 |              ],
 |              &quot;pandas_version&quot;: &quot;1.4.0&quot;
 |          },
 |          &quot;data&quot;: [
 |              {
 |                  &quot;index&quot;: &quot;row 1&quot;,
 |                  &quot;col 1&quot;: &quot;a&quot;,
 |                  &quot;col 2&quot;: &quot;b&quot;
 |              },
 |              {
 |                  &quot;index&quot;: &quot;row 2&quot;,
 |                  &quot;col 1&quot;: &quot;c&quot;,
 |                  &quot;col 2&quot;: &quot;d&quot;
 |              }
 |          ]
 |      }
 |  
 |  to_latex(self, buf: &#39;FilePath | WriteBuffer[str] | None&#39; = None, columns: &#39;Sequence[Hashable] | None&#39; = None, header: &#39;bool_t | Sequence[str]&#39; = True, index: &#39;bool_t&#39; = True, na_rep: &#39;str&#39; = &#39;NaN&#39;, formatters: &#39;FormattersType | None&#39; = None, float_format: &#39;FloatFormatType | None&#39; = None, sparsify: &#39;bool_t | None&#39; = None, index_names: &#39;bool_t&#39; = True, bold_rows: &#39;bool_t&#39; = False, column_format: &#39;str | None&#39; = None, longtable: &#39;bool_t | None&#39; = None, escape: &#39;bool_t | None&#39; = None, encoding: &#39;str | None&#39; = None, decimal: &#39;str&#39; = &#39;.&#39;, multicolumn: &#39;bool_t | None&#39; = None, multicolumn_format: &#39;str | None&#39; = None, multirow: &#39;bool_t | None&#39; = None, caption: &#39;str | tuple[str, str] | None&#39; = None, label: &#39;str | None&#39; = None, position: &#39;str | None&#39; = None) -&gt; &#39;str | None&#39;
 |      Render object to a LaTeX tabular, longtable, or nested table.
 |      
 |      Requires ``\usepackage{{booktabs}}``.  The output can be copy/pasted
 |      into a main LaTeX document or read from an external file
 |      with ``\input{{table.tex}}``.
 |      
 |      .. versionchanged:: 1.2.0
 |         Added position argument, changed meaning of caption argument.
 |      
 |      .. versionchanged:: 2.0.0
 |         Refactored to use the Styler implementation via jinja2 templating.
 |      
 |      Parameters
 |      ----------
 |      buf : str, Path or StringIO-like, optional, default None
 |          Buffer to write to. If None, the output is returned as a string.
 |      columns : list of label, optional
 |          The subset of columns to write. Writes all columns by default.
 |      header : bool or list of str, default True
 |          Write out the column names. If a list of strings is given,
 |          it is assumed to be aliases for the column names.
 |      index : bool, default True
 |          Write row names (index).
 |      na_rep : str, default &#39;NaN&#39;
 |          Missing data representation.
 |      formatters : list of functions or dict of {{str: function}}, optional
 |          Formatter functions to apply to columns&#39; elements by position or
 |          name. The result of each function must be a unicode string.
 |          List must be of length equal to the number of columns.
 |      float_format : one-parameter function or str, optional, default None
 |          Formatter for floating point numbers. For example
 |          ``float_format=&quot;%.2f&quot;`` and ``float_format=&quot;{{:0.2f}}&quot;.format`` will
 |          both result in 0.1234 being formatted as 0.12.
 |      sparsify : bool, optional
 |          Set to False for a DataFrame with a hierarchical index to print
 |          every multiindex key at each row. By default, the value will be
 |          read from the config module.
 |      index_names : bool, default True
 |          Prints the names of the indexes.
 |      bold_rows : bool, default False
 |          Make the row labels bold in the output.
 |      column_format : str, optional
 |          The columns format as specified in `LaTeX table format
 |          &lt;https://en.wikibooks.org/wiki/LaTeX/Tables&gt;`__ e.g. &#39;rcl&#39; for 3
 |          columns. By default, &#39;l&#39; will be used for all columns except
 |          columns of numbers, which default to &#39;r&#39;.
 |      longtable : bool, optional
 |          Use a longtable environment instead of tabular. Requires
 |          adding a \usepackage{{longtable}} to your LaTeX preamble.
 |          By default, the value will be read from the pandas config
 |          module, and set to `True` if the option ``styler.latex.environment`` is
 |          `&quot;longtable&quot;`.
 |      
 |          .. versionchanged:: 2.0.0
 |             The pandas option affecting this argument has changed.
 |      escape : bool, optional
 |          By default, the value will be read from the pandas config
 |          module and set to `True` if the option ``styler.format.escape`` is
 |          `&quot;latex&quot;`. When set to False prevents from escaping latex special
 |          characters in column names.
 |      
 |          .. versionchanged:: 2.0.0
 |             The pandas option affecting this argument has changed, as has the
 |             default value to `False`.
 |      encoding : str, optional
 |          A string representing the encoding to use in the output file,
 |          defaults to &#39;utf-8&#39;.
 |      decimal : str, default &#39;.&#39;
 |          Character recognized as decimal separator, e.g. &#39;,&#39; in Europe.
 |      multicolumn : bool, default True
 |          Use \multicolumn to enhance MultiIndex columns.
 |          The default will be read from the config module, and is set
 |          as the option ``styler.sparse.columns``.
 |      
 |          .. versionchanged:: 2.0.0
 |             The pandas option affecting this argument has changed.
 |      multicolumn_format : str, default &#39;r&#39;
 |          The alignment for multicolumns, similar to `column_format`
 |          The default will be read from the config module, and is set as the option
 |          ``styler.latex.multicol_align``.
 |      
 |          .. versionchanged:: 2.0.0
 |             The pandas option affecting this argument has changed, as has the
 |             default value to &quot;r&quot;.
 |      multirow : bool, default True
 |          Use \multirow to enhance MultiIndex rows. Requires adding a
 |          \usepackage{{multirow}} to your LaTeX preamble. Will print
 |          centered labels (instead of top-aligned) across the contained
 |          rows, separating groups via clines. The default will be read
 |          from the pandas config module, and is set as the option
 |          ``styler.sparse.index``.
 |      
 |          .. versionchanged:: 2.0.0
 |             The pandas option affecting this argument has changed, as has the
 |             default value to `True`.
 |      caption : str or tuple, optional
 |          Tuple (full_caption, short_caption),
 |          which results in ``\caption[short_caption]{{full_caption}}``;
 |          if a single string is passed, no short caption will be set.
 |      
 |          .. versionchanged:: 1.2.0
 |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.
 |      
 |      label : str, optional
 |          The LaTeX label to be placed inside ``\label{{}}`` in the output.
 |          This is used with ``\ref{{}}`` in the main ``.tex`` file.
 |      
 |      position : str, optional
 |          The LaTeX positional argument for tables, to be placed after
 |          ``\begin{{}}`` in the output.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      Returns
 |      -------
 |      str or None
 |          If buf is None, returns the result as a string. Otherwise returns None.
 |      
 |      See Also
 |      --------
 |      io.formats.style.Styler.to_latex : Render a DataFrame to LaTeX
 |          with conditional formatting.
 |      DataFrame.to_string : Render a DataFrame to a console-friendly
 |          tabular output.
 |      DataFrame.to_html : Render a DataFrame as an HTML table.
 |      
 |      Notes
 |      -----
 |      As of v2.0.0 this method has changed to use the Styler implementation as
 |      part of :meth:`.Styler.to_latex` via ``jinja2`` templating. This means
 |      that ``jinja2`` is a requirement, and needs to be installed, for this method
 |      to function. It is advised that users switch to using Styler, since that
 |      implementation is more frequently updated and contains much more
 |      flexibility with the output.
 |      
 |      Examples
 |      --------
 |      Convert a general DataFrame to LaTeX with formatting:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(name=[&#39;Raphael&#39;, &#39;Donatello&#39;],
 |      ...                        age=[26, 45],
 |      ...                        height=[181.23, 177.65]))
 |      &gt;&gt;&gt; print(df.to_latex(index=False,
 |      ...                   formatters={&quot;name&quot;: str.upper},
 |      ...                   float_format=&quot;{:.1f}&quot;.format,
 |      ... ))  # doctest: +SKIP
 |      \begin{tabular}{lrr}
 |      \toprule
 |      name &amp; age &amp; height \\
 |      \midrule
 |      RAPHAEL &amp; 26 &amp; 181.2 \\
 |      DONATELLO &amp; 45 &amp; 177.7 \\
 |      \bottomrule
 |      \end{tabular}
 |  
 |  to_pickle(self, path: &#39;FilePath | WriteBuffer[bytes]&#39;, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, protocol: &#39;int&#39; = 5, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;None&#39;
 |      Pickle (serialize) object to file.
 |      
 |      Parameters
 |      ----------
 |      path : str, path object, or file-like object
 |          String, path object (implementing ``os.PathLike[str]``), or file-like
 |          object implementing a binary ``write()`` function. File path where
 |          the pickled object will be stored.
 |      compression : str or dict, default &#39;infer&#39;
 |          For on-the-fly compression of the output data. If &#39;infer&#39; and &#39;path&#39; is
 |          path-like, then detect compression from the following extensions: &#39;.gz&#39;,
 |          &#39;.bz2&#39;, &#39;.zip&#39;, &#39;.xz&#39;, &#39;.zst&#39;, &#39;.tar&#39;, &#39;.tar.gz&#39;, &#39;.tar.xz&#39; or &#39;.tar.bz2&#39;
 |          (otherwise no compression).
 |          Set to ``None`` for no compression.
 |          Can also be a dict with key ``&#39;method&#39;`` set
 |          to one of {``&#39;zip&#39;``, ``&#39;gzip&#39;``, ``&#39;bz2&#39;``, ``&#39;zstd&#39;``, ``&#39;tar&#39;``} and other
 |          key-value pairs are forwarded to
 |          ``zipfile.ZipFile``, ``gzip.GzipFile``,
 |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor`` or
 |          ``tarfile.TarFile``, respectively.
 |          As an example, the following could be passed for faster compression and to create
 |          a reproducible gzip archive:
 |          ``compression={&#39;method&#39;: &#39;gzip&#39;, &#39;compresslevel&#39;: 1, &#39;mtime&#39;: 1}``.
 |      
 |          .. versionadded:: 1.5.0
 |              Added support for `.tar` files.
 |      protocol : int
 |          Int which indicates which protocol should be used by the pickler,
 |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible
 |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol
 |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.
 |      
 |          .. [1] https://docs.python.org/3/library/pickle.html.
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib.request.Request`` as header options. For other
 |          URLs (e.g. starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are
 |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more
 |          details, and for more examples on storage options refer `here
 |          &lt;https://pandas.pydata.org/docs/user_guide/io.html?
 |          highlight=storage_options#reading-writing-remote-files&gt;`_.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      See Also
 |      --------
 |      read_pickle : Load pickled pandas object (or any object) from file.
 |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.
 |      DataFrame.to_sql : Write DataFrame to a SQL database.
 |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; original_df = pd.DataFrame({&quot;foo&quot;: range(5), &quot;bar&quot;: range(5, 10)})  # doctest: +SKIP
 |      &gt;&gt;&gt; original_df  # doctest: +SKIP
 |         foo  bar
 |      0    0    5
 |      1    1    6
 |      2    2    7
 |      3    3    8
 |      4    4    9
 |      &gt;&gt;&gt; original_df.to_pickle(&quot;./dummy.pkl&quot;)  # doctest: +SKIP
 |      
 |      &gt;&gt;&gt; unpickled_df = pd.read_pickle(&quot;./dummy.pkl&quot;)  # doctest: +SKIP
 |      &gt;&gt;&gt; unpickled_df  # doctest: +SKIP
 |         foo  bar
 |      0    0    5
 |      1    1    6
 |      2    2    7
 |      3    3    8
 |      4    4    9
 |  
 |  to_sql(self, name: &#39;str&#39;, con, schema: &#39;str | None&#39; = None, if_exists: &quot;Literal[&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;]&quot; = &#39;fail&#39;, index: &#39;bool_t&#39; = True, index_label: &#39;IndexLabel&#39; = None, chunksize: &#39;int | None&#39; = None, dtype: &#39;DtypeArg | None&#39; = None, method: &#39;str | None&#39; = None) -&gt; &#39;int | None&#39;
 |      Write records stored in a DataFrame to a SQL database.
 |      
 |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be
 |      newly created, appended to, or overwritten.
 |      
 |      Parameters
 |      ----------
 |      name : str
 |          Name of SQL table.
 |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection
 |          Using SQLAlchemy makes it possible to use any DB supported by that
 |          library. Legacy support is provided for sqlite3.Connection objects. The user
 |          is responsible for engine disposal and connection closure for the SQLAlchemy
 |          connectable. See `here                 &lt;https://docs.sqlalchemy.org/en/20/core/connections.html&gt;`_.
 |          If passing a sqlalchemy.engine.Connection which is already in a transaction,
 |          the transaction will not be committed.  If passing a sqlite3.Connection,
 |          it will not be possible to roll back the record insertion.
 |      
 |      schema : str, optional
 |          Specify the schema (if database flavor supports this). If None, use
 |          default schema.
 |      if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
 |          How to behave if the table already exists.
 |      
 |          * fail: Raise a ValueError.
 |          * replace: Drop the table before inserting new values.
 |          * append: Insert new values to the existing table.
 |      
 |      index : bool, default True
 |          Write DataFrame index as a column. Uses `index_label` as the column
 |          name in the table.
 |      index_label : str or sequence, default None
 |          Column label for index column(s). If None is given (default) and
 |          `index` is True, then the index names are used.
 |          A sequence should be given if the DataFrame uses MultiIndex.
 |      chunksize : int, optional
 |          Specify the number of rows in each batch to be written at a time.
 |          By default, all rows will be written at once.
 |      dtype : dict or scalar, optional
 |          Specifying the datatype for columns. If a dictionary is used, the
 |          keys should be the column names and the values should be the
 |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a
 |          scalar is provided, it will be applied to all columns.
 |      method : {None, &#39;multi&#39;, callable}, optional
 |          Controls the SQL insertion clause used:
 |      
 |          * None : Uses standard SQL ``INSERT`` clause (one per row).
 |          * &#39;multi&#39;: Pass multiple values in a single ``INSERT`` clause.
 |          * callable with signature ``(pd_table, conn, keys, data_iter)``.
 |      
 |          Details and a sample callable implementation can be found in the
 |          section :ref:`insert method &lt;io.sql.method&gt;`.
 |      
 |      Returns
 |      -------
 |      None or int
 |          Number of rows affected by to_sql. None is returned if the callable
 |          passed into ``method`` does not return an integer number of rows.
 |      
 |          The number of returned rows affected is the sum of the ``rowcount``
 |          attribute of ``sqlite3.Cursor`` or SQLAlchemy connectable which may not
 |          reflect the exact number of written rows as stipulated in the
 |          `sqlite3 &lt;https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount&gt;`__ or
 |          `SQLAlchemy &lt;https://docs.sqlalchemy.org/en/20/core/connections.html#sqlalchemy.engine.CursorResult.rowcount&gt;`__.
 |      
 |          .. versionadded:: 1.4.0
 |      
 |      Raises
 |      ------
 |      ValueError
 |          When the table already exists and `if_exists` is &#39;fail&#39; (the
 |          default).
 |      
 |      See Also
 |      --------
 |      read_sql : Read a DataFrame from a table.
 |      
 |      Notes
 |      -----
 |      Timezone aware datetime columns will be written as
 |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the
 |      database. Otherwise, the datetimes will be stored as timezone unaware
 |      timestamps local to the original timezone.
 |      
 |      References
 |      ----------
 |      .. [1] https://docs.sqlalchemy.org
 |      .. [2] https://www.python.org/dev/peps/pep-0249/
 |      
 |      Examples
 |      --------
 |      Create an in-memory SQLite database.
 |      
 |      &gt;&gt;&gt; from sqlalchemy import create_engine
 |      &gt;&gt;&gt; engine = create_engine(&#39;sqlite://&#39;, echo=False)
 |      
 |      Create a table from scratch with 3 rows.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;name&#39; : [&#39;User 1&#39;, &#39;User 2&#39;, &#39;User 3&#39;]})
 |      &gt;&gt;&gt; df
 |           name
 |      0  User 1
 |      1  User 2
 |      2  User 3
 |      
 |      &gt;&gt;&gt; df.to_sql(&#39;users&#39;, con=engine)
 |      3
 |      &gt;&gt;&gt; from sqlalchemy import text
 |      &gt;&gt;&gt; with engine.connect() as conn:
 |      ...    conn.execute(text(&quot;SELECT * FROM users&quot;)).fetchall()
 |      [(0, &#39;User 1&#39;), (1, &#39;User 2&#39;), (2, &#39;User 3&#39;)]
 |      
 |      An `sqlalchemy.engine.Connection` can also be passed to `con`:
 |      
 |      &gt;&gt;&gt; with engine.begin() as connection:
 |      ...     df1 = pd.DataFrame({&#39;name&#39; : [&#39;User 4&#39;, &#39;User 5&#39;]})
 |      ...     df1.to_sql(&#39;users&#39;, con=connection, if_exists=&#39;append&#39;)
 |      2
 |      
 |      This is allowed to support operations that require that the same
 |      DBAPI connection is used for the entire operation.
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;name&#39; : [&#39;User 6&#39;, &#39;User 7&#39;]})
 |      &gt;&gt;&gt; df2.to_sql(&#39;users&#39;, con=engine, if_exists=&#39;append&#39;)
 |      2
 |      &gt;&gt;&gt; with engine.connect() as conn:
 |      ...    conn.execute(text(&quot;SELECT * FROM users&quot;)).fetchall()
 |      [(0, &#39;User 1&#39;), (1, &#39;User 2&#39;), (2, &#39;User 3&#39;),
 |       (0, &#39;User 4&#39;), (1, &#39;User 5&#39;), (0, &#39;User 6&#39;),
 |       (1, &#39;User 7&#39;)]
 |      
 |      Overwrite the table with just ``df2``.
 |      
 |      &gt;&gt;&gt; df2.to_sql(&#39;users&#39;, con=engine, if_exists=&#39;replace&#39;,
 |      ...            index_label=&#39;id&#39;)
 |      2
 |      &gt;&gt;&gt; with engine.connect() as conn:
 |      ...    conn.execute(text(&quot;SELECT * FROM users&quot;)).fetchall()
 |      [(0, &#39;User 6&#39;), (1, &#39;User 7&#39;)]
 |      
 |      Specify the dtype (especially useful for integers with missing values).
 |      Notice that while pandas is forced to store the data as floating point,
 |      the database supports nullable integers. When fetching the data with
 |      Python, we get back integer scalars.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, None, 2]})
 |      &gt;&gt;&gt; df
 |           A
 |      0  1.0
 |      1  NaN
 |      2  2.0
 |      
 |      &gt;&gt;&gt; from sqlalchemy.types import Integer
 |      &gt;&gt;&gt; df.to_sql(&#39;integers&#39;, con=engine, index=False,
 |      ...           dtype={&quot;A&quot;: Integer()})
 |      3
 |      
 |      &gt;&gt;&gt; with engine.connect() as conn:
 |      ...   conn.execute(text(&quot;SELECT * FROM integers&quot;)).fetchall()
 |      [(1,), (None,), (2,)]
 |  
 |  to_xarray(self)
 |      Return an xarray object from the pandas object.
 |      
 |      Returns
 |      -------
 |      xarray.DataArray or xarray.Dataset
 |          Data in the pandas structure converted to Dataset if the object is
 |          a DataFrame, or a DataArray if the object is a Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.
 |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.
 |      
 |      Notes
 |      -----
 |      See the `xarray docs &lt;https://xarray.pydata.org/en/stable/&gt;`__
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;falcon&#39;, &#39;bird&#39;, 389.0, 2),
 |      ...                    (&#39;parrot&#39;, &#39;bird&#39;, 24.0, 2),
 |      ...                    (&#39;lion&#39;, &#39;mammal&#39;, 80.5, 4),
 |      ...                    (&#39;monkey&#39;, &#39;mammal&#39;, np.nan, 4)],
 |      ...                   columns=[&#39;name&#39;, &#39;class&#39;, &#39;max_speed&#39;,
 |      ...                            &#39;num_legs&#39;])
 |      &gt;&gt;&gt; df
 |           name   class  max_speed  num_legs
 |      0  falcon    bird      389.0         2
 |      1  parrot    bird       24.0         2
 |      2    lion  mammal       80.5         4
 |      3  monkey  mammal        NaN         4
 |      
 |      &gt;&gt;&gt; df.to_xarray()
 |      &lt;xarray.Dataset&gt;
 |      Dimensions:    (index: 4)
 |      Coordinates:
 |        * index      (index) int64 0 1 2 3
 |      Data variables:
 |          name       (index) object &#39;falcon&#39; &#39;parrot&#39; &#39;lion&#39; &#39;monkey&#39;
 |          class      (index) object &#39;bird&#39; &#39;bird&#39; &#39;mammal&#39; &#39;mammal&#39;
 |          max_speed  (index) float64 389.0 24.0 80.5 nan
 |          num_legs   (index) int64 2 2 4 4
 |      
 |      &gt;&gt;&gt; df[&#39;max_speed&#39;].to_xarray()
 |      &lt;xarray.DataArray &#39;max_speed&#39; (index: 4)&gt;
 |      array([389. ,  24. ,  80.5,   nan])
 |      Coordinates:
 |        * index    (index) int64 0 1 2 3
 |      
 |      &gt;&gt;&gt; dates = pd.to_datetime([&#39;2018-01-01&#39;, &#39;2018-01-01&#39;,
 |      ...                         &#39;2018-01-02&#39;, &#39;2018-01-02&#39;])
 |      &gt;&gt;&gt; df_multiindex = pd.DataFrame({&#39;date&#39;: dates,
 |      ...                               &#39;animal&#39;: [&#39;falcon&#39;, &#39;parrot&#39;,
 |      ...                                          &#39;falcon&#39;, &#39;parrot&#39;],
 |      ...                               &#39;speed&#39;: [350, 18, 361, 15]})
 |      &gt;&gt;&gt; df_multiindex = df_multiindex.set_index([&#39;date&#39;, &#39;animal&#39;])
 |      
 |      &gt;&gt;&gt; df_multiindex
 |                         speed
 |      date       animal
 |      2018-01-01 falcon    350
 |                 parrot     18
 |      2018-01-02 falcon    361
 |                 parrot     15
 |      
 |      &gt;&gt;&gt; df_multiindex.to_xarray()
 |      &lt;xarray.Dataset&gt;
 |      Dimensions:  (date: 2, animal: 2)
 |      Coordinates:
 |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02
 |        * animal   (animal) object &#39;falcon&#39; &#39;parrot&#39;
 |      Data variables:
 |          speed    (date, animal) int64 350 18 361 15
 |  
 |  truncate(self: &#39;NDFrameT&#39;, before=None, after=None, axis: &#39;Axis | None&#39; = None, copy: &#39;bool_t | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Truncate a Series or DataFrame before and after some index value.
 |      
 |      This is a useful shorthand for boolean indexing based on index
 |      values above or below certain thresholds.
 |      
 |      Parameters
 |      ----------
 |      before : date, str, int
 |          Truncate all rows before this index value.
 |      after : date, str, int
 |          Truncate all rows after this index value.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, optional
 |          Axis to truncate. Truncates the index (rows) by default.
 |          For `Series` this parameter is unused and defaults to 0.
 |      copy : bool, default is True,
 |          Return a copy of the truncated section.
 |      
 |      Returns
 |      -------
 |      type of caller
 |          The truncated Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Select a subset of a DataFrame by label.
 |      DataFrame.iloc : Select a subset of a DataFrame by position.
 |      
 |      Notes
 |      -----
 |      If the index being truncated contains only datetime values,
 |      `before` and `after` may be specified as strings instead of
 |      Timestamps.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;],
 |      ...                    &#39;B&#39;: [&#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;],
 |      ...                    &#39;C&#39;: [&#39;k&#39;, &#39;l&#39;, &#39;m&#39;, &#39;n&#39;, &#39;o&#39;]},
 |      ...                   index=[1, 2, 3, 4, 5])
 |      &gt;&gt;&gt; df
 |         A  B  C
 |      1  a  f  k
 |      2  b  g  l
 |      3  c  h  m
 |      4  d  i  n
 |      5  e  j  o
 |      
 |      &gt;&gt;&gt; df.truncate(before=2, after=4)
 |         A  B  C
 |      2  b  g  l
 |      3  c  h  m
 |      4  d  i  n
 |      
 |      The columns of a DataFrame can be truncated.
 |      
 |      &gt;&gt;&gt; df.truncate(before=&quot;A&quot;, after=&quot;B&quot;, axis=&quot;columns&quot;)
 |         A  B
 |      1  a  f
 |      2  b  g
 |      3  c  h
 |      4  d  i
 |      5  e  j
 |      
 |      For Series, only rows can be truncated.
 |      
 |      &gt;&gt;&gt; df[&#39;A&#39;].truncate(before=2, after=4)
 |      2    b
 |      3    c
 |      4    d
 |      Name: A, dtype: object
 |      
 |      The index values in ``truncate`` can be datetimes or string
 |      dates.
 |      
 |      &gt;&gt;&gt; dates = pd.date_range(&#39;2016-01-01&#39;, &#39;2016-02-01&#39;, freq=&#39;s&#39;)
 |      &gt;&gt;&gt; df = pd.DataFrame(index=dates, data={&#39;A&#39;: 1})
 |      &gt;&gt;&gt; df.tail()
 |                           A
 |      2016-01-31 23:59:56  1
 |      2016-01-31 23:59:57  1
 |      2016-01-31 23:59:58  1
 |      2016-01-31 23:59:59  1
 |      2016-02-01 00:00:00  1
 |      
 |      &gt;&gt;&gt; df.truncate(before=pd.Timestamp(&#39;2016-01-05&#39;),
 |      ...             after=pd.Timestamp(&#39;2016-01-10&#39;)).tail()
 |                           A
 |      2016-01-09 23:59:56  1
 |      2016-01-09 23:59:57  1
 |      2016-01-09 23:59:58  1
 |      2016-01-09 23:59:59  1
 |      2016-01-10 00:00:00  1
 |      
 |      Because the index is a DatetimeIndex containing only dates, we can
 |      specify `before` and `after` as strings. They will be coerced to
 |      Timestamps before truncation.
 |      
 |      &gt;&gt;&gt; df.truncate(&#39;2016-01-05&#39;, &#39;2016-01-10&#39;).tail()
 |                           A
 |      2016-01-09 23:59:56  1
 |      2016-01-09 23:59:57  1
 |      2016-01-09 23:59:58  1
 |      2016-01-09 23:59:59  1
 |      2016-01-10 00:00:00  1
 |      
 |      Note that ``truncate`` assumes a 0 value for any unspecified time
 |      component (midnight). This differs from partial string slicing, which
 |      returns any partially matching dates.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;2016-01-05&#39;:&#39;2016-01-10&#39;, :].tail()
 |                           A
 |      2016-01-10 23:59:55  1
 |      2016-01-10 23:59:56  1
 |      2016-01-10 23:59:57  1
 |      2016-01-10 23:59:58  1
 |      2016-01-10 23:59:59  1
 |  
 |  tz_convert(self: &#39;NDFrameT&#39;, tz, axis: &#39;Axis&#39; = 0, level=None, copy: &#39;bool_t | None&#39; = None) -&gt; &#39;NDFrameT&#39;
 |      Convert tz-aware axis to target time zone.
 |      
 |      Parameters
 |      ----------
 |      tz : str or tzinfo object or None
 |          Target time zone. Passing ``None`` will convert to
 |          UTC and remove the timezone information.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to convert
 |      level : int, str, default None
 |          If axis is a MultiIndex, convert a specific level. Otherwise
 |          must be None.
 |      copy : bool, default True
 |          Also make a copy of the underlying data.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame
 |          Object with time zone converted axis.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the axis is tz-naive.
 |      
 |      Examples
 |      --------
 |      Change to another time zone:
 |      
 |      &gt;&gt;&gt; s = pd.Series(
 |      ...     [1],
 |      ...     index=pd.DatetimeIndex([&#39;2018-09-15 01:30:00+02:00&#39;]),
 |      ... )
 |      &gt;&gt;&gt; s.tz_convert(&#39;Asia/Shanghai&#39;)
 |      2018-09-15 07:30:00+08:00    1
 |      dtype: int64
 |      
 |      Pass None to convert to UTC and get a tz-naive index:
 |      
 |      &gt;&gt;&gt; s = pd.Series([1],
 |      ...     index=pd.DatetimeIndex([&#39;2018-09-15 01:30:00+02:00&#39;]))
 |      &gt;&gt;&gt; s.tz_convert(None)
 |      2018-09-14 23:30:00    1
 |      dtype: int64
 |  
 |  tz_localize(self: &#39;NDFrameT&#39;, tz, axis: &#39;Axis&#39; = 0, level=None, copy: &#39;bool_t | None&#39; = None, ambiguous: &#39;TimeAmbiguous&#39; = &#39;raise&#39;, nonexistent: &#39;TimeNonexistent&#39; = &#39;raise&#39;) -&gt; &#39;NDFrameT&#39;
 |      Localize tz-naive index of a Series or DataFrame to target time zone.
 |      
 |      This operation localizes the Index. To localize the values in a
 |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.
 |      
 |      Parameters
 |      ----------
 |      tz : str or tzinfo or None
 |          Time zone to localize. Passing ``None`` will remove the
 |          time zone information and preserve local time.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to localize
 |      level : int, str, default None
 |          If axis ia a MultiIndex, localize a specific level. Otherwise
 |          must be None.
 |      copy : bool, default True
 |          Also make a copy of the underlying data.
 |      ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
 |          When clocks moved backward due to DST, ambiguous times may arise.
 |          For example in Central European Time (UTC+01), when going from
 |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at
 |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the
 |          `ambiguous` parameter dictates how ambiguous times should be
 |          handled.
 |      
 |          - &#39;infer&#39; will attempt to infer fall dst-transition hours based on
 |            order
 |          - bool-ndarray where True signifies a DST time, False designates
 |            a non-DST time (note that this flag is only applicable for
 |            ambiguous times)
 |          - &#39;NaT&#39; will return NaT where there are ambiguous times
 |          - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous
 |            times.
 |      nonexistent : str, default &#39;raise&#39;
 |          A nonexistent time does not exist in a particular timezone
 |          where clocks moved forward due to DST. Valid values are:
 |      
 |          - &#39;shift_forward&#39; will shift the nonexistent time forward to the
 |            closest existing time
 |          - &#39;shift_backward&#39; will shift the nonexistent time backward to the
 |            closest existing time
 |          - &#39;NaT&#39; will return NaT where there are nonexistent times
 |          - timedelta objects will shift nonexistent times by the timedelta
 |          - &#39;raise&#39; will raise an NonExistentTimeError if there are
 |            nonexistent times.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame
 |          Same type as the input.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the TimeSeries is tz-aware and tz is not None.
 |      
 |      Examples
 |      --------
 |      Localize local times:
 |      
 |      &gt;&gt;&gt; s = pd.Series(
 |      ...     [1],
 |      ...     index=pd.DatetimeIndex([&#39;2018-09-15 01:30:00&#39;]),
 |      ... )
 |      &gt;&gt;&gt; s.tz_localize(&#39;CET&#39;)
 |      2018-09-15 01:30:00+02:00    1
 |      dtype: int64
 |      
 |      Pass None to convert to tz-naive index and preserve local time:
 |      
 |      &gt;&gt;&gt; s = pd.Series([1],
 |      ...     index=pd.DatetimeIndex([&#39;2018-09-15 01:30:00+02:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(None)
 |      2018-09-15 01:30:00    1
 |      dtype: int64
 |      
 |      Be careful with DST changes. When there is sequential data, pandas
 |      can infer the DST time:
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(7),
 |      ...               index=pd.DatetimeIndex([&#39;2018-10-28 01:30:00&#39;,
 |      ...                                       &#39;2018-10-28 02:00:00&#39;,
 |      ...                                       &#39;2018-10-28 02:30:00&#39;,
 |      ...                                       &#39;2018-10-28 02:00:00&#39;,
 |      ...                                       &#39;2018-10-28 02:30:00&#39;,
 |      ...                                       &#39;2018-10-28 03:00:00&#39;,
 |      ...                                       &#39;2018-10-28 03:30:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;CET&#39;, ambiguous=&#39;infer&#39;)
 |      2018-10-28 01:30:00+02:00    0
 |      2018-10-28 02:00:00+02:00    1
 |      2018-10-28 02:30:00+02:00    2
 |      2018-10-28 02:00:00+01:00    3
 |      2018-10-28 02:30:00+01:00    4
 |      2018-10-28 03:00:00+01:00    5
 |      2018-10-28 03:30:00+01:00    6
 |      dtype: int64
 |      
 |      In some cases, inferring the DST is impossible. In such cases, you can
 |      pass an ndarray to the ambiguous parameter to set the DST explicitly
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(3),
 |      ...               index=pd.DatetimeIndex([&#39;2018-10-28 01:20:00&#39;,
 |      ...                                       &#39;2018-10-28 02:36:00&#39;,
 |      ...                                       &#39;2018-10-28 03:46:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;CET&#39;, ambiguous=np.array([True, True, False]))
 |      2018-10-28 01:20:00+02:00    0
 |      2018-10-28 02:36:00+02:00    1
 |      2018-10-28 03:46:00+01:00    2
 |      dtype: int64
 |      
 |      If the DST transition causes nonexistent times, you can shift these
 |      dates forward or backward with a timedelta object or `&#39;shift_forward&#39;`
 |      or `&#39;shift_backward&#39;`.
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(2),
 |      ...               index=pd.DatetimeIndex([&#39;2015-03-29 02:30:00&#39;,
 |      ...                                       &#39;2015-03-29 03:30:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;Europe/Warsaw&#39;, nonexistent=&#39;shift_forward&#39;)
 |      2015-03-29 03:00:00+02:00    0
 |      2015-03-29 03:30:00+02:00    1
 |      dtype: int64
 |      &gt;&gt;&gt; s.tz_localize(&#39;Europe/Warsaw&#39;, nonexistent=&#39;shift_backward&#39;)
 |      2015-03-29 01:59:59.999999999+01:00    0
 |      2015-03-29 03:30:00+02:00              1
 |      dtype: int64
 |      &gt;&gt;&gt; s.tz_localize(&#39;Europe/Warsaw&#39;, nonexistent=pd.Timedelta(&#39;1H&#39;))
 |      2015-03-29 03:30:00+02:00    0
 |      2015-03-29 03:30:00+02:00    1
 |      dtype: int64
 |  
 |  xs(self: &#39;NDFrameT&#39;, key: &#39;IndexLabel&#39;, axis: &#39;Axis&#39; = 0, level: &#39;IndexLabel&#39; = None, drop_level: &#39;bool_t&#39; = True) -&gt; &#39;NDFrameT&#39;
 |      Return cross-section from the Series/DataFrame.
 |      
 |      This method takes a `key` argument to select data at a particular
 |      level of a MultiIndex.
 |      
 |      Parameters
 |      ----------
 |      key : label or tuple of label
 |          Label contained in the index, or partially in a MultiIndex.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Axis to retrieve cross-section on.
 |      level : object, defaults to first n levels (n=1 or len(key))
 |          In case of a key partially contained in a MultiIndex, indicate
 |          which levels are used. Levels can be referred by label or position.
 |      drop_level : bool, default True
 |          If False, returns object with same levels as self.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Cross-section from the original Series or DataFrame
 |          corresponding to the selected index levels.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Access a group of rows and columns
 |          by label(s) or a boolean array.
 |      DataFrame.iloc : Purely integer-location based indexing
 |          for selection by position.
 |      
 |      Notes
 |      -----
 |      `xs` can not be used to set values.
 |      
 |      MultiIndex Slicers is a generic way to get/set values on
 |      any level or levels.
 |      It is a superset of `xs` functionality, see
 |      :ref:`MultiIndex Slicers &lt;advanced.mi_slicers&gt;`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; d = {&#39;num_legs&#39;: [4, 4, 2, 2],
 |      ...      &#39;num_wings&#39;: [0, 0, 2, 2],
 |      ...      &#39;class&#39;: [&#39;mammal&#39;, &#39;mammal&#39;, &#39;mammal&#39;, &#39;bird&#39;],
 |      ...      &#39;animal&#39;: [&#39;cat&#39;, &#39;dog&#39;, &#39;bat&#39;, &#39;penguin&#39;],
 |      ...      &#39;locomotion&#39;: [&#39;walks&#39;, &#39;walks&#39;, &#39;flies&#39;, &#39;walks&#39;]}
 |      &gt;&gt;&gt; df = pd.DataFrame(data=d)
 |      &gt;&gt;&gt; df = df.set_index([&#39;class&#39;, &#39;animal&#39;, &#39;locomotion&#39;])
 |      &gt;&gt;&gt; df
 |                                 num_legs  num_wings
 |      class  animal  locomotion
 |      mammal cat     walks              4          0
 |             dog     walks              4          0
 |             bat     flies              2          2
 |      bird   penguin walks              2          2
 |      
 |      Get values at specified index
 |      
 |      &gt;&gt;&gt; df.xs(&#39;mammal&#39;)
 |                         num_legs  num_wings
 |      animal locomotion
 |      cat    walks              4          0
 |      dog    walks              4          0
 |      bat    flies              2          2
 |      
 |      Get values at several indexes
 |      
 |      &gt;&gt;&gt; df.xs((&#39;mammal&#39;, &#39;dog&#39;, &#39;walks&#39;))
 |      num_legs     4
 |      num_wings    0
 |      Name: (mammal, dog, walks), dtype: int64
 |      
 |      Get values at specified index and level
 |      
 |      &gt;&gt;&gt; df.xs(&#39;cat&#39;, level=1)
 |                         num_legs  num_wings
 |      class  locomotion
 |      mammal walks              4          0
 |      
 |      Get values at several indexes and levels
 |      
 |      &gt;&gt;&gt; df.xs((&#39;bird&#39;, &#39;walks&#39;),
 |      ...       level=[0, &#39;locomotion&#39;])
 |               num_legs  num_wings
 |      animal
 |      penguin         2          2
 |      
 |      Get values at specified column and axis
 |      
 |      &gt;&gt;&gt; df.xs(&#39;num_wings&#39;, axis=1)
 |      class   animal   locomotion
 |      mammal  cat      walks         0
 |              dog      walks         0
 |              bat      flies         2
 |      bird    penguin  walks         2
 |      Name: num_wings, dtype: int64
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pandas.core.generic.NDFrame:
 |  
 |  flags
 |      Get the properties associated with this pandas object.
 |      
 |      The available flags are
 |      
 |      * :attr:`Flags.allows_duplicate_labels`
 |      
 |      See Also
 |      --------
 |      Flags : Flags that apply to pandas objects.
 |      DataFrame.attrs : Global metadata applying to this dataset.
 |      
 |      Notes
 |      -----
 |      &quot;Flags&quot; differ from &quot;metadata&quot;. Flags reflect properties of the
 |      pandas object (the Series or DataFrame). Metadata refer to properties
 |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2]})
 |      &gt;&gt;&gt; df.flags
 |      &lt;Flags(allows_duplicate_labels=True)&gt;
 |      
 |      Flags can be get or set using ``.``
 |      
 |      &gt;&gt;&gt; df.flags.allows_duplicate_labels
 |      True
 |      &gt;&gt;&gt; df.flags.allows_duplicate_labels = False
 |      
 |      Or by slicing with a key
 |      
 |      &gt;&gt;&gt; df.flags[&quot;allows_duplicate_labels&quot;]
 |      False
 |      &gt;&gt;&gt; df.flags[&quot;allows_duplicate_labels&quot;] = True
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pandas.core.generic.NDFrame:
 |  
 |  attrs
 |      Dictionary of global attributes of this dataset.
 |      
 |      .. warning::
 |      
 |         attrs is experimental and may change without warning.
 |      
 |      See Also
 |      --------
 |      DataFrame.flags : Global flags applying to this object.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.base.PandasObject:
 |  
 |  __sizeof__(self) -&gt; &#39;int&#39;
 |      Generates the total memory usage for an object that returns
 |      either a value or Series of values
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.accessor.DirNamesMixin:
 |  
 |  __dir__(self) -&gt; &#39;list[str]&#39;
 |      Provide method name lookup and completion.
 |      
 |      Notes
 |      -----
 |      Only provide &#39;public&#39; methods.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:
 |  
 |  at
 |      Access a single value for a row/column label pair.
 |      
 |      Similar to ``loc``, in that both provide label-based lookups. Use
 |      ``at`` if you only need to get or set a single value in a DataFrame
 |      or Series.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          * If getting a value and &#39;label&#39; does not exist in a DataFrame or
 |              Series.
 |      ValueError
 |          * If row/column label pair is not a tuple or if any label from
 |              the pair is not a scalar for DataFrame.
 |          * If label is list-like (*excluding* NamedTuple) for Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.at : Access a single value for a row/column pair by label.
 |      DataFrame.iat : Access a single value for a row/column pair by integer
 |          position.
 |      DataFrame.loc : Access a group of rows and columns by label(s).
 |      DataFrame.iloc : Access a group of rows and columns by integer
 |          position(s).
 |      Series.at : Access a single value by label.
 |      Series.iat : Access a single value by integer position.
 |      Series.loc : Access a group of rows by label(s).
 |      Series.iloc : Access a group of rows by integer position(s).
 |      
 |      Notes
 |      -----
 |      See :ref:`Fast scalar value getting and setting &lt;indexing.basics.get_value&gt;`
 |      for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
 |      ...                   index=[4, 5, 6], columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |          A   B   C
 |      4   0   2   3
 |      5   0   4   1
 |      6  10  20  30
 |      
 |      Get value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.at[4, &#39;B&#39;]
 |      2
 |      
 |      Set value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.at[4, &#39;B&#39;] = 10
 |      &gt;&gt;&gt; df.at[4, &#39;B&#39;]
 |      10
 |      
 |      Get value within a Series
 |      
 |      &gt;&gt;&gt; df.loc[5].at[&#39;B&#39;]
 |      4
 |  
 |  iat
 |      Access a single value for a row/column pair by integer position.
 |      
 |      Similar to ``iloc``, in that both provide integer-based lookups. Use
 |      ``iat`` if you only need to get or set a single value in a DataFrame
 |      or Series.
 |      
 |      Raises
 |      ------
 |      IndexError
 |          When integer position is out of bounds.
 |      
 |      See Also
 |      --------
 |      DataFrame.at : Access a single value for a row/column label pair.
 |      DataFrame.loc : Access a group of rows and columns by label(s).
 |      DataFrame.iloc : Access a group of rows and columns by integer position(s).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
 |      ...                   columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |          A   B   C
 |      0   0   2   3
 |      1   0   4   1
 |      2  10  20  30
 |      
 |      Get value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.iat[1, 2]
 |      1
 |      
 |      Set value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.iat[1, 2] = 10
 |      &gt;&gt;&gt; df.iat[1, 2]
 |      10
 |      
 |      Get value within a series
 |      
 |      &gt;&gt;&gt; df.loc[0].iat[1]
 |      2
 |  
 |  iloc
 |      Purely integer-location based indexing for selection by position.
 |      
 |      ``.iloc[]`` is primarily integer position based (from ``0`` to
 |      ``length-1`` of the axis), but may also be used with a boolean
 |      array.
 |      
 |      Allowed inputs are:
 |      
 |      - An integer, e.g. ``5``.
 |      - A list or array of integers, e.g. ``[4, 3, 0]``.
 |      - A slice object with ints, e.g. ``1:7``.
 |      - A boolean array.
 |      - A ``callable`` function with one argument (the calling Series or
 |        DataFrame) and that returns valid output for indexing (one of the above).
 |        This is useful in method chains, when you don&#39;t have a reference to the
 |        calling object, but would like to base your selection on some value.
 |      - A tuple of row and column indexes. The tuple elements consist of one of the
 |        above inputs, e.g. ``(0, 1)``.
 |      
 |      ``.iloc`` will raise ``IndexError`` if a requested indexer is
 |      out-of-bounds, except *slice* indexers which allow out-of-bounds
 |      indexing (this conforms with python/numpy *slice* semantics).
 |      
 |      See more at :ref:`Selection by Position &lt;indexing.integer&gt;`.
 |      
 |      See Also
 |      --------
 |      DataFrame.iat : Fast integer location scalar accessor.
 |      DataFrame.loc : Purely label-location based indexer for selection by label.
 |      Series.iloc : Purely integer-location based indexing for
 |                     selection by position.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; mydict = [{&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4},
 |      ...           {&#39;a&#39;: 100, &#39;b&#39;: 200, &#39;c&#39;: 300, &#39;d&#39;: 400},
 |      ...           {&#39;a&#39;: 1000, &#39;b&#39;: 2000, &#39;c&#39;: 3000, &#39;d&#39;: 4000 }]
 |      &gt;&gt;&gt; df = pd.DataFrame(mydict)
 |      &gt;&gt;&gt; df
 |            a     b     c     d
 |      0     1     2     3     4
 |      1   100   200   300   400
 |      2  1000  2000  3000  4000
 |      
 |      **Indexing just the rows**
 |      
 |      With a scalar integer.
 |      
 |      &gt;&gt;&gt; type(df.iloc[0])
 |      &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      &gt;&gt;&gt; df.iloc[0]
 |      a    1
 |      b    2
 |      c    3
 |      d    4
 |      Name: 0, dtype: int64
 |      
 |      With a list of integers.
 |      
 |      &gt;&gt;&gt; df.iloc[[0]]
 |         a  b  c  d
 |      0  1  2  3  4
 |      &gt;&gt;&gt; type(df.iloc[[0]])
 |      &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
 |      
 |      &gt;&gt;&gt; df.iloc[[0, 1]]
 |           a    b    c    d
 |      0    1    2    3    4
 |      1  100  200  300  400
 |      
 |      With a `slice` object.
 |      
 |      &gt;&gt;&gt; df.iloc[:3]
 |            a     b     c     d
 |      0     1     2     3     4
 |      1   100   200   300   400
 |      2  1000  2000  3000  4000
 |      
 |      With a boolean mask the same length as the index.
 |      
 |      &gt;&gt;&gt; df.iloc[[True, False, True]]
 |            a     b     c     d
 |      0     1     2     3     4
 |      2  1000  2000  3000  4000
 |      
 |      With a callable, useful in method chains. The `x` passed
 |      to the ``lambda`` is the DataFrame being sliced. This selects
 |      the rows whose index label even.
 |      
 |      &gt;&gt;&gt; df.iloc[lambda x: x.index % 2 == 0]
 |            a     b     c     d
 |      0     1     2     3     4
 |      2  1000  2000  3000  4000
 |      
 |      **Indexing both axes**
 |      
 |      You can mix the indexer types for the index and columns. Use ``:`` to
 |      select the entire axis.
 |      
 |      With scalar integers.
 |      
 |      &gt;&gt;&gt; df.iloc[0, 1]
 |      2
 |      
 |      With lists of integers.
 |      
 |      &gt;&gt;&gt; df.iloc[[0, 2], [1, 3]]
 |            b     d
 |      0     2     4
 |      2  2000  4000
 |      
 |      With `slice` objects.
 |      
 |      &gt;&gt;&gt; df.iloc[1:3, 0:3]
 |            a     b     c
 |      1   100   200   300
 |      2  1000  2000  3000
 |      
 |      With a boolean array whose length matches the columns.
 |      
 |      &gt;&gt;&gt; df.iloc[:, [True, False, True, False]]
 |            a     c
 |      0     1     3
 |      1   100   300
 |      2  1000  3000
 |      
 |      With a callable function that expects the Series or DataFrame.
 |      
 |      &gt;&gt;&gt; df.iloc[:, lambda df: [0, 2]]
 |            a     c
 |      0     1     3
 |      1   100   300
 |      2  1000  3000
 |  
 |  loc
 |      Access a group of rows and columns by label(s) or a boolean array.
 |      
 |      ``.loc[]`` is primarily label based, but may also be used with a
 |      boolean array.
 |      
 |      Allowed inputs are:
 |      
 |      - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
 |        interpreted as a *label* of the index, and **never** as an
 |        integer position along the index).
 |      - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
 |      - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;``.
 |      
 |        .. warning:: Note that contrary to usual python slices, **both** the
 |            start and the stop are included
 |      
 |      - A boolean array of the same length as the axis being sliced,
 |        e.g. ``[True, False, True]``.
 |      - An alignable boolean Series. The index of the key will be aligned before
 |        masking.
 |      - An alignable Index. The Index of the returned selection will be the input.
 |      - A ``callable`` function with one argument (the calling Series or
 |        DataFrame) and that returns valid output for indexing (one of the above)
 |      
 |      See more at :ref:`Selection by Label &lt;indexing.label&gt;`.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          If any items are not found.
 |      IndexingError
 |          If an indexed key is passed and its index is unalignable to the frame index.
 |      
 |      See Also
 |      --------
 |      DataFrame.at : Access a single value for a row/column label pair.
 |      DataFrame.iloc : Access group of rows and columns by integer position(s).
 |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the
 |          Series/DataFrame.
 |      Series.loc : Access group of values using labels.
 |      
 |      Examples
 |      --------
 |      **Getting values**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
 |      ...      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
 |      ...      columns=[&#39;max_speed&#39;, &#39;shield&#39;])
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra               1       2
 |      viper               4       5
 |      sidewinder          7       8
 |      
 |      Single label. Note this returns the row as a Series.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;viper&#39;]
 |      max_speed    4
 |      shield       5
 |      Name: viper, dtype: int64
 |      
 |      List of labels. Note using ``[[]]`` returns a DataFrame.
 |      
 |      &gt;&gt;&gt; df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;]]
 |                  max_speed  shield
 |      viper               4       5
 |      sidewinder          7       8
 |      
 |      Single label for row and column
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;, &#39;shield&#39;]
 |      2
 |      
 |      Slice with labels for row and single label for column. As mentioned
 |      above, note that both the start and stop of the slice are included.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;:&#39;viper&#39;, &#39;max_speed&#39;]
 |      cobra    1
 |      viper    4
 |      Name: max_speed, dtype: int64
 |      
 |      Boolean list with the same length as the row axis
 |      
 |      &gt;&gt;&gt; df.loc[[False, False, True]]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      Alignable boolean Series:
 |      
 |      &gt;&gt;&gt; df.loc[pd.Series([False, True, False],
 |      ...        index=[&#39;viper&#39;, &#39;sidewinder&#39;, &#39;cobra&#39;])]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      Index (same behavior as ``df.reindex``)
 |      
 |      &gt;&gt;&gt; df.loc[pd.Index([&quot;cobra&quot;, &quot;viper&quot;], name=&quot;foo&quot;)]
 |             max_speed  shield
 |      foo
 |      cobra          1       2
 |      viper          4       5
 |      
 |      Conditional that returns a boolean Series
 |      
 |      &gt;&gt;&gt; df.loc[df[&#39;shield&#39;] &gt; 6]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      Conditional that returns a boolean Series with column labels specified
 |      
 |      &gt;&gt;&gt; df.loc[df[&#39;shield&#39;] &gt; 6, [&#39;max_speed&#39;]]
 |                  max_speed
 |      sidewinder          7
 |      
 |      Callable that returns a boolean Series
 |      
 |      &gt;&gt;&gt; df.loc[lambda df: df[&#39;shield&#39;] == 8]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      **Setting values**
 |      
 |      Set value for all items matching the list of labels
 |      
 |      &gt;&gt;&gt; df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;], [&#39;shield&#39;]] = 50
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra               1       2
 |      viper               4      50
 |      sidewinder          7      50
 |      
 |      Set value for an entire row
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;] = 10
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra              10      10
 |      viper               4      50
 |      sidewinder          7      50
 |      
 |      Set value for an entire column
 |      
 |      &gt;&gt;&gt; df.loc[:, &#39;max_speed&#39;] = 30
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra              30      10
 |      viper              30      50
 |      sidewinder         30      50
 |      
 |      Set value for rows matching callable condition
 |      
 |      &gt;&gt;&gt; df.loc[df[&#39;shield&#39;] &gt; 35] = 0
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra              30      10
 |      viper               0       0
 |      sidewinder          0       0
 |      
 |      **Getting values on a DataFrame with an index that has integer labels**
 |      
 |      Another example using integers for the index
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
 |      ...      index=[7, 8, 9], columns=[&#39;max_speed&#39;, &#39;shield&#39;])
 |      &gt;&gt;&gt; df
 |         max_speed  shield
 |      7          1       2
 |      8          4       5
 |      9          7       8
 |      
 |      Slice with integer labels for rows. As mentioned above, note that both
 |      the start and stop of the slice are included.
 |      
 |      &gt;&gt;&gt; df.loc[7:9]
 |         max_speed  shield
 |      7          1       2
 |      8          4       5
 |      9          7       8
 |      
 |      **Getting values with a MultiIndex**
 |      
 |      A number of examples using a DataFrame with a MultiIndex
 |      
 |      &gt;&gt;&gt; tuples = [
 |      ...    (&#39;cobra&#39;, &#39;mark i&#39;), (&#39;cobra&#39;, &#39;mark ii&#39;),
 |      ...    (&#39;sidewinder&#39;, &#39;mark i&#39;), (&#39;sidewinder&#39;, &#39;mark ii&#39;),
 |      ...    (&#39;viper&#39;, &#39;mark ii&#39;), (&#39;viper&#39;, &#39;mark iii&#39;)
 |      ... ]
 |      &gt;&gt;&gt; index = pd.MultiIndex.from_tuples(tuples)
 |      &gt;&gt;&gt; values = [[12, 2], [0, 4], [10, 20],
 |      ...         [1, 4], [7, 1], [16, 36]]
 |      &gt;&gt;&gt; df = pd.DataFrame(values, columns=[&#39;max_speed&#39;, &#39;shield&#39;], index=index)
 |      &gt;&gt;&gt; df
 |                           max_speed  shield
 |      cobra      mark i           12       2
 |                 mark ii           0       4
 |      sidewinder mark i           10      20
 |                 mark ii           1       4
 |      viper      mark ii           7       1
 |                 mark iii         16      36
 |      
 |      Single label. Note this returns a DataFrame with a single index.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;]
 |               max_speed  shield
 |      mark i          12       2
 |      mark ii          0       4
 |      
 |      Single index tuple. Note this returns a Series.
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark ii&#39;)]
 |      max_speed    0
 |      shield       4
 |      Name: (cobra, mark ii), dtype: int64
 |      
 |      Single label for row and column. Similar to passing in a tuple, this
 |      returns a Series.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;, &#39;mark i&#39;]
 |      max_speed    12
 |      shield        2
 |      Name: (cobra, mark i), dtype: int64
 |      
 |      Single tuple. Note using ``[[]]`` returns a DataFrame.
 |      
 |      &gt;&gt;&gt; df.loc[[(&#39;cobra&#39;, &#39;mark ii&#39;)]]
 |                     max_speed  shield
 |      cobra mark ii          0       4
 |      
 |      Single tuple for the index with a single label for the column
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark i&#39;), &#39;shield&#39;]
 |      2
 |      
 |      Slice from index tuple to single label
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):&#39;viper&#39;]
 |                           max_speed  shield
 |      cobra      mark i           12       2
 |                 mark ii           0       4
 |      sidewinder mark i           10      20
 |                 mark ii           1       4
 |      viper      mark ii           7       1
 |                 mark iii         16      36
 |      
 |      Slice from index tuple to index tuple
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):(&#39;viper&#39;, &#39;mark ii&#39;)]
 |                          max_speed  shield
 |      cobra      mark i          12       2
 |                 mark ii          0       4
 |      sidewinder mark i          10      20
 |                 mark ii          1       4
 |      viper      mark ii          7       1
 |      
 |      Please see the :ref:`user guide&lt;advanced.advanced_hierarchical&gt;`
 |      for more details and explanations of advanced indexing.
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="70">
<div class="sourceCode" id="cb30"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>1.100561</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>-1.032715</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>1.845914</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode" id="cb31"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>df.iloc[<span class="dv">2</span>:, <span class="dv">1</span>]<span class="op">=</span> np.nan   <span class="co">#all rows from third onwards, second column</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>NaN</td>
<td>-0.328430</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>NaN</td>
<td>0.157982</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>NaN</td>
<td>-0.172841</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode" id="cb32"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>df.iloc[<span class="dv">4</span>:, <span class="dv">2</span>] <span class="op">=</span> np.nan</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>NaN</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode" id="cb33"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>df.fillna(method <span class="op">=</span> <span class="st">&quot;ffill&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode" id="cb34"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>df.fillna({<span class="dv">1</span>:<span class="fl">0.5</span>})</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>0.5</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>0.5</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>0.5</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>0.5</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>0.5</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>0.5</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>0.5</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode" id="cb35"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>df.fillna(method<span class="op">=</span><span class="st">&#39;ffill&#39;</span>, limit<span class="op">=</span><span class="dv">2</span>) <span class="co"># 2 values of third column gets filled</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.716945</td>
<td>NaN</td>
<td>0.198477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.815565</td>
<td>NaN</td>
<td>-1.749359</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.073905</td>
<td>NaN</td>
<td>0.826025</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.122968</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.037637</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>-0.077328</td>
<td>NaN</td>
<td>0.932057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0.363370</td>
<td>NaN</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="imputations-with-fillna" class="level2">
<h2>imputations with fillna()</h2>
<ul>
<li>fucntion arguments (value, method, axis, limit)</li>
</ul>
<div class="cell" data-execution_count="83">
<div class="sourceCode" id="cb36"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># imputations with fillna</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.Series([<span class="fl">1.</span>, np.nan, <span class="fl">3.5</span>, np.nan, <span class="dv">7</span>])</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>0    1.0
1    NaN
2    3.5
3    NaN
4    7.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode" id="cb38"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>data.fillna(data.mean())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>0    1.000000
1    3.833333
2    3.500000
3    3.833333
4    7.000000
dtype: float64</code></pre>
</div>
</div>
</section>
<section id="data-transformation-1" class="level1">
<h1>Data Transformation</h1>
<section id="removing-duplicates" class="level2">
<h2>Removing duplicates</h2>
<div class="cell" data-execution_count="90">
<div class="sourceCode" id="cb40"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">&quot;k1&quot;</span>:[<span class="st">&#39;one&#39;</span>, <span class="st">&#39;two&#39;</span>]<span class="op">*</span> <span class="dv">3</span> <span class="op">+</span> [<span class="st">&#39;two&#39;</span>],</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;k2&quot;</span>: [<span class="dv">1</span>, <span class="dv">22</span>, <span class="dv">1</span>, <span class="dv">22</span>, <span class="dv">3</span>, <span class="dv">22</span>, <span class="dv">3</span>,]})</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">k1</th>
<th data-quarto-table-cell-role="th">k2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>one</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>two</td>
<td>22</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>one</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>two</td>
<td>22</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>one</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>two</td>
<td>22</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>two</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode" id="cb41"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>data.duplicated()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>0    False
1    False
2     True
3     True
4    False
5     True
6    False
dtype: bool</code></pre>
</div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode" id="cb43"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>data.drop_duplicates()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">k1</th>
<th data-quarto-table-cell-role="th">k2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>one</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>two</td>
<td>22</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>one</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>two</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode" id="cb44"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># removing duplicates based on column</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;k3&#39;</span>] <span class="op">=</span> <span class="bu">range</span>(<span class="dv">7</span>)   <span class="co"># adding column</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode" id="cb45"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">k1</th>
<th data-quarto-table-cell-role="th">k2</th>
<th data-quarto-table-cell-role="th">k3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>one</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>two</td>
<td>22</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>one</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>two</td>
<td>22</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>one</td>
<td>3</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>two</td>
<td>22</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>two</td>
<td>3</td>
<td>6</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="98">
<div class="sourceCode" id="cb46"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>data.drop_duplicates(subset<span class="op">=</span>[<span class="st">&quot;k1&quot;</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">k1</th>
<th data-quarto-table-cell-role="th">k2</th>
<th data-quarto-table-cell-role="th">k3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>one</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>two</td>
<td>22</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="transforming-data-using-a-function-or-mapping" class="level2">
<h2>Transforming data using a Function or mapping</h2>
<div class="cell" data-execution_count="99">
<div class="sourceCode" id="cb47"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">&#39;food&#39;</span>: [<span class="st">&#39;poisson&#39;</span>, <span class="st">&#39;boeuf&#39;</span>, <span class="st">&#39;mouton&#39;</span>, <span class="st">&#39;bacon&#39;</span>, <span class="st">&#39;poulet&#39;</span>],</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>                     <span class="st">&#39;quantité - ounces&#39;</span> : [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>]})</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">food</th>
<th data-quarto-table-cell-role="th">quantité - ounces</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>poisson</td>
<td>4</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>boeuf</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>mouton</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>bacon</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>poulet</td>
<td>2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="106">
<div class="sourceCode" id="cb48"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># writing animal names in english alongside</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>meat_of_animal <span class="op">=</span> {<span class="st">&#39;poisson&#39;</span>: <span class="st">&#39;fish&#39;</span>,</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&#39;boeuf&#39;</span> : <span class="st">&#39;beef&#39;</span>,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&#39;mouton&#39;</span> : <span class="st">&#39;sheep&#39;</span>,</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&#39;bacon&#39;</span>: <span class="st">&#39;pig&#39;</span>,</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&#39;poulet&#39;</span>: <span class="st">&#39;chicken&#39;</span>}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="107">
<div class="sourceCode" id="cb49"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;english&#39;</span>] <span class="op">=</span> data[<span class="st">&#39;food&#39;</span>].<span class="bu">map</span>(meat_of_animal)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="108">
<div class="sourceCode" id="cb50"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">food</th>
<th data-quarto-table-cell-role="th">quantité - ounces</th>
<th data-quarto-table-cell-role="th">english</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>poisson</td>
<td>4</td>
<td>fish</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>boeuf</td>
<td>5</td>
<td>beef</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>mouton</td>
<td>3</td>
<td>sheep</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>bacon</td>
<td>4</td>
<td>pig</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>poulet</td>
<td>2</td>
<td>chicken</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="110">
<div class="sourceCode" id="cb51"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># creating a function for the same and using map() </span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> animal_english (x):</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> meat_of_animal[x]</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;food&#39;</span>].<span class="bu">map</span>(animal_english)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>0       fish
1       beef
2      sheep
3        pig
4    chicken
Name: food, dtype: object</code></pre>
</div>
</div>
</section>
<section id="replacing-values" class="level2">
<h2>Replacing values</h2>
<div class="cell" data-execution_count="111">
<div class="sourceCode" id="cb53"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="111">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">food</th>
<th data-quarto-table-cell-role="th">quantité - ounces</th>
<th data-quarto-table-cell-role="th">english</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>poisson</td>
<td>4</td>
<td>fish</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>boeuf</td>
<td>5</td>
<td>beef</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>mouton</td>
<td>3</td>
<td>sheep</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>bacon</td>
<td>4</td>
<td>pig</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>poulet</td>
<td>2</td>
<td>chicken</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="112">
<div class="sourceCode" id="cb54"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>data2 <span class="op">=</span> pd.Series([<span class="fl">1.</span>, <span class="op">-</span> <span class="dv">323</span>, <span class="op">-</span><span class="fl">.32</span> , <span class="fl">4.</span>])</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>data2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>0      1.00
1   -323.00
2     -0.32
3      4.00
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="113">
<div class="sourceCode" id="cb56"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>data2.replace(<span class="op">-</span><span class="dv">323</span>, np.nan)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>0    1.00
1     NaN
2   -0.32
3    4.00
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="115">
<div class="sourceCode" id="cb58"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># replacing multiple values</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>data2.replace([<span class="op">-</span><span class="dv">323</span>, <span class="op">-</span><span class="fl">.32</span>], np.nan)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="115">
<pre><code>0    1.0
1    NaN
2    NaN
3    4.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="116">
<div class="sourceCode" id="cb60"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using different replacement values for different substitutes</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>data2.replace([<span class="op">-</span><span class="dv">323</span>, <span class="op">-</span><span class="fl">.32</span>], [np.nan, <span class="dv">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="116">
<pre><code>0    1.0
1    NaN
2    0.0
3    4.0
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="117">
<div class="sourceCode" id="cb62"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># argument passed can alse be a dictionary</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>data2.replace({<span class="op">-</span><span class="dv">323</span>: np.nan, <span class="op">-</span><span class="fl">.32</span>:<span class="dv">55555</span>})</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="117">
<pre><code>0        1.0
1        NaN
2    55555.0
3        4.0
dtype: float64</code></pre>
</div>
</div>
</section>
<section id="renaming-axis-indexes" class="level2">
<h2>Renaming Axis indexes</h2>
<div class="cell" data-execution_count="118">
<div class="sourceCode" id="cb64"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">food</th>
<th data-quarto-table-cell-role="th">quantité - ounces</th>
<th data-quarto-table-cell-role="th">english</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>poisson</td>
<td>4</td>
<td>fish</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>boeuf</td>
<td>5</td>
<td>beef</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>mouton</td>
<td>3</td>
<td>sheep</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>bacon</td>
<td>4</td>
<td>pig</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>poulet</td>
<td>2</td>
<td>chicken</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode" id="cb65"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># transforming first four letters of column</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform(x):</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x[:<span class="dv">5</span>].upper()</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>data.columns.<span class="bu">map</span>(transform)  </span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<pre><code>Index([&#39;FOOD&#39;, &#39;QUANT&#39;, &#39;ENGLI&#39;], dtype=&#39;object&#39;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="129">
<div class="sourceCode" id="cb67"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># changing the titles of the DataFrame</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>data.columns <span class="op">=</span> data.columns.<span class="bu">map</span>(transform)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">FOOD</th>
<th data-quarto-table-cell-role="th">QUANT</th>
<th data-quarto-table-cell-role="th">ENGLI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>poisson</td>
<td>4</td>
<td>fish</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>boeuf</td>
<td>5</td>
<td>beef</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>mouton</td>
<td>3</td>
<td>sheep</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>bacon</td>
<td>4</td>
<td>pig</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>poulet</td>
<td>2</td>
<td>chicken</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="131">
<div class="sourceCode" id="cb68"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tranformed version of dataset without modifying the orignal</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>data.rename(columns <span class="op">=</span> <span class="bu">str</span>.lower)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">food</th>
<th data-quarto-table-cell-role="th">quant</th>
<th data-quarto-table-cell-role="th">engli</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>poisson</td>
<td>4</td>
<td>fish</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>boeuf</td>
<td>5</td>
<td>beef</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>mouton</td>
<td>3</td>
<td>sheep</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>bacon</td>
<td>4</td>
<td>pig</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>poulet</td>
<td>2</td>
<td>chicken</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="discretization-and-binning" class="level2">
<h2>Discretization and Binning</h2>
<ul>
<li>pandas.cut</li>
<li>pandas.value_counts</li>
</ul>
<div class="cell" data-execution_count="132">
<div class="sourceCode" id="cb69"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>ages <span class="op">=</span> [<span class="dv">21</span>, <span class="dv">33</span>, <span class="dv">12</span>, <span class="dv">33</span>, <span class="dv">32</span>, <span class="dv">21</span>, <span class="dv">44</span>, <span class="dv">55</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="133">
<div class="sourceCode" id="cb70"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> [<span class="dv">12</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">100</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="134">
<div class="sourceCode" id="cb71"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>age_categories <span class="op">=</span> pd.cut(ages, bins)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode" id="cb72"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>age_categories</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="135">
<pre><code>[(12.0, 30.0], (30.0, 40.0], NaN, (30.0, 40.0], (30.0, 40.0], (12.0, 30.0], (40.0, 50.0], (50.0, 60.0]]
Categories (6, interval[int64, right]): [(12, 30] &lt; (30, 40] &lt; (40, 50] &lt; (50, 60] &lt; (60, 70] &lt; (70, 100]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="136">
<div class="sourceCode" id="cb74"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>pd.value_counts(age_categories)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>(30, 40]     3
(12, 30]     2
(40, 50]     1
(50, 60]     1
(60, 70]     0
(70, 100]    0
Name: count, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="137">
<div class="sourceCode" id="cb76"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(pd.value_counts)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on function value_counts in module pandas.core.algorithms:

value_counts(values, sort: &#39;bool&#39; = True, ascending: &#39;bool&#39; = False, normalize: &#39;bool&#39; = False, bins=None, dropna: &#39;bool&#39; = True) -&gt; &#39;Series&#39;
    Compute a histogram of the counts of non-null values.
    
    Parameters
    ----------
    values : ndarray (1-d)
    sort : bool, default True
        Sort by values
    ascending : bool, default False
        Sort in ascending order
    normalize: bool, default False
        If True then compute a relative histogram
    bins : integer, optional
        Rather than count values, group them into half-open bins,
        convenience for pd.cut, only works with numeric data
    dropna : bool, default True
        Don&#39;t include counts of NaN
    
    Returns
    -------
    Series
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode" id="cb78"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># parnethesis is towards open side</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="co"># changing side</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>pd.cut(ages, bins, right<span class="op">=</span> <span class="va">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="141">
<pre><code>[[12, 30), [30, 40), [12, 30), [30, 40), [30, 40), [12, 30), [40, 50), [50, 60)]
Categories (6, interval[int64, left]): [[12, 30) &lt; [30, 40) &lt; [40, 50) &lt; [50, 60) &lt; [60, 70) &lt; [70, 100)]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="142">
<div class="sourceCode" id="cb80"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># changing labels</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>group_names <span class="op">=</span> [<span class="st">&#39;ados&#39;</span>,<span class="st">&#39;youth&#39;</span>, <span class="st">&#39;youngsters&#39;</span>, <span class="st">&#39;midaged&#39;</span>, <span class="st">&#39;senior&#39;</span>, <span class="st">&#39;retired&#39;</span>, ]</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>pd.cut(ages, bins, labels <span class="op">=</span> group_names)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>[&#39;ados&#39;, &#39;youth&#39;, NaN, &#39;youth&#39;, &#39;youth&#39;, &#39;ados&#39;, &#39;youngsters&#39;, &#39;midaged&#39;]
Categories (6, object): [&#39;ados&#39; &lt; &#39;youth&#39; &lt; &#39;youngsters&#39; &lt; &#39;midaged&#39; &lt; &#39;senior&#39; &lt; &#39;retired&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="148">
<div class="sourceCode" id="cb82"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>data3 <span class="op">=</span> np.random.uniform (size <span class="op">=</span> <span class="dv">20</span>)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> pd.cut(data3, <span class="dv">4</span>, precision<span class="op">=</span><span class="dv">2</span>)   <span class="co"># 4 is the number of bins</span></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="co"># precision limits decmical point to two decimal places</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="149">
<div class="sourceCode" id="cb83"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>pd.value_counts(categories)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="149">
<pre><code>(0.011, 0.25]    8
(0.49, 0.73]     6
(0.73, 0.97]     5
(0.25, 0.49]     1
Name: count, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="151">
<div class="sourceCode" id="cb85"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># for equal sized bins</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>categories_1 <span class="op">=</span> pd.qcut(data3, <span class="dv">4</span>, precision <span class="op">=</span> <span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="153">
<div class="sourceCode" id="cb86"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>pd.value_counts(categories_1)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>(0.002, 0.14]    5
(0.14, 0.51]     5
(0.51, 0.69]     5
(0.69, 0.97]     5
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="detecting-and-filtering-outliers" class="level2">
<h2>Detecting and Filtering Outliers</h2>
<div class="cell" data-execution_count="158">
<div class="sourceCode" id="cb88"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>data4 <span class="op">=</span> pd.DataFrame(np.random.standard_normal((<span class="dv">1000</span>, <span class="dv">4</span>)))</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>data4.describe()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="158">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>1000.000000</td>
<td>1000.000000</td>
<td>1000.000000</td>
<td>1000.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>0.016561</td>
<td>-0.031729</td>
<td>0.027078</td>
<td>0.064505</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1.007664</td>
<td>1.047383</td>
<td>1.001156</td>
<td>0.993706</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>-3.592826</td>
<td>-3.066364</td>
<td>-3.149016</td>
<td>-3.644190</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>-0.627244</td>
<td>-0.749349</td>
<td>-0.603733</td>
<td>-0.592056</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>0.046336</td>
<td>-0.056226</td>
<td>0.010209</td>
<td>0.030974</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>0.686210</td>
<td>0.658083</td>
<td>0.737684</td>
<td>0.765335</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>3.262253</td>
<td>3.918947</td>
<td>2.981393</td>
<td>3.029627</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="159">
<div class="sourceCode" id="cb89"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># find values of columns exceeding 3 in absolute value</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> data4[<span class="dv">2</span>]</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>col[col.<span class="bu">abs</span>() <span class="op">&gt;</span> <span class="dv">3</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="159">
<pre><code>614   -3.149016
701   -3.093409
Name: 2, dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="161">
<div class="sourceCode" id="cb91"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting all the columns</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>data4[(data4.<span class="bu">abs</span>() <span class="op">&gt;</span> <span class="dv">3</span>).<span class="bu">any</span>(axis <span class="op">=</span> <span class="st">&#39;columns&#39;</span>)]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="161">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">78</td>
<td>-3.591639</td>
<td>-0.652692</td>
<td>2.002021</td>
<td>-0.233262</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">105</td>
<td>1.620532</td>
<td>3.918947</td>
<td>-0.014565</td>
<td>0.483555</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">178</td>
<td>-0.642515</td>
<td>-3.020820</td>
<td>-1.899087</td>
<td>-0.244327</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">184</td>
<td>-3.592826</td>
<td>-1.979726</td>
<td>0.371343</td>
<td>1.022697</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">240</td>
<td>-0.331648</td>
<td>3.687370</td>
<td>-0.459598</td>
<td>0.994123</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">267</td>
<td>1.236309</td>
<td>-3.066364</td>
<td>-0.132627</td>
<td>0.551233</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">274</td>
<td>-1.350742</td>
<td>3.505783</td>
<td>0.908839</td>
<td>-0.219144</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">306</td>
<td>-0.419746</td>
<td>3.068152</td>
<td>-0.085927</td>
<td>1.446228</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">346</td>
<td>0.174638</td>
<td>3.035741</td>
<td>1.034076</td>
<td>1.208338</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">414</td>
<td>1.224208</td>
<td>3.060689</td>
<td>0.439984</td>
<td>-1.323200</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">433</td>
<td>1.493799</td>
<td>-0.528079</td>
<td>-0.241609</td>
<td>3.029627</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">543</td>
<td>3.262253</td>
<td>-0.713190</td>
<td>0.583197</td>
<td>1.791658</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">614</td>
<td>0.535075</td>
<td>-1.450999</td>
<td>-3.149016</td>
<td>1.604812</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">617</td>
<td>0.240876</td>
<td>-0.628409</td>
<td>0.151670</td>
<td>-3.455415</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">701</td>
<td>-0.618249</td>
<td>0.618510</td>
<td>-3.093409</td>
<td>1.118688</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">817</td>
<td>-0.376220</td>
<td>-0.653628</td>
<td>-1.408788</td>
<td>-3.644190</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="166">
<div class="sourceCode" id="cb92"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code to cap values outsite the inteval -3 to 3</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>data4[data4.<span class="bu">abs</span>() <span class="op">&gt;</span> <span class="dv">3</span>] <span class="op">=</span> np.sign(data4) <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>data4.describe()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="166">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>1000.000000</td>
<td>1000.000000</td>
<td>1000.000000</td>
<td>1000.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>0.017483</td>
<td>-0.033918</td>
<td>0.027320</td>
<td>0.065575</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1.002943</td>
<td>1.039751</td>
<td>1.000406</td>
<td>0.989902</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>-3.000000</td>
<td>-3.000000</td>
<td>-3.000000</td>
<td>-3.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>-0.627244</td>
<td>-0.749349</td>
<td>-0.603733</td>
<td>-0.592056</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>0.046336</td>
<td>-0.056226</td>
<td>0.010209</td>
<td>0.030974</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>0.686210</td>
<td>0.658083</td>
<td>0.737684</td>
<td>0.765335</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>3.000000</td>
<td>3.000000</td>
<td>2.981393</td>
<td>3.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="168">
<div class="sourceCode" id="cb93"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># np.sign(data4) produces 1 and -1 values</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>np.sign(data4).head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="168">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1.0</td>
<td>1.0</td>
<td>-1.0</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>-1.0</td>
<td>-1.0</td>
<td>-1.0</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>1.0</td>
<td>-1.0</td>
<td>-1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>-1.0</td>
<td>1.0</td>
<td>-1.0</td>
<td>-1.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-1.0</td>
<td>-1.0</td>
<td>1.0</td>
<td>-1.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="permutation-and-random-sampling" class="level2">
<h2>Permutation and Random Sampling</h2>
<div class="cell" data-execution_count="172">
<div class="sourceCode" id="cb94"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.DataFrame (np.arange(<span class="dv">5</span><span class="op">*</span><span class="dv">7</span>).reshape(<span class="dv">5</span>,<span class="dv">7</span>))</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>df2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="172">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
<th data-quarto-table-cell-role="th">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
<td>13</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>14</td>
<td>15</td>
<td>16</td>
<td>17</td>
<td>18</td>
<td>19</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>21</td>
<td>22</td>
<td>23</td>
<td>24</td>
<td>25</td>
<td>26</td>
<td>27</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>28</td>
<td>29</td>
<td>30</td>
<td>31</td>
<td>32</td>
<td>33</td>
<td>34</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="174">
<div class="sourceCode" id="cb95"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> np.random.permutation(<span class="dv">5</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>sampler</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="174">
<pre><code>array([4, 1, 2, 0, 3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="175">
<div class="sourceCode" id="cb97"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># take function or &#39;iloc&#39; based indexing</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>df2.take(sampler)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="175">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
<th data-quarto-table-cell-role="th">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>28</td>
<td>29</td>
<td>30</td>
<td>31</td>
<td>32</td>
<td>33</td>
<td>34</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
<td>13</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>14</td>
<td>15</td>
<td>16</td>
<td>17</td>
<td>18</td>
<td>19</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>21</td>
<td>22</td>
<td>23</td>
<td>24</td>
<td>25</td>
<td>26</td>
<td>27</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="177">
<div class="sourceCode" id="cb98"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>df2.iloc[sampler]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="177">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
<th data-quarto-table-cell-role="th">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>28</td>
<td>29</td>
<td>30</td>
<td>31</td>
<td>32</td>
<td>33</td>
<td>34</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
<td>13</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>14</td>
<td>15</td>
<td>16</td>
<td>17</td>
<td>18</td>
<td>19</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>21</td>
<td>22</td>
<td>23</td>
<td>24</td>
<td>25</td>
<td>26</td>
<td>27</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="179">
<div class="sourceCode" id="cb99"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># selecting random subset without replacement</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>df2.sample(n<span class="op">=</span><span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="179">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
<th data-quarto-table-cell-role="th">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
<td>13</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>28</td>
<td>29</td>
<td>30</td>
<td>31</td>
<td>32</td>
<td>33</td>
<td>34</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>21</td>
<td>22</td>
<td>23</td>
<td>24</td>
<td>25</td>
<td>26</td>
<td>27</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="180">
<div class="sourceCode" id="cb100"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># with replacement</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>df2.sample(n <span class="op">=</span><span class="dv">4</span>, replace <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="180">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
<th data-quarto-table-cell-role="th">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>28</td>
<td>29</td>
<td>30</td>
<td>31</td>
<td>32</td>
<td>33</td>
<td>34</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>28</td>
<td>29</td>
<td>30</td>
<td>31</td>
<td>32</td>
<td>33</td>
<td>34</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>14</td>
<td>15</td>
<td>16</td>
<td>17</td>
<td>18</td>
<td>19</td>
<td>20</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
<td>13</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="computing-indicatordummay-variables" class="level2">
<h2>Computing Indicator/Dummay Variables</h2>
<ul>
<li>pandas.get_dummies function</li>
<li>used for statistical modelling or machine learning applications</li>
<li>DataFrame.join() method</li>
<li>combine get_dummies() with pandas.cut()</li>
</ul>
<div class="cell" data-execution_count="186">
<div class="sourceCode" id="cb101"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>df_dict <span class="op">=</span> pd.DataFrame({<span class="st">&#39;key&#39;</span>: [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>, <span class="st">&#39;e&#39;</span>,],</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>                       <span class="st">&#39;data1&#39;</span>: <span class="bu">range</span>(<span class="dv">5</span>)})</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>df_dict</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="186">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">key</th>
<th data-quarto-table-cell-role="th">data1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>a</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>b</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>c</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>d</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>e</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="187">
<div class="sourceCode" id="cb102"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>pd.get_dummies(df_dict[<span class="st">&#39;key&#39;</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="187">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">a</th>
<th data-quarto-table-cell-role="th">b</th>
<th data-quarto-table-cell-role="th">c</th>
<th data-quarto-table-cell-role="th">d</th>
<th data-quarto-table-cell-role="th">e</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="189">
<div class="sourceCode" id="cb103"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>dummies <span class="op">=</span> pd.get_dummies(df_dict[<span class="st">&#39;key&#39;</span>], prefix <span class="op">=</span> <span class="st">&#39;key&#39;</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>df_with_dummy <span class="op">=</span> df_dict[[<span class="st">&#39;data1&#39;</span>]].join(dummies)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>df_with_dummy</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="189">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">data1</th>
<th data-quarto-table-cell-role="th">key_a</th>
<th data-quarto-table-cell-role="th">key_b</th>
<th data-quarto-table-cell-role="th">key_c</th>
<th data-quarto-table-cell-role="th">key_d</th>
<th data-quarto-table-cell-role="th">key_e</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode" id="cb104"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># combine pd.get_dummies() with pd.cut()</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> np.random.uniform(size <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>values</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="192">
<pre><code>array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,
       0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="193">
<div class="sourceCode" id="cb106"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> [<span class="dv">0</span>, <span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">1.0</span>]</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>pd.get_dummies(pd.cut(values, bins))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="193">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">(0.0, 0.2]</th>
<th data-quarto-table-cell-role="th">(0.2, 0.4]</th>
<th data-quarto-table-cell-role="th">(0.4, 0.6]</th>
<th data-quarto-table-cell-role="th">(0.6, 0.8]</th>
<th data-quarto-table-cell-role="th">(0.8, 1.0]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="extension-data-types-1" class="level2">
<h2>Extension data types</h2>
<div class="cell" data-execution_count="194">
<div class="sourceCode" id="cb107"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pd.Series([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="va">None</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="195">
<div class="sourceCode" id="cb108"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>s</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="195">
<pre><code>0    1.0
1    2.0
2    4.0
3    NaN
dtype: float64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="197">
<div class="sourceCode" id="cb110"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>s.dtype</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="197">
<pre><code>dtype(&#39;float64&#39;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode" id="cb112"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>s.isna()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="198">
<pre><code>0    False
1    False
2    False
3     True
dtype: bool</code></pre>
</div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode" id="cb114"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>s_int <span class="op">=</span> pd.Series([<span class="st">&#39;one&#39;</span>, <span class="st">&#39;two&#39;</span>, <span class="st">&#39;three&#39;</span>, <span class="va">None</span>, <span class="st">&#39;four&#39;</span>],</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>                 dtype <span class="op">=</span> pd.StringDtype())</span></code></pre></div>
</div>
<div class="cell" data-execution_count="201">
<div class="sourceCode" id="cb115"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>s_int</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="201">
<pre><code>0      one
1      two
2    three
3     &lt;NA&gt;
4     four
dtype: string</code></pre>
</div>
</div>
<div class="cell" data-execution_count="202">
<div class="sourceCode" id="cb117"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.DataFrame({<span class="st">&#39;A&#39;</span>: [<span class="dv">1</span>,<span class="dv">2</span>, <span class="va">None</span>, <span class="dv">4</span>],</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&#39;B&#39;</span>: [<span class="st">&#39;one&#39;</span>, <span class="st">&#39;two&#39;</span>, <span class="st">&#39;three&#39;</span>, <span class="va">None</span>],</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&#39;C&#39;</span>: [<span class="va">False</span>, <span class="va">True</span>, <span class="va">None</span>, <span class="va">True</span>]})</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>df3</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="202">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>one</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.0</td>
<td>two</td>
<td>True</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>NaN</td>
<td>three</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.0</td>
<td>None</td>
<td>True</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="206">
<div class="sourceCode" id="cb118"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># changing to their respective categories</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>df3[<span class="st">&#39;A&#39;</span>] <span class="op">=</span> df3[<span class="st">&#39;A&#39;</span>].astype(<span class="st">&#39;Int64&#39;</span>)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>df3[<span class="st">&#39;B&#39;</span>] <span class="op">=</span> df3[<span class="st">&#39;B&#39;</span>].astype(<span class="st">&#39;string&#39;</span>)</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>df3[<span class="st">&#39;C&#39;</span>] <span class="op">=</span> df3[<span class="st">&#39;C&#39;</span>].astype(<span class="st">&#39;boolean&#39;</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="205">
<div class="sourceCode" id="cb119"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>df3</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="205">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">A</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>one</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>two</td>
<td>True</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>&lt;NA&gt;</td>
<td>three</td>
<td>&lt;NA&gt;</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>&lt;NA&gt;</td>
<td>True</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="string-manipulation-1" class="level2">
<h2>String manipulation</h2>
<div class="cell" data-execution_count="4">
<div class="sourceCode" id="cb120"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>val <span class="op">=</span> <span class="st">&#39;a, b, kuch v&#39;</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>val.split(<span class="st">&#39;,&#39;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>[&#39;a&#39;, &#39; b&#39;, &#39; kuch v&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode" id="cb122"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># removing white space</span></span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>remove <span class="op">=</span> [x.strip() <span class="cf">for</span> x <span class="kw">in</span> val.split(<span class="st">&#39;,&#39;</span>)]</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>remove</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>[&#39;a&#39;, &#39;b&#39;, &#39;kuch v&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode" id="cb124"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># two colon concatenation</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>first, second, third <span class="op">=</span> remove</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>first <span class="op">+</span> <span class="st">&#39;::&#39;</span> <span class="op">+</span> second <span class="op">+</span> <span class="st">&#39;::&#39;</span> <span class="op">+</span> third</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>&#39;a::b::kuch v&#39;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode" id="cb126"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;::&#39;</span>.join(val)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;::&#39;</span>.join(remove)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>&#39;a::b::kuch v&#39;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode" id="cb128"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># in keyword</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="co">&#39;kuch v&#39;</span> <span class="kw">in</span> val</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode" id="cb130"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>val.index(<span class="st">&#39;,&#39;</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode" id="cb132"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>val.find(<span class="st">&#39;:&#39;</span>)</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="co"># remark- index doesnot give an error if the value is not found</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>-1</code></pre>
</div>
</div>
</section>
<section id="regular-expressions" class="level2">
<h2>Regular expressions</h2>
<ul>
<li>re saves CPU cycles</li>
</ul>
<div class="cell" data-execution_count="17">
<div class="sourceCode" id="cb134"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">&#39;bla bla bla ta ta ta bar</span><span class="ch">\t</span><span class="st"> baz aja </span><span class="ch">\t</span><span class="st"> nai fer&#39;</span></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>text</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>&#39;bla bla bla ta ta ta bar\t baz aja \t nai fer&#39;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode" id="cb136"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>re.split(<span class="vs">r&quot;\s+&quot;</span>, text)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>[&#39;bla&#39;, &#39;bla&#39;, &#39;bla&#39;, &#39;ta&#39;, &#39;ta&#39;, &#39;ta&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;aja&#39;, &#39;nai&#39;, &#39;fer&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode" id="cb138"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="co"># doing it with re</span></span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>withre <span class="op">=</span> re.<span class="bu">compile</span>(<span class="vs">r&quot;\s+&quot;</span>)</span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>withre.split(text)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>[&#39;bla&#39;, &#39;bla&#39;, &#39;bla&#39;, &#39;ta&#39;, &#39;ta&#39;, &#39;ta&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;aja&#39;, &#39;nai&#39;, &#39;fer&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode" id="cb140"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co"># finding pattern</span></span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>withre.findall(text)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>[&#39; &#39;, &#39; &#39;, &#39; &#39;, &#39; &#39;, &#39; &#39;, &#39; &#39;, &#39;\t &#39;, &#39; &#39;, &#39; \t &#39;, &#39; &#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode" id="cb142"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>text2 <span class="op">=</span> <span class="st">&quot;&quot;&quot;</span></span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="st">Kunal Khuranasoilpau@gmail.com</span></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="st">Sonakshi mehra.43@gmail.com</span></span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="st">Karan gill007@outlook.ca</span></span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a><span class="st">Smriti cuti3_43@ourkut.ca</span></span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;&quot;&quot;</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode" id="cb143"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>pattern <span class="op">=</span> <span class="vs">r&quot;[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}&quot;</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode" id="cb144"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using re.IGNORECASE</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>final_text <span class="op">=</span> re.<span class="bu">compile</span>(pattern, flags<span class="op">=</span>re.IGNORECASE)</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>final_text.findall(text2)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>[&#39;Khuranasoilpau@gmail.com&#39;,
 &#39;mehra.43@gmail.com&#39;,
 &#39;gill007@outlook.ca&#39;,
 &#39;cuti3_43@ourkut.ca&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode" id="cb146"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(final_text.sub(<span class="st">&#39;REDACTED&#39;</span>, text2))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Kunal REDACTED
Sonakshi REDACTED
Karan REDACTED
Smriti REDACTED
</code></pre>
</div>
</div>
</section>
<section id="string-functions-in-pandas" class="level2">
<h2>String functions in pandas</h2>
<ul>
<li>convert dictionary to Series with pandas</li>
<li><a href="https://learning.oreilly.com/library/view/python-for-data/9781098104023/ch07.html#table_vec_string">pandas string methods</a></li>
</ul>
<div class="cell" data-execution_count="48">
<div class="sourceCode" id="cb148"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">&#39;Kunal&#39;</span>: <span class="st">&#39;Khuranasoilpau@gmail.com&#39;</span>, <span class="st">&#39;Robin&#39;</span>: <span class="st">&#39;aryan_robin@yahoo.com&#39;</span>,</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;Deepika&#39;</span>: <span class="st">&#39;padukone.deepi@outlook.ca&#39;</span>, <span class="st">&#39;Ranbir&#39;</span> : <span class="st">&quot;singh.cool7@yahoo.com&quot;</span>,</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>       <span class="st">&#39;kabir&#39;</span>: np.nan}</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.Series(data)</span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>Kunal       Khuranasoilpau@gmail.com
Robin          aryan_robin@yahoo.com
Deepika    padukone.deepi@outlook.ca
Ranbir         singh.cool7@yahoo.com
kabir                            NaN
dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode" id="cb150"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>data.<span class="bu">str</span>.findall(pattern, flags<span class="op">=</span>re.IGNORECASE)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>Kunal       [Khuranasoilpau@gmail.com]
Robin          [aryan_robin@yahoo.com]
Deepika    [padukone.deepi@outlook.ca]
Ranbir         [singh.cool7@yahoo.com]
kabir                              NaN
dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode" id="cb152"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># slice</span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>data.<span class="bu">str</span>[:<span class="dv">7</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>Kunal      Khurana
Robin      aryan_r
Deepika    padukon
Ranbir     singh.c
kabir          NaN
dtype: object</code></pre>
</div>
</div>
</section>
<section id="categorical-data-1" class="level2">
<h2>Categorical data</h2>
<div class="cell" data-execution_count="65">
<div class="sourceCode" id="cb154"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> pd.Series([<span class="st">&#39;apple&#39;</span>, <span class="st">&#39;orange&#39;</span>, <span class="st">&#39;apple&#39;</span>, <span class="st">&#39;mango&#39;</span>]<span class="op">*</span> <span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode" id="cb155"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>values</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>0     apple
1    orange
2     apple
3     mango
4     apple
5    orange
6     apple
7     mango
dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode" id="cb157"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>pd.unique(values)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>array([&#39;apple&#39;, &#39;orange&#39;, &#39;mango&#39;], dtype=object)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="70">
<div class="sourceCode" id="cb159"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>values2 <span class="op">=</span> pd.Series([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">*</span> <span class="dv">2</span>)</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a>dim <span class="op">=</span> pd.Series([<span class="st">&#39;apple&#39;</span>, <span class="st">&#39;orange&#39;</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode" id="cb160"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>values2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>0    0
1    1
2    0
3    0
4    0
5    1
6    0
7    0
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode" id="cb162"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>dim</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>0     apple
1    orange
dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode" id="cb164"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="co"># take method to restore orignal set of strings</span></span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>dim.take(values2)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>0     apple
1    orange
0     apple
0     apple
0     apple
1    orange
0     apple
0     apple
dtype: object</code></pre>
</div>
</div>
</section>
<section id="categorical-extension-type-in-pandas" class="level2">
<h2>Categorical Extension type in pandas</h2>
<div class="cell" data-execution_count="76">
<div class="sourceCode" id="cb166"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>fruits <span class="op">=</span> [<span class="st">&#39;apple&#39;</span>, <span class="st">&#39;orange&#39;</span>, <span class="st">&#39;apple&#39;</span>, <span class="st">&#39;papaya&#39;</span>] <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb166-2"><a href="#cb166-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-3"><a href="#cb166-3" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="bu">len</span>(fruits)</span>
<span id="cb166-4"><a href="#cb166-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb166-5"><a href="#cb166-5" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed <span class="op">=</span> <span class="dv">123</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode" id="cb167"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;fruit&#39;</span>: fruits,</span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;basket_id&#39;</span>: np.arange(N),</span>
<span id="cb167-3"><a href="#cb167-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&#39;count&#39;</span>: rng.integers(<span class="dv">3</span>, <span class="dv">15</span>, size <span class="op">=</span> N),</span>
<span id="cb167-4"><a href="#cb167-4" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;weight&#39;</span>: rng.uniform(<span class="dv">0</span>, <span class="dv">4</span>, size <span class="op">=</span> N)},</span>
<span id="cb167-5"><a href="#cb167-5" aria-hidden="true" tabindex="-1"></a>                 columns <span class="op">=</span> [<span class="st">&#39;basket_id&#39;</span>, <span class="st">&#39;fruit&#39;</span>, <span class="st">&#39;count&#39;</span>, <span class="st">&#39;weight&#39;</span>])</span>
<span id="cb167-6"><a href="#cb167-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb167-7"><a href="#cb167-7" aria-hidden="true" tabindex="-1"></a>df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">basket_id</th>
<th data-quarto-table-cell-role="th">fruit</th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">weight</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>apple</td>
<td>9</td>
<td>0.694527</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>orange</td>
<td>3</td>
<td>1.250969</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>apple</td>
<td>7</td>
<td>0.057898</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>papaya</td>
<td>9</td>
<td>0.130208</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>apple</td>
<td>14</td>
<td>1.986807</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>5</td>
<td>orange</td>
<td>5</td>
<td>1.873250</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>6</td>
<td>apple</td>
<td>10</td>
<td>0.510761</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>7</td>
<td>papaya</td>
<td>12</td>
<td>1.030250</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode" id="cb168"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="co"># converting df to categorical</span></span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>fruit_cat <span class="op">=</span> df[<span class="st">&#39;fruit&#39;</span>].astype(<span class="st">&#39;category&#39;</span>)</span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a>fruit_cat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>0     apple
1    orange
2     apple
3    papaya
4     apple
5    orange
6     apple
7    papaya
Name: fruit, dtype: category
Categories (3, object): [&#39;apple&#39;, &#39;orange&#39;, &#39;papaya&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode" id="cb170"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> fruit_cat.array</span></code></pre></div>
</div>
<div class="cell" data-execution_count="88">
<div class="sourceCode" id="cb171"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(c)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>pandas.core.arrays.categorical.Categorical</code></pre>
</div>
</div>
<div class="cell" data-execution_count="89">
<div class="sourceCode" id="cb173"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>c.categories</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>Index([&#39;apple&#39;, &#39;orange&#39;, &#39;papaya&#39;], dtype=&#39;object&#39;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode" id="cb175"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>c.codes</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>array([0, 1, 0, 2, 0, 1, 0, 2], dtype=int8)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode" id="cb177"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="co"># how to get mapping between code and categories</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a><span class="bu">dict</span>(<span class="bu">enumerate</span>(c.categories))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>{0: &#39;apple&#39;, 1: &#39;orange&#39;, 2: &#39;papaya&#39;}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode" id="cb179"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>pd.unique(values)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>array([0, 1], dtype=int64)</code></pre>
</div>
</div>
</section>
<section id="categorical-data-2" class="level2">
<h2>Categorical data</h2>
<div class="cell" data-execution_count="96">
<div class="sourceCode" id="cb181"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>values3 <span class="op">=</span> pd.Series([<span class="st">&#39;apple&#39;</span>, <span class="st">&#39;orange&#39;</span>, <span class="st">&#39;apple&#39;</span>,</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;apple&#39;</span>] <span class="op">*</span> <span class="dv">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode" id="cb182"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>values3</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>0     apple
1    orange
2     apple
3     apple
4     apple
5    orange
6     apple
7     apple
dtype: object</code></pre>
</div>
</div>
<div class="cell" data-execution_count="98">
<div class="sourceCode" id="cb184"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>pd.unique(values3)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>array([&#39;apple&#39;, &#39;orange&#39;], dtype=object)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode" id="cb186"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>pd.value_counts(values3)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>apple     6
orange    2
Name: count, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="104">
<div class="sourceCode" id="cb188"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> [<span class="st">&#39;foo&#39;</span>, <span class="st">&#39;bar&#39;</span>, <span class="st">&#39;baz&#39;</span>]</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>codes <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb188-5"><a href="#cb188-5" aria-hidden="true" tabindex="-1"></a>my_cats2 <span class="op">=</span> pd.Categorical.from_codes(codes, categories)</span>
<span id="cb188-6"><a href="#cb188-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb188-7"><a href="#cb188-7" aria-hidden="true" tabindex="-1"></a>my_cats2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>[&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;bar&#39;]
Categories (3, object): [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="106">
<div class="sourceCode" id="cb190"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>ordered_cat <span class="op">=</span> pd.Categorical.from_codes(codes, categories, </span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a>                                 ordered <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb190-3"><a href="#cb190-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-4"><a href="#cb190-4" aria-hidden="true" tabindex="-1"></a>ordered_cat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>[&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;bar&#39;]
Categories (3, object): [&#39;foo&#39; &lt; &#39;bar&#39; &lt; &#39;baz&#39;]</code></pre>
</div>
</div>
</section>
<section id="computations-with-categoricals" class="level2">
<h2>Computations with categoricals</h2>
<div class="cell" data-execution_count="107">
<div class="sourceCode" id="cb192"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb192-3"><a href="#cb192-3" aria-hidden="true" tabindex="-1"></a>draws <span class="op">=</span> rng.standard_normal(<span class="dv">1000</span>)</span>
<span id="cb192-4"><a href="#cb192-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb192-5"><a href="#cb192-5" aria-hidden="true" tabindex="-1"></a>draws[:<span class="dv">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>array([-0.98912135, -0.36778665,  1.28792526,  0.19397442,  0.9202309 ])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="110">
<div class="sourceCode" id="cb194"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> pd.qcut(draws, <span class="dv">4</span>, labels<span class="op">=</span>[<span class="st">&#39;Q1&#39;</span>, <span class="st">&#39;Q2&#39;</span>, <span class="st">&#39;Q3&#39;</span>, <span class="st">&#39;Q4&#39;</span>])</span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb194-3"><a href="#cb194-3" aria-hidden="true" tabindex="-1"></a>bins</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>[&#39;Q1&#39;, &#39;Q2&#39;, &#39;Q4&#39;, &#39;Q3&#39;, &#39;Q4&#39;, ..., &#39;Q1&#39;, &#39;Q3&#39;, &#39;Q3&#39;, &#39;Q1&#39;, &#39;Q3&#39;]
Length: 1000
Categories (4, object): [&#39;Q1&#39; &lt; &#39;Q2&#39; &lt; &#39;Q3&#39; &lt; &#39;Q4&#39;]</code></pre>
</div>
</div>
<section id="using-groupby-for-summary-statistics" class="level3">
<h3>using groupby for summary statistics</h3>
<div class="cell" data-execution_count="113">
<div class="sourceCode" id="cb196"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> pd.Series(bins, name<span class="op">=</span> <span class="st">&#39;quartile&#39;</span>)</span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-3"><a href="#cb196-3" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> (pd.Series(draws)</span>
<span id="cb196-4"><a href="#cb196-4" aria-hidden="true" tabindex="-1"></a>           .groupby(bins)</span>
<span id="cb196-5"><a href="#cb196-5" aria-hidden="true" tabindex="-1"></a>           .agg([<span class="st">&#39;count&#39;</span>, <span class="st">&#39;min&#39;</span>, <span class="st">&#39;max&#39;</span>])</span>
<span id="cb196-6"><a href="#cb196-6" aria-hidden="true" tabindex="-1"></a>           .reset_index())</span>
<span id="cb196-7"><a href="#cb196-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-8"><a href="#cb196-8" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">quartile</th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">min</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Q1</td>
<td>250</td>
<td>-3.298281</td>
<td>-0.626241</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Q2</td>
<td>250</td>
<td>-0.622043</td>
<td>0.040753</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Q3</td>
<td>250</td>
<td>0.043084</td>
<td>0.736086</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Q4</td>
<td>250</td>
<td>0.738013</td>
<td>3.058244</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="better-performance-with-categoricals" class="level3">
<h3>Better performance with categoricals</h3>
<div class="cell" data-execution_count="115">
<div class="sourceCode" id="cb197"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10_000_000</span></span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb197-3"><a href="#cb197-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> pd.Series([<span class="st">&#39;foo&#39;</span>, <span class="st">&#39;bar&#39;</span>, <span class="st">&#39;baz&#39;</span>, <span class="st">&#39;qux&#39;</span>]) <span class="op">*</span> (N <span class="op">//</span><span class="dv">4</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="116">
<div class="sourceCode" id="cb198"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="co"># convert labels to categoricals</span></span>
<span id="cb198-2"><a href="#cb198-2" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> labels.astype(<span class="st">&#39;category&#39;</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="119">
<div class="sourceCode" id="cb199"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="co"># memory use</span></span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>labels.memory_usage(deep <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>30000356</code></pre>
</div>
</div>
<div class="cell" data-execution_count="118">
<div class="sourceCode" id="cb201"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>categories.memory_usage(deep <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>30000532</code></pre>
</div>
</div>
</section>
</section>
<section id="categorical-methods" class="level2">
<h2>Categorical Methods</h2>
<ul>
<li><a href="https://learning.oreilly.com/library/view/python-for-data/9781098104023/ch07.html#table_categorical_methods">list of categorical methods</a></li>
</ul>
<div class="cell" data-execution_count="122">
<div class="sourceCode" id="cb203"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> pd.Series([<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>] <span class="op">*</span> <span class="dv">2</span>)</span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-3"><a href="#cb203-3" aria-hidden="true" tabindex="-1"></a>cat_s <span class="op">=</span> s.astype(<span class="st">&#39;category&#39;</span>)</span>
<span id="cb203-4"><a href="#cb203-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb203-5"><a href="#cb203-5" aria-hidden="true" tabindex="-1"></a>cat_s</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>0    a
1    b
2    c
3    d
4    a
5    b
6    c
7    d
dtype: category
Categories (4, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="123">
<div class="sourceCode" id="cb205"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using special accessor attribute cat</span></span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb205-3"><a href="#cb205-3" aria-hidden="true" tabindex="-1"></a>cat_s.cat.codes</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="123">
<pre><code>0    0
1    1
2    2
3    3
4    0
5    1
6    2
7    3
dtype: int8</code></pre>
</div>
</div>
<div class="cell" data-execution_count="124">
<div class="sourceCode" id="cb207"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>actual_categories <span class="op">=</span> [<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>, <span class="st">&#39;e&#39;</span>]</span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb207-3"><a href="#cb207-3" aria-hidden="true" tabindex="-1"></a>cat_s2 <span class="op">=</span> cat_s.cat.set_categories(actual_categories)</span>
<span id="cb207-4"><a href="#cb207-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb207-5"><a href="#cb207-5" aria-hidden="true" tabindex="-1"></a>cat_s2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>0    a
1    b
2    c
3    d
4    a
5    b
6    c
7    d
dtype: category
Categories (5, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="125">
<div class="sourceCode" id="cb209"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>cat_s.value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="125">
<pre><code>a    2
b    2
c    2
d    2
Name: count, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="126">
<div class="sourceCode" id="cb211"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>cat_s2.value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<pre><code>a    2
b    2
c    2
d    2
e    0
Name: count, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="127">
<div class="sourceCode" id="cb213"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>cat_s3 <span class="op">=</span> cat_s[cat_s.isin([<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>])]</span>
<span id="cb213-2"><a href="#cb213-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb213-3"><a href="#cb213-3" aria-hidden="true" tabindex="-1"></a>cat_s3</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="127">
<pre><code>0    a
1    b
4    a
5    b
dtype: category
Categories (4, object): [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="130">
<div class="sourceCode" id="cb215"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="co"># removing unused categories</span></span>
<span id="cb215-2"><a href="#cb215-2" aria-hidden="true" tabindex="-1"></a>cat_s3.cat.remove_unused_categories()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="130">
<pre><code>0    a
1    b
4    a
5    b
dtype: category
Categories (2, object): [&#39;a&#39;, &#39;b&#39;]</code></pre>
</div>
</div>
</section>
<section id="creating-dummy-variables-for-modelling" class="level2">
<h2>Creating dummy variables for modelling</h2>
<div class="cell" data-execution_count="131">
<div class="sourceCode" id="cb217"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>cat_s <span class="op">=</span> pd.Series([<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>] <span class="op">*</span> <span class="dv">2</span>,</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a>                 dtype<span class="op">=</span> <span class="st">&#39;category&#39;</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="132">
<div class="sourceCode" id="cb218"><pre class="sourceCode python cell-code"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>pd.get_dummies(cat_s)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="132">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">a</th>
<th data-quarto-table-cell-role="th">b</th>
<th data-quarto-table-cell-role="th">c</th>
<th data-quarto-table-cell-role="th">d</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>True</td>
<td>False</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>False</td>
<td>True</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>False</td>
<td>False</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>True</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden" data-render-id="quarto-int-sidebar-title">Homepage</span> <span class="hidden" data-render-id="quarto-int-navbar-title">Homepage</span> <span class="hidden" data-render-id="quarto-int-navbar:Kunal Khurana">Kunal Khurana</span> <span class="hidden" data-render-id="quarto-int-navbar:/about.html">/about.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Posts">Posts</span> <span class="hidden" data-render-id="quarto-int-navbar:All posts">All posts</span> <span class="hidden" data-render-id="quarto-int-navbar:/posts/index.html">/posts/index.html</span> <span class="hidden" data-render-id="quarto-int-navbar:English">English</span> <span class="hidden" data-render-id="quarto-int-navbar:/posts/en.html">/posts/en.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Français">Français</span> <span class="hidden" data-render-id="quarto-int-navbar:/posts/fr.html">/posts/fr.html</span> <span class="hidden" data-render-id="quarto-int-navbar:https://github.com/Kkhurana007/fr_blog_mine">https://github.com/Kkhurana007/fr_blog_mine</span> <span class="hidden" data-render-id="quarto-int-navbar:https://twitter.com/kunalkhurana007">https://twitter.com/kunalkhurana007</span> <span class="hidden" data-render-id="footer-left">Blog made with <a href="https://quarto.org/">Quarto</a> by Kunal.</span></p>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden" data-render-id="quarto-metatitle">Homepage - Data Cleaning</span> <span class="hidden" data-render-id="quarto-twittercardtitle">Homepage - Data Cleaning</span> <span class="hidden" data-render-id="quarto-ogcardtitle">Homepage - Data Cleaning</span> <span class="hidden" data-render-id="quarto-metasitename">Homepage</span> <span class="hidden" data-render-id="quarto-twittercarddesc">Python basics</span> <span class="hidden" data-render-id="quarto-ogcardddesc">Python basics</span></p>
</div>
</section>
</section>

</main> <!-- /main -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.ilovesoils\.com\/**");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<script src="https://giscus.app/client.js"
        data-repo="Kkhurana007/fr_blog_mine"
        data-repo-id="R_kgDOJuKwyw"
        data-category="General"
        data-category-id="DIC_kwDOJuKwy84CXJ4P"
        data-mapping="title"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <div class='footer-contents'>Blog made with [Quarto](https://quarto.org/) by Kunal.</div>  
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Kkhurana007">
      <i 
  class="bi bi-github" 
  role="img" 
>
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/kunalkhurana007">
      <i 
  class="bi bi-twitter" 
  role="img" 
>
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:Khuranasoilpau@gmail.com">
      <i 
  class="bi bi-envelope" 
  role="img" 
>
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>

</body>

</html>