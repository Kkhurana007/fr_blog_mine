{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a5226b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-06T06:58:30.145088Z",
     "iopub.status.busy": "2024-05-06T06:58:30.144231Z",
     "iopub.status.idle": "2024-05-06T06:58:31.159455Z",
     "shell.execute_reply": "2024-05-06T06:58:31.157924Z"
    },
    "papermill": {
     "duration": 1.025398,
     "end_time": "2024-05-06T06:58:31.162603",
     "exception": false,
     "start_time": "2024-05-06T06:58:30.137205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "image: logistic_regression.png\n",
    "title: logistic_regression\n",
    "subtitle: Efficiency of logistic regression with sample data from scikit-learn\n",
    "date: '2024-05-20'\n",
    "categories: [logistic regression, machine learning, algorithm]\n",
    "author: Kunal Khurana\n",
    "jupyter: python3\n",
    "toc: True\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab68f2",
   "metadata": {
    "papermill": {
     "duration": 0.003573,
     "end_time": "2024-05-06T06:58:31.170567",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.166994",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bac0f4ca",
   "metadata": {
    "papermill": {
     "duration": 0.003383,
     "end_time": "2024-05-06T06:58:31.177868",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.174485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explanation and steps for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b806e",
   "metadata": {
    "papermill": {
     "duration": 0.003338,
     "end_time": "2024-05-06T06:58:31.184915",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.181577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Probabilities are utilized instead of specific values in this approach which is not the case for linear regression. Instead of mean square error, cross-entropy is employed.\n",
    "\n",
    "The Gradient Descent method is applied for LogisticRegression as well.\n",
    "\n",
    "Weight calculation involves subtracting the gradient from the current weight.\n",
    "\n",
    "Steps: \n",
    "    (i) Training - Initialize weight and bias as zero. \n",
    "    (ii) Given a data point - predict result, calculate error, use gradient descent to determine new weight and bias, repeat n times. \n",
    "    (iii) Testing - input values into the equation, select label based on probability.\n",
    "    \n",
    "The same equation as in linear regression is utilized, integrated into the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc337fe",
   "metadata": {
    "papermill": {
     "duration": 0.003321,
     "end_time": "2024-05-06T06:58:31.191910",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.188589",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cc2060b",
   "metadata": {
    "papermill": {
     "duration": 0.003265,
     "end_time": "2024-05-06T06:58:31.198961",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.195696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e0aa6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T06:58:31.208443Z",
     "iopub.status.busy": "2024-05-06T06:58:31.207898Z",
     "iopub.status.idle": "2024-05-06T06:58:31.220379Z",
     "shell.execute_reply": "2024-05-06T06:58:31.219241Z"
    },
    "papermill": {
     "duration": 0.020766,
     "end_time": "2024-05-06T06:58:31.223360",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.202594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a class LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sigmoid function as we'll be using it\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "\n",
    "    # always start by adding fit and predict funciton \n",
    "    def fit(self, X, y):\n",
    "        # Initializing weights and bias\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)  # assigning zeros as weights\n",
    "        self.bias = 0\n",
    "\n",
    "        # Gradient Descent\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_pred)\n",
    "            \n",
    "            # Gradient calculation\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_pred)\n",
    "        class_pred = [0 if i <= 0.5 else 1 for i in y_pred]\n",
    "        return class_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed8a1d",
   "metadata": {
    "papermill": {
     "duration": 0.003674,
     "end_time": "2024-05-06T06:58:31.231253",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.227579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564e7544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T06:58:31.242460Z",
     "iopub.status.busy": "2024-05-06T06:58:31.240967Z",
     "iopub.status.idle": "2024-05-06T06:58:33.013258Z",
     "shell.execute_reply": "2024-05-06T06:58:33.011357Z"
    },
    "papermill": {
     "duration": 1.782495,
     "end_time": "2024-05-06T06:58:33.017686",
     "exception": false,
     "start_time": "2024-05-06T06:58:31.235191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# testing how accurate it is with breast_cancer dataset from scikit_learn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "clf = LogisticRegression(lr=0.01, n_iters=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Accuracy function\n",
    "def accuracy(y_pred, y_test):\n",
    "    accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(f'Accuracy: {acc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.772645,
   "end_time": "2024-05-06T06:58:33.761809",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-06T06:58:26.989164",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
